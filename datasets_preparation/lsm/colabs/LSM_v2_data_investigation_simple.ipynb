{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ojx9U3lSg9k"
      },
      "source": [
        "1.  Please do\n",
        "    [AoD](https://grants.corp.google.com/#/grants?request=20h%2Fchr-ards-fitbit-prod-research-deid-eng-team:r\u0026reason=%22b%2F285178698%22)\n",
        "    before running this colab.\n",
        "2.  Run `experimental/health_foundation_models/colab/colab_launch_borg_cpu.sh`\n",
        "3.  Use `heath_foundation_models_cpu` as the colab kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95s6ictnHEZO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from google3.medical.waveforms.modelling.lsm.datasets.lsm import sensor_constants\n",
        "from google3.pyglib import gfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRcQ9Dq5Qevs"
      },
      "outputs": [],
      "source": [
        "DEFAULT_DATA_ROOT = '/namespace/fitbit-medical-sandboxes/jg/partner/encrypted/chr-ards-fitbit-prod-research/deid/exp/dmcduff/ttl=52w/lsm_v2/datasets/tfds'  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tZLGPH8jvll"
      },
      "outputs": [],
      "source": [
        "# @title Constants\n",
        "labels = sensor_constants.FEATURES_TO_INCLUDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvhALc2d2wh9"
      },
      "outputs": [],
      "source": [
        "# @title Check the paths\n",
        "\n",
        "latest_dataset_paths = gfile.Glob(f'{DEFAULT_DATA_ROOT}/*')\n",
        "latest_dataset_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PVo2BK5R-hu"
      },
      "outputs": [],
      "source": [
        "# @title Utils\n",
        "\n",
        "\n",
        "def check_dataset_length(root_data_path: str, dataset_name: str) -\u003e None:\n",
        "  \"\"\"Checks and prints the length of a dataset.\n",
        "\n",
        "  This function takes the root data path and the dataset name as input.\n",
        "  It then uses gfile.Glob to find all the data samples within the dataset\n",
        "  and prints the total number of samples found.\n",
        "\n",
        "  Args:\n",
        "    root_data_path: The root directory where the dataset is located.\n",
        "    dataset_name: The name of the dataset to check.\n",
        "\n",
        "  Returns:\n",
        "      None. This function prints the dataset name and the number of data\n",
        "      samples.\n",
        "  \"\"\"\n",
        "  print('Dataset Name:', dataset_name)\n",
        "  print(\n",
        "      'Number of Data Sample:',\n",
        "      len(gfile.Glob(f'{root_data_path}/{dataset_name}/lsm/*/*')),\n",
        "  )\n",
        "\n",
        "\n",
        "def inspect_dataset(\n",
        "    root_data_path: str, dataset_name: str, data_class: str == 'lsm'\n",
        "):\n",
        "  \"\"\"Loads, inspects, and visualizes a subset of a TensorFlow dataset.\n",
        "\n",
        "  This function loads a specified dataset using `tfds.load`, prints its length,\n",
        "  and then visualizes the first 5 samples. It extracts the 'mask' and\n",
        "  'input_signal' from each sample, converts them to NumPy arrays, and\n",
        "  uses the `visualize` function to display them.\n",
        "\n",
        "  Args:\n",
        "    root_data_path: The root directory where the dataset is located.\n",
        "    dataset_name: The name of the dataset to inspect.\n",
        "\n",
        "  Returns:\n",
        "    None. This function prints information and displays visualizations.\n",
        "  \"\"\"\n",
        "  print('Dataset Name:', dataset_name)\n",
        "  try:\n",
        "    data = tfds.load(\n",
        "        data_class,\n",
        "        data_dir=f'{root_data_path}/{dataset_name}',\n",
        "        split='train',\n",
        "        shuffle_files=False,\n",
        "    )\n",
        "    print('Number of Train Data Sample:', len(data))\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  data_valid = tfds.load(\n",
        "      data_class,\n",
        "      data_dir=f'{root_data_path}/{dataset_name}',\n",
        "      split='valid',\n",
        "      shuffle_files=False,\n",
        "  )\n",
        "  print('Number of Valid Data Sample:', len(data_valid))\n",
        "\n",
        "  for sample in data_valid.take(5):\n",
        "    mask = tf.io.parse_tensor(sample['mask'], out_type=tf.bool).numpy().T\n",
        "    sample = (\n",
        "        tf.io.parse_tensor(sample['input_signal'], out_type=tf.double).numpy().T\n",
        "    )\n",
        "\n",
        "    visualize(mask, cmap='Greys')\n",
        "    visualize(sample)\n",
        "\n",
        "    print('--------------------------')\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    sample_signal_input,\n",
        "    figsize=(20, 5),\n",
        "    title='',\n",
        "    cmap='cool',\n",
        "    dim=None,\n",
        "    cbar=True,\n",
        "    disabletext=False,\n",
        "):\n",
        "  \"\"\"Visualizes a sample signal as a heatmap.\n",
        "\n",
        "  This function creates a heatmap visualization of the input sample signal.\n",
        "  It uses `seaborn.heatmap` to generate the heatmap and allows for customization\n",
        "  of figure size, title, colormap, and display options.\n",
        "\n",
        "  Args:\n",
        "    sample_signal_input: The input sample signal data as a NumPy array.\n",
        "    figsize: Tuple specifying the width and height of the figure (default: (20,\n",
        "      5)).\n",
        "    title: The title of the plot (default: '').\n",
        "    cmap: The colormap to use for the heatmap (default: 'cool').\n",
        "    dim: Optional dimension to select for visualization (default: None, displays\n",
        "      all dimensions).\n",
        "    cbar: Whether to display the colorbar (default: True).\n",
        "    disabletext: Whether to disable the plot title (default: False).\n",
        "\n",
        "  Returns:\n",
        "    None. This function displays the heatmap visualization.\n",
        "  \"\"\"\n",
        "\n",
        "  if dim is not None:\n",
        "    sample_signal_input = sample_signal_input[[dim], :]\n",
        "    labels_temp = []\n",
        "  else:\n",
        "    labels_temp = labels\n",
        "\n",
        "  plt.figure(figsize=figsize)\n",
        "  ax1 = plt.subplot2grid((1, 12), (0, 0), colspan=12)\n",
        "  ax1 = sns.heatmap(\n",
        "      sample_signal_input,\n",
        "      cmap=cmap,\n",
        "      cbar=cbar,\n",
        "      linewidths=0.0,\n",
        "      linecolor='black',\n",
        "      alpha=0.8,\n",
        "      ax=ax1,\n",
        "      yticklabels=labels_temp,\n",
        "  )\n",
        "\n",
        "  for tick in ax1.get_xticklabels():\n",
        "    tick.set_fontname('Ubuntu')\n",
        "  ax1.tick_params(axis='x', labelsize=10.5)\n",
        "\n",
        "  for tick in ax1.get_yticklabels():\n",
        "    tick.set_fontname('Ubuntu')\n",
        "  ax1.tick_params(axis='y', labelsize=10.5)\n",
        "\n",
        "  # Set x-axis ticks every 4 hours\n",
        "  tick_interval = 4 * 60  # 4 hours in minutes\n",
        "  xticks = np.arange(0, sample_signal_input.shape[1], tick_interval)\n",
        "  xtick_labels = [minutes_to_time(x) for x in xticks]\n",
        "  ax1.set_xticks(xticks)\n",
        "  ax1.set_xticklabels(xtick_labels, rotation=45, ha='right')\n",
        "  # ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  if not disabletext:\n",
        "    plt.title(title)\n",
        "\n",
        "  for i in np.arange(0, sample_signal_input.shape[1], 60):\n",
        "    if i % (60 * 24) == 0:\n",
        "      tempwidth, tempalpha = 2, 1\n",
        "    else:\n",
        "      tempwidth, tempalpha = 1, 0.4\n",
        "    ax1.axvline(x=i, color='k', alpha=tempalpha, linewidth=tempwidth)\n",
        "\n",
        "  for i in np.arange(0, sample_signal_input.shape[0] + 1, 1):\n",
        "    ax1.axhline(y=i, color='k', alpha=0.4, linewidth=1)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def consecutive_ones_lengths(mask):\n",
        "  \"\"\"Calculates the lengths of consecutive sequences of 1s in a binary mask.\n",
        "\n",
        "  This function identifies and measures the lengths of continuous stretches of\n",
        "  1s within\n",
        "  a given binary mask (an array consisting of 0s and 1s). It works by:\n",
        "\n",
        "  1. Finding the points where the mask transitions from 0 to 1 (start of a\n",
        "  sequence)\n",
        "     and from 1 to 0 (end of a sequence) using `np.diff`.\n",
        "  2. Using `np.where` to get the indices of these transitions.\n",
        "  3. Calculating the length of each sequence by subtracting the start index from\n",
        "  the end index.\n",
        "\n",
        "  It's particularly useful for analyzing patterns or gaps in data represented by\n",
        "  such masks.\n",
        "\n",
        "  Args:\n",
        "    mask: A 1-D NumPy array representing the binary mask.\n",
        "\n",
        "  Returns:\n",
        "    A 1-D NumPy array containing the lengths of each consecutive sequence of 1s\n",
        "    found\n",
        "    in the input mask.\n",
        "  \"\"\"\n",
        "\n",
        "  # Find where the mask changes value\n",
        "  diff = np.diff(mask, prepend=0, append=0)\n",
        "\n",
        "  # Start and end indices of sequences of ones\n",
        "  starts = np.where(diff == 1)[0]\n",
        "  ends = np.where(diff == -1)[0]\n",
        "\n",
        "  # Calculate lengths of each sequence of ones\n",
        "  lengths = ends - starts\n",
        "  return lengths\n",
        "\n",
        "\n",
        "def minutes_to_time(x):\n",
        "  \"\"\"Converts minutes to a time string in HH:MM format.\n",
        "\n",
        "  This function takes an integer representing a duration in minutes and\n",
        "  converts it into a formatted time string in the format \"HH:MM\" (hours and\n",
        "  minutes).\n",
        "\n",
        "  Args:\n",
        "    x: An integer representing the duration in minutes.\n",
        "\n",
        "  Returns:\n",
        "    A string representing the time in HH:MM format.\n",
        "  \"\"\"\n",
        "  hours = int(x // 60)\n",
        "  minutes = int(x % 60)\n",
        "  return f'{hours:02d}:{minutes:02d}'\n",
        "\n",
        "\n",
        "class StopExecution(Exception):\n",
        "  \"\"\"Custom exception used to halt the execution of a cell or process.\n",
        "\n",
        "  This exception is designed to stop the execution flow without displaying\n",
        "  a traceback. It is useful for scenarios where you want to terminate\n",
        "  a process prematurely but avoid cluttering the output with unnecessary\n",
        "  traceback information.\n",
        "\n",
        "  Attributes: None\n",
        "\n",
        "  Methods:\n",
        "      _render_traceback_: Overrides the default traceback rendering to\n",
        "          suppress the traceback output.\n",
        "  \"\"\"\n",
        "\n",
        "  def _render_traceback_(self):\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg_ww6vvN60b"
      },
      "outputs": [],
      "source": [
        "# @title Check the Data Length\n",
        "check_dataset_length(\n",
        "    DEFAULT_DATA_ROOT,\n",
        "    'lsm_v2_pretrain_sessions_-1_windowsize_1440_sensorfeatures_26_validonly_False_missingratio_0.2_timestamp_202503080218',\n",
        ")\n",
        "check_dataset_length(\n",
        "    DEFAULT_DATA_ROOT,\n",
        "    'lsm_v2_pretrain_sessions_-1_windowsize_1440_sensorfeatures_26_validonly_False_missingratio_0.5_timestamp_202503090320',\n",
        ")\n",
        "check_dataset_length(\n",
        "    DEFAULT_DATA_ROOT,\n",
        "    'lsm_v2_pretrain_sessions_-1_windowsize_1440_sensorfeatures_26_validonly_False_missingratio_0.8_timestamp_202503091557',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SMWkuMoHQRp"
      },
      "outputs": [],
      "source": [
        "# @title Inspect the 20% Daily Data\n",
        "\n",
        "inspect_dataset(\n",
        "    DEFAULT_DATA_ROOT,\n",
        "    'lsm_v2_pretrain_sessions_-1_windowsize_1440_sensorfeatures_26_validonly_False_missingratio_0.2_timestamp_202503080218',\n",
        "    'lsm',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd5wP5zMlfb_"
      },
      "outputs": [],
      "source": [
        "# @title Inspect 50% Missing Daily Data\n",
        "\n",
        "inspect_dataset(\n",
        "    DEFAULT_DATA_ROOT,\n",
        "    'lsm_v2_pretrain_sessions_-1_windowsize_1440_sensorfeatures_26_validonly_False_missingratio_0.5_timestamp_202503090320',\n",
        "    'lsm',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAansOLZSJF-"
      },
      "outputs": [],
      "source": [
        "# @title Inspect the 80% Daily Data\n",
        "\n",
        "inspect_dataset(\n",
        "    DEFAULT_DATA_ROOT,\n",
        "    'lsm_v2_pretrain_sessions_-1_windowsize_1440_sensorfeatures_26_validonly_False_missingratio_0.8_timestamp_202503091557',\n",
        "    'lsm',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HKsLZxKWzCs"
      },
      "outputs": [],
      "source": [
        "# @title Inspect the perfect balanced test dataset\n",
        "\n",
        "inspect_dataset(\n",
        "    '/namespace/fitbit-medical-sandboxes/jg/partner/encrypted/chr-ards-fitbit-prod-research/deid/exp/dmcduff/ttl=52w/lsm_v2/datasets/tfds_test',\n",
        "    'lsm_v2_missing_balanced_20250301_valid_dataset',\n",
        "    'LsmMissingBalanced',\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//experimental/health_foundation_models/colab:colab_deps",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/medical/waveforms/modelling/lsm/datasets/lsm/colabs/LSM_v2_data_investigation_simple.ipynb",
          "timestamp": 1741662338655
        },
        {
          "file_id": "/piper/depot/google3/medical/waveforms/modelling/lsm/datasets/lsm/colabs/LSM_v2_data_investigation.ipynb",
          "timestamp": 1738262858956
        },
        {
          "file_id": "/piper/depot/google3/medical/waveforms/modelling/lsm/datasets/lsm/colabs/LSM_v2_data_investigation.ipynb",
          "timestamp": 1736790202458
        },
        {
          "file_id": "/piper/depot/google3/medical/waveforms/modelling/lsm/datasets/lsm/colabs/LSM_v2_data_investigation.ipynb",
          "timestamp": 1736731703577
        },
        {
          "file_id": "1bRgne2ysRTl-pbkBWetZZVIo9W2gllHw",
          "timestamp": 1734551140091
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
