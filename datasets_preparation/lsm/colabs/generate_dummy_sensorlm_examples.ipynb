{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKCR6jyVJawD"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from io import BytesIO\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL.Image as pil_image\n",
        "from google3.file.base.python import shards\n",
        "from google3.pyglib import gfile\n",
        "from google3.third_party.array_record.python import array_record_module\n",
        "from google3.third_party.tensorflow.core.example import example_pb2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnS-gtfMaz2c"
      },
      "outputs": [],
      "source": [
        "def image_to_bytes(image: pil_image.Image, image_format: str = 'PNG') -\u003e bytes:\n",
        "  \"\"\"Converts a PIL image to bytes.\"\"\"\n",
        "  data = io.BytesIO()\n",
        "  image.save(data, format=image_format)\n",
        "  return data.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1sY9PQPLmjZ"
      },
      "outputs": [],
      "source": [
        "# @title Write ArrayRecords with TF Example\n",
        "\n",
        "OUTPUT_DIR = '/cns/dz-d/home/xliucs/sensorlm'\n",
        "NUMBER_OF_SHARDS = 5\n",
        "NUMBER_OF_IMAGES_PER_SHARD = 10\n",
        "gfile.MakeDirs(os.path.join(OUTPUT_DIR))\n",
        "filenames = shards.GenerateShardedFilenames(\n",
        "    os.path.join(\n",
        "        OUTPUT_DIR, f'dummy_{NUMBER_OF_SHARDS}.arrayrecord@{NUMBER_OF_SHARDS}'\n",
        "    )\n",
        ")\n",
        "for shard_id in range(NUMBER_OF_SHARDS):\n",
        "  path = filenames[shard_id]\n",
        "  writer = array_record_module.ArrayRecordWriter(path)\n",
        "  try:\n",
        "    for _ in range(NUMBER_OF_IMAGES_PER_SHARD):\n",
        "      value = example_pb2.Example()\n",
        "      dummy_image = pil_image.new('RGB', (100, 100), color='red')\n",
        "      value.features.feature['input_images'].bytes_list.value.append(\n",
        "          image_to_bytes(dummy_image)\n",
        "      )\n",
        "      value.features.feature['input_texts'].bytes_list.value.append(\n",
        "          'What is this image?'.encode()\n",
        "      )\n",
        "      value.features.feature['output_texts'].bytes_list.value.append(\n",
        "          'All ones.'.encode()\n",
        "      )\n",
        "      writer.write(value.SerializeToString())\n",
        "  finally:\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht6LyUHjOq4C"
      },
      "outputs": [],
      "source": [
        "filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb7R8sJlN5-w"
      },
      "outputs": [],
      "source": [
        "# @title Read ArrayRecords with TF Example\n",
        "\n",
        "reader = array_record_module.ArrayRecordReader(filenames[0])\n",
        "vqa_content = iter(example_pb2.Example.FromString(r) for r in reader.read_all())\n",
        "\n",
        "def get_vqa_sample_data_point():\n",
        "  \"\"\"Returns tuple (question str, image bytes, answer str).\"\"\"\n",
        "  vqa_example = next(vqa_content)\n",
        "  return (\n",
        "      vqa_example.features.feature[\"input_texts\"]\n",
        "      .bytes_list.value[0]\n",
        "      .decode(\"utf-8\"),\n",
        "      vqa_example.features.feature[\"input_images\"].bytes_list.value[0],\n",
        "      vqa_example.features.feature[\"output_texts\"]\n",
        "      .bytes_list.value[0]\n",
        "      .decode(\"utf-8\"),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRBoecjMN6MC"
      },
      "outputs": [],
      "source": [
        "input_text, input_image, output_text = get_vqa_sample_data_point()\n",
        "\n",
        "print(f\"Question: {input_text}\")\n",
        "display(Image.open(BytesIO(input_image)))\n",
        "print(f\"Response: {output_text}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1j7RuaX089WvX_vcHHJI5xWoY6j8vH2GJ",
          "timestamp": 1740525945795
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
