{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHOrMYI2BlSL"
      },
      "source": [
        "# LSM XM Metrics Reader\n",
        "\n",
        "This notebook gives a generic interfce to grab an XM job and its associated metrics, and convert it to a tablular form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zvGLQCTxTy48"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bJfw9lT9B34z"
      },
      "outputs": [],
      "source": [
        "# @title Plot Formatting\n",
        "\n",
        "MEDIUM_SIZE = 18\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = MEDIUM_SIZE\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ig-LwzuqCCBM"
      },
      "outputs": [],
      "source": [
        "# @title Set Up\n",
        "\n",
        "# Setup XM Client\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TZQ46No1CSDw"
      },
      "outputs": [],
      "source": [
        "# @title Metrics\n",
        "\n",
        "# @title Metrics and Field Names\n",
        "\n",
        "# Get metric names.\n",
        "metric_names = [\n",
        "    # Generic Metrics\n",
        "    'train_loss',\n",
        "    'valid_loss',\n",
        "\n",
        "    # Classification Metrics\n",
        "    'train_accuracy',\n",
        "    'train_balanced_accuracy',\n",
        "    'train_f1_score',\n",
        "    'train_mAP',\n",
        "    'train_AP',\n",
        "\n",
        "    'valid_accuracy',\n",
        "    'valid_balanced_accuracy',\n",
        "    'valid_f1_score',\n",
        "    'valid_mAP',\n",
        "    'valid_AP',\n",
        "\n",
        "    # Generative Task Metrics\n",
        "    # TODO(girishvn): Add generative metrics here (e.g. random impute / impute / forecast / etc. MAE / MSE / etc.)\n",
        "]\n",
        "\n",
        "meta_data_name = [\n",
        "    'num_trainable_params',\n",
        "    'core_hours',\n",
        "    'examples_seen',\n",
        "    'gflops',\n",
        "]\n",
        "\n",
        "data_field_names = meta_data_name + metric_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9yqQ22t8CXUA"
      },
      "outputs": [],
      "source": [
        "# @title Helpers\n",
        "\n",
        "def read_xm_series_metrics(\n",
        "    example_xid, metric_name, unit_id, lowest=False\n",
        "):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if metric_name == series.label:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      steps = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "        steps.append(measurement.step)\n",
        "\n",
        "      # If return the lowest value.\n",
        "      if lowest:\n",
        "        min_arg = np.argmin(all_measurements)\n",
        "        min_val = all_measurements[min_arg]\n",
        "        min_step = steps[min_arg]\n",
        "        return min_val, min_step, series.label\n",
        "\n",
        "      # Else return the entire series\n",
        "      else:\n",
        "        return all_measurements, steps, series.label\n",
        "\n",
        "  # If not found\n",
        "  return None, None, metric_name\n",
        "\n",
        "\n",
        "def add_min_columns(df):\n",
        "  # Function to calculate the minimum value in each list\n",
        "  def min_of_list(lst):\n",
        "    return min(lst)\n",
        "\n",
        "  def min_idx_of_list(lst):\n",
        "    min_idx = np.argmin(lst)\n",
        "    return min_idx\n",
        "\n",
        "  def last_of_list(lst):\n",
        "    return lst[-1]\n",
        "\n",
        "  # Calculate minimum values and add as new columns\n",
        "  for col in df.columns:\n",
        "    if 'error' in col:\n",
        "      new_col_name = 'min_' + col\n",
        "      new_col_name_idx = 'min_idx_' + col\n",
        "      min_val = df[col].apply(min_of_list)\n",
        "      min_val_idx = df[col].apply(min_idx_of_list)\n",
        "      df[new_col_name] = min_val\n",
        "      df[new_col_name_idx] = min_val_idx\n",
        "\n",
        "      new_col_name = 'final_' + col\n",
        "      df[new_col_name] = df[col].apply(last_of_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def add_better_col_names(df):\n",
        "\n",
        "  def patch_col_name(patch_size):\n",
        "    return f'{patch_size[0]}x{patch_size[1]}'\n",
        "\n",
        "  for col in df.columns:\n",
        "    if col == 'config.model.patches.size':\n",
        "      df['patch_size'] = df[col].apply(patch_col_name)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_metrics_df(xm_dict, data_field_names):\n",
        "\n",
        "  # Get all metrics.\n",
        "  xm_exp_dict = collections.defaultdict(list)\n",
        "  # Iterate through XIDs\n",
        "  for xid, xid_added_constants in xm_dict.items():\n",
        "\n",
        "    # Setup.\n",
        "    experiment = xm_client.get_experiment(xid)\n",
        "    num_of_units = experiment.get_num_work_units()\n",
        "\n",
        "    # Iterate through job WIDs\n",
        "    for wid in range(1, num_of_units + 1):\n",
        "\n",
        "      # Add constant values\n",
        "      xm_exp_dict['xid'].append(xid)  # add xid\n",
        "      xm_exp_dict['wid'].append(wid)  # add wid\n",
        "      xm_exp_dict.update(xid_added_constants)  # add hardcoded xid constants\n",
        "\n",
        "      # Get info from XM API\n",
        "      work_unit = experiment.get_work_unit(wid)  # work info\n",
        "      key_list = work_unit.parameters.keys()  # work unit parameters\n",
        "\n",
        "      # Get params (often defined as hyperparameters)\n",
        "      for param_name in key_list:\n",
        "        xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "\n",
        "      # Get XM metrics\n",
        "      steps_super_set = []\n",
        "      for metric in data_field_names:\n",
        "        metric_val, metric_steps, metric_name = read_xm_series_metrics(\n",
        "            xid, metric, wid, lowest=False\n",
        "        )\n",
        "        if metric_val is not None:\n",
        "          xm_exp_dict[metric_name].append(metric_val)\n",
        "          xm_exp_dict[f'steps_{metric_name}'].append(metric_steps)\n",
        "          steps_super_set += metric_steps\n",
        "\n",
        "      steps_super_set = sorted(list(set(steps_super_set)))\n",
        "      xm_exp_dict['steps'].append(steps_super_set)\n",
        "\n",
        "\n",
        "  # Generate dataframe\n",
        "  df = pd.DataFrame(xm_exp_dict)\n",
        "  df = add_min_columns(df)\n",
        "  df = add_better_col_names(df)\n",
        "\n",
        "  # If a column list is of length 1, simply use the scalar value.\n",
        "  df = df.map(lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_step_df(df, step, data_field_names):\n",
        "\n",
        "  # Setup\n",
        "  step_df = df.copy()\n",
        "  df_cols = list(step_df.columns)\n",
        "  metric_cols = list(set(data_field_names) \u0026 set(df_cols))\n",
        "  metric_cols.append('steps')\n",
        "\n",
        "  # Get step to use\n",
        "  steps = step_df['steps'][0]\n",
        "\n",
        "  # Edge cases\n",
        "  if step == -1:\n",
        "    step = steps[-1]\n",
        "  elif step == 0:\n",
        "    step = steps[0]\n",
        "\n",
        "  # Ensure step exist\n",
        "  if step not in steps:\n",
        "    raise ValueError(f'Step {step} not in {steps}')\n",
        "\n",
        "  # Update columns\n",
        "  for col in metric_cols:\n",
        "      if 'steps' in col:\n",
        "        continue\n",
        "\n",
        "      step_col_name = f'steps_{col}'\n",
        "      col_steps = step_df[step_col_name][0]\n",
        "\n",
        "      if not isinstance(col_steps, list):\n",
        "        continue\n",
        "\n",
        "      try:\n",
        "        step_idx = np.argwhere(np.array(col_steps) == step)[0][0]\n",
        "      except:\n",
        "        step_idx = None\n",
        "\n",
        "      step_df[col] = step_df[col].apply(\n",
        "          lambda x: x[step_idx]\n",
        "          if (isinstance(x, list) and (step_idx is not None))\n",
        "          else None\n",
        "      )\n",
        "\n",
        "  for col in df_cols:\n",
        "    if 'steps' in col:\n",
        "      # Drop step column\n",
        "      step_df = step_df.drop(columns=col)\n",
        "\n",
        "  return step_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzW2kuEiGGgH"
      },
      "source": [
        "# Metric Retrieval / Formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9hMTW4mBxLHB"
      },
      "outputs": [],
      "source": [
        "# @title Get All Metrics\n",
        "\n",
        "\n",
        "XID_WID_DICT = {\n",
        "    157571037 : {\n",
        "        'method': 'LSM_v2'\n",
        "    }\n",
        "}\n",
        "\n",
        "metrics_df = get_metrics_df(XID_WID_DICT, data_field_names)\n",
        "metrics_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KjEHs0sd--nP"
      },
      "outputs": [],
      "source": [
        "# @title Get Single Step Metrics\n",
        "\n",
        "# Set step = 0 for first step\n",
        "# Set step = -1 for the last step\n",
        "\n",
        "step = 26\n",
        "\n",
        "df_step = get_step_df(metrics_df, step, data_field_names)\n",
        "df_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOINN6MPC_U-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1OC0XqxPTegCa8DjQ2stTJT9ms3N6U-Dy",
          "timestamp": 1744045626132
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
