{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_2cKO5pj9bE"
      },
      "source": [
        "## LSM Embedding Analysis\n",
        "##### Colab Kernel (Brainframe GPU)\n",
        "##### Dataset (Electrodes)\n",
        "\n",
        "Grants command for Access on Demand (AoD):\n",
        "\n",
        "https://grants.corp.google.com/#/grants?request=20h%2Fchr-ards-electrodes-deid-colab-jobs\u0026reason=b%2F314799341\n",
        "\n",
        "### About This Notebook:\n",
        "Visualizes embeddings, of training data, produced by the ViT MAE encoder.\n",
        "This notebook explores the affect of two pre-train data sizes (1K, 1.3M) and the affect fine-tuning as compared to the pre-trained embedding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3S5-w6LK23"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w3x__zT2WTjS"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import os\n",
        "import collections\n",
        "from collections import Counter\n",
        "import itertools\n",
        "from typing import Sequence\n",
        "\n",
        "import jax.numpy as jnp\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "\n",
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "from google3.pyglib import gfile\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQqEBGHCa8gR"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ckuLRZX-6g2H"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Plotting Helper Functions\n",
        "\n",
        "# Helper Functions\n",
        "def plot_embeddings(Xd, yd, colors, names):\n",
        "  if len(names) != len(colors):\n",
        "    raise ValueError(f'names ({len(names)}) and colors ({len(colors)}) must have the same length.')\n",
        "\n",
        "  # # PCA\n",
        "  # pca = PCA()\n",
        "  # pipe = Pipeline([('scaler', StandardScaler()), ('pca', pca)])\n",
        "  # plt.figure(figsize=(8,6))\n",
        "  # Xt = pipe.fit_transform(Xd)\n",
        "  # plot = plt.scatter(Xt[:,2], Xt[:,3], c=yd);\n",
        "  # plt.xlabel('PCA Dim 1')\n",
        "  # plt.ylabel('PCA Dim 2')\n",
        "  # plt.legend(\n",
        "  #     handles=plot.legend_elements()[0],\n",
        "  #     labels=names,\n",
        "  #     loc='upper left',\n",
        "  #     bbox_to_anchor=(1, 1)\n",
        "  # );\n",
        "  # plt.show()\n",
        "  # print('\\n\\n')\n",
        "\n",
        "\n",
        "  # # LDA\n",
        "  # clf = LDA()\n",
        "  # clf.fit(Xd, yd)\n",
        "  # lda = LDA(n_components=None, priors=None, shrinkage=None, solver='svd',store_covariance=False, tol=0.0001)\n",
        "  # X_r2 = lda.fit(Xd, yd).transform(Xd)\n",
        "\n",
        "  # plt.figure(figsize=(8,6))\n",
        "  # for i in range(len(names)):\n",
        "  #   plt.scatter(X_r2[yd == i, 0], X_r2[yd == i, 1], label=names[i], alpha=0.3, c=colors[i])\n",
        "\n",
        "  # plt.xlabel('LDA Dim 1')\n",
        "  # plt.ylabel('LDA Dim 2')\n",
        "  # plt.legend(\n",
        "  #     loc='upper left',\n",
        "  #     bbox_to_anchor=(1, 1),\n",
        "  #     shadow=False,\n",
        "  #     scatterpoints=1\n",
        "  # );\n",
        "  # plt.show()\n",
        "  # print('\\n\\n')\n",
        "\n",
        "\n",
        "  # # LDA 1D Distributions\n",
        "  # plt.figure(figsize=(8,6))\n",
        "  # for i in range(len(names)):\n",
        "  #   plt.hist(X_r2[yd == i, 0],20, density=True, label=names[i], alpha=0.5, color=colors[i])\n",
        "\n",
        "  # plt.xlabel('LDA Dim 1')\n",
        "  # plt.ylabel('Frac. of Examples Per Class')\n",
        "  # plt.legend(\n",
        "  #     loc='upper left',\n",
        "  #     bbox_to_anchor=(1, 1),\n",
        "  #     shadow=False,\n",
        "  #     scatterpoints=1\n",
        "  # );\n",
        "  # plt.show()\n",
        "\n",
        "\n",
        "  # TSNE\n",
        "  tsne = TSNE(n_components=2, random_state=0)\n",
        "  Xt = tsne.fit_transform(Xd)\n",
        "\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  for i in range(len(names)):\n",
        "    plt.scatter(Xt[yd == i, 0], Xt[yd == i, 1], label=names[i], alpha=0.3, c=colors[i])\n",
        "\n",
        "  plt.xlabel('t-SNE Dim 1')\n",
        "  plt.ylabel('t-SNE Dim 2')\n",
        "  plt.legend(\n",
        "      loc='upper left',\n",
        "      bbox_to_anchor=(1, 1),\n",
        "      shadow=False,\n",
        "      scatterpoints=1\n",
        "  );\n",
        "  plt.show()\n",
        "\n",
        "  return Xt\n",
        "\n",
        "\n",
        "def reshape_time_crop_patch_embeddings(\n",
        "    x,\n",
        "    patch_reorder_shape,\n",
        "    start=None,\n",
        "    end=None,\n",
        "):\n",
        "  \"\"\"Reshape n_token embeddeding into an image of embeddedings.\"\"\"\n",
        "  # Get patch and input shape.\n",
        "  n_h, n_w = patch_reorder_shape\n",
        "  n_batch, n_tokens, embedding_dim = x.shape  # pylint: disable=unused-variable\n",
        "\n",
        "  # Get start and end crop (along time axis).\n",
        "  if end is None:\n",
        "    end = 1\n",
        "  if start is None:\n",
        "    start = 0\n",
        "  if start \u003e= end:\n",
        "    raise ValueError(f'start {start}, is greater than end {end}.')\n",
        "  if start \u003e 1 or end \u003e 1:\n",
        "    raise ValueError(f'start {start} and end {end} cannot be greater than 1.')\n",
        "\n",
        "  # reorganize patches into image:\n",
        "  x = jnp.reshape(x, [n_batch, n_h, n_w, embedding_dim])\n",
        "\n",
        "  # Time Crop image based on horizon\n",
        "  start_idx = int(start * n_h)\n",
        "  end_idx = int(end * n_h)\n",
        "  x = x[:, start_idx:end_idx, :, :]\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "egJ3ll__Ii7C"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Constants and Setup\n",
        "\n",
        "# Constants\n",
        "# Feature names in order.\n",
        "ALL_FEATURE_NAMES = ['sclValue', 'sclSlope', 'skinTempValue',\n",
        "                    'hr', 'hrvPercentGood','hrvRR80thPercentile', 'hrvRR20thPercentile',\n",
        "                    'hrvRRMedian', 'hrvRRMean', 'hrvShannonEntropyRR', 'hrvShannonEntropyRRDiffs',\n",
        "                    'hrvPNN30', 'hrvRMSSD', 'hrvSDNN', 'sleepCoefficient', 'onWrist',\n",
        "                    'jerkAuto', 'stepCount', 'logEnergy', 'grok_covariance', 'logEnergyRatio',\n",
        "                    'zeroCrossingStd', 'zeroCrossingAvg', 'axisMean', 'altimStdNorm', 'grok_kurtosis']\n",
        "\n",
        "# All activity names and their corresponding activity ID.\n",
        "actDict = {'Yoga': 52000, 'Pilates': 53000, 'Bike':90001,\n",
        "            'Run':90009,'Hike':90012,'Walk':90013,'Elliptical':90017,'Treadmill':90019,\n",
        "            'Swim':90024,'HIIT':91040,'Weightlifting':91043,'Core training':91046}\n",
        "\n",
        "# Activities and the index that are represented by in an OHE label.\n",
        "actOHEDict = {\n",
        "    'Weightlifting': 0, 'Swim': 1, 'Elliptical': 2, 'Walk': 3,\n",
        "    'Run': 4, 'Bike': 5, 'HIIT': 6, 'Strength training': 7\n",
        "}\n",
        "\n",
        "# Pretrain data sizes.\n",
        "datasizes = [1000, 10000, 100000, 750000, 1321235]\n",
        "\n",
        "# XM Dict of Embedding Dump Jobs:\n",
        "embedding_dump_xm_dict = {\n",
        "    # Train size: 1.3 M\n",
        "    '126388131/1': {\n",
        "        'pretrain_datasize': 1321235,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'linear_probe'\n",
        "    },\n",
        "\n",
        "    # Train size: 750 K\n",
        "    '127490536/4': {\n",
        "        'pretrain_datasize': 750000,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'linear_probe'\n",
        "    },\n",
        "\n",
        "    # Train size: 100 K\n",
        "    '127490536/3': {\n",
        "        'pretrain_datasize': 100000,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'linear_probe'\n",
        "    },\n",
        "\n",
        "    # Train size: 10 K\n",
        "    '127490536/2': {\n",
        "        'pretrain_datasize': 10000,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'linear_probe'\n",
        "    },\n",
        "\n",
        "    # Train size: 1 K\n",
        "    '127490536/1': {\n",
        "        'pretrain_datasize': 1000,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'linear_probe'\n",
        "    },\n",
        "}\n",
        "\n",
        "# XM Dict of Embedding Dump Jobs:\n",
        "finetune_embedding_dump_xm_dict = {\n",
        "    # Train size: 1.3 M\n",
        "    '126268296/1': {\n",
        "        'pretrain_datasize': 1321235,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'finetune'\n",
        "    },\n",
        "\n",
        "    # Train size: 1 K\n",
        "    '127526958/1': {\n",
        "        'pretrain_datasize': 1000,\n",
        "        'pretrain_step': 50000,\n",
        "        'ft_step': 300,\n",
        "        'ft_probe': 'finetune'\n",
        "    },\n",
        "}\n",
        "\n",
        "# Setup XM Client\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F27gkW42RjQG"
      },
      "source": [
        "## Non-Finetune 1.3M Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MJtQq4SxJpFJ"
      },
      "outputs": [],
      "source": [
        "# @title Load Embeddings (~20 mins to load embeddings to RAM).\n",
        "\n",
        "# A full list of these XID / WID pairs can be found in constants\n",
        "xid_wid = '126388131/1'\n",
        "\n",
        "file_name = os.path.join('/cns/dz-d/home/xliucs/lsm/xm/', xid_wid)\n",
        "# embedding_dump_fname = os.path.join(file_name, f'full_train_embeddeding_300.npy')\n",
        "embedding_dump_fname = os.path.join(file_name, f'pooled_train_embeddeding_300.npy')\n",
        "metadata_name = os.path.join(file_name, f'metadata_300.npy')\n",
        "\n",
        "print('Reading Full (Pooled) Embedding File:', embedding_dump_fname)\n",
        "with gfile.Open(embedding_dump_fname, 'rb') as f:\n",
        "  embedding_arr = np.load(f)\n",
        "\n",
        "print('Reading Metadata File:', metadata_name)\n",
        "with gfile.Open(metadata_name, 'rb') as f:\n",
        "  metadata_arr = np.load(f)\n",
        "\n",
        "print('\\nPooled Embedding shape', embedding_arr.shape)\n",
        "print('Metadata shape', metadata_arr.shape)\n",
        "\n",
        "# Parse meta data\n",
        "targets = metadata_arr[0, :]\n",
        "preds = metadata_arr[1, :]\n",
        "subj_id = metadata_arr[2, :]\n",
        "age = metadata_arr[3, :]\n",
        "weight = metadata_arr[4, :]\n",
        "gender = metadata_arr[5, :]\n",
        "\n",
        "# Setup\n",
        "labels = targets.tolist()\n",
        "print(f'\\nTotal Count {len(labels)}\\n')\n",
        "y, X = [], []\n",
        "for actName, act in actOHEDict.items():\n",
        "  indices = [i for i, x in enumerate(labels) if x == act]\n",
        "  print(actName, str(len(indices)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QI83GKVp99rK"
      },
      "outputs": [],
      "source": [
        "# @title (UNUSED) Crop and Pool Embeddings\n",
        "# NOTE: This is to be used if you are loading the FULL (unpooled) embeddings.\n",
        "# This can then be used to reshape the spatio-temporal characteristics of the\n",
        "# patches, and then select a time window of interest.\n",
        "\n",
        "# Xd = embedding_arr\n",
        "\n",
        "# # Each 0.1 of [start, end] represents 30 mins.\n",
        "# # Eg. 1: [start, end] = [0.8, 0.9] = [240 min, 270 min]\n",
        "# # Eg. 2: [start, end] = [None, None] = [0, 1] = [0 min, 300 min]\n",
        "# # A single patch is 0.033333 = 10 mins\n",
        "# start = None\n",
        "# end = None\n",
        "\n",
        "# print('Full Embedding shape', Xd.shape)\n",
        "# # Takes the embeddings from the last (end - start) percentage of 300 min window.\n",
        "# Xd = reshape_time_crop_patch_embeddings(Xd, patch_reorder_shape=(30, 6), start=start, end=end)\n",
        "# print('Cropped Embedding shape', Xd.shape)\n",
        "# # These selected embeddings are average pooled.\n",
        "# Xd = np.mean(Xd, axis=(1, 2))\n",
        "# print('Pooled Embedding shape', Xd.shape)\n",
        "# Xd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I5V6__n9Jy9N"
      },
      "outputs": [],
      "source": [
        "# @title ACTIVITY RECOGNITION\n",
        "\n",
        "Xd = embedding_arr\n",
        "yd = targets\n",
        "names = list(actOHEDict.keys())\n",
        "colors = sns.color_palette(\"Set2\", n_colors=8).as_hex()\n",
        "embedding_xt_1M = plot_embeddings(Xd, yd, colors, names)\n",
        "yd_1M = yd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WnAIOZhearIW"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Quality\n",
        "\n",
        "# get kmeans\n",
        "num_classes = 8\n",
        "kmeans_1M = KMeans(n_clusters=8, random_state=42).fit_predict(embedding_xt_1M)\n",
        "\n",
        "sil_score = silhouette_score(embedding_xt_1M, kmeans_1M)\n",
        "db_score = davies_bouldin_score(embedding_xt_1M, kmeans_1M)\n",
        "ch_score = calinski_harabasz_score(embedding_xt_1M, kmeans_1M)\n",
        "ari = adjusted_rand_score(yd_1M, kmeans_1M)\n",
        "nmi = normalized_mutual_info_score(yd_1M, kmeans_1M)\n",
        "\n",
        "print('1.3 M Pretrain / No Finetune')\n",
        "print(f\"Silhouette Score: {sil_score}\")\n",
        "print(f\"Davies-Bouldin Score: {db_score}\")\n",
        "print(f\"Calinski-Harabasz Score: {ch_score}\")\n",
        "print(f\"Adjusted Rand Index: {ari}\")\n",
        "print(f\"Normalized Mutual Information: {nmi}\")\n",
        "\n",
        "data = [\n",
        "    ['Silhouette Score', sil_score],\n",
        "    ['Davies-Bouldin Score', db_score],\n",
        "    ['Calinski-Harabasz Score', ch_score],\n",
        "    ['Adjusted Rand Index', ari],\n",
        "    ['Normalized Mutual Information', nmi],\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Metric', 'Value'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqdIRa7fRmzV"
      },
      "source": [
        "## Non-Finetune 1K Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7NsSVztMRo3D"
      },
      "outputs": [],
      "source": [
        "# @title Load Embeddings (~20 mins to load embeddings to RAM).\n",
        "\n",
        "# A full list of these XID / WID pairs can be found in constants\n",
        "xid_wid = '127490536/1'\n",
        "\n",
        "file_name = os.path.join('/cns/dz-d/home/xliucs/lsm/xm/', xid_wid)\n",
        "# embedding_dump_fname = os.path.join(file_name, f'full_train_embeddeding_300.npy')\n",
        "embedding_dump_fname = os.path.join(file_name, f'pooled_train_embeddeding_300.npy')\n",
        "metadata_name = os.path.join(file_name, f'metadata_300.npy')\n",
        "\n",
        "print('Reading Full (Pooled) Embedding File:', embedding_dump_fname)\n",
        "with gfile.Open(embedding_dump_fname, 'rb') as f:\n",
        "  embedding_arr = np.load(f)\n",
        "\n",
        "print('Reading Metadata File:', metadata_name)\n",
        "with gfile.Open(metadata_name, 'rb') as f:\n",
        "  metadata_arr = np.load(f)\n",
        "\n",
        "print('\\nPooled Embedding shape', embedding_arr.shape)\n",
        "print('Metadata shape', metadata_arr.shape)\n",
        "\n",
        "# Parse meta data\n",
        "targets = metadata_arr[0, :]\n",
        "preds = metadata_arr[1, :]\n",
        "subj_id = metadata_arr[2, :]\n",
        "age = metadata_arr[3, :]\n",
        "weight = metadata_arr[4, :]\n",
        "gender = metadata_arr[5, :]\n",
        "\n",
        "# Setup\n",
        "labels = targets.tolist()\n",
        "print(f'\\nTotal Count {len(labels)}\\n')\n",
        "y, X = [], []\n",
        "for actName, act in actOHEDict.items():\n",
        "  indices = [i for i, x in enumerate(labels) if x == act]\n",
        "  print(actName, str(len(indices)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TEfgKh1zSVPO"
      },
      "outputs": [],
      "source": [
        "# @title ACTIVITY RECOGNITION\n",
        "\n",
        "Xd = embedding_arr\n",
        "yd = targets\n",
        "names = list(actOHEDict.keys())\n",
        "colors = sns.color_palette(\"Set2\", n_colors=8).as_hex()\n",
        "embedding_xt_1K = plot_embeddings(Xd, yd, colors, names)\n",
        "yd_1K = yd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iSiCAlBMcrHm"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Quality\n",
        "\n",
        "num_classes = 8\n",
        "kmeans_1K = KMeans(n_clusters=8, random_state=42).fit_predict(embedding_xt_1K)\n",
        "\n",
        "sil_score = silhouette_score(embedding_xt_1K, kmeans_1K)\n",
        "db_score = davies_bouldin_score(embedding_xt_1K, kmeans_1K)\n",
        "ch_score = calinski_harabasz_score(embedding_xt_1K, kmeans_1K)\n",
        "ari = adjusted_rand_score(yd_1K, kmeans_1K)\n",
        "nmi = normalized_mutual_info_score(yd_1K, kmeans_1K)\n",
        "\n",
        "print('1.3 M Pretrain / No Finetune')\n",
        "print(f\"Silhouette Score: {sil_score}\")\n",
        "print(f\"Davies-Bouldin Score: {db_score}\")\n",
        "print(f\"Calinski-Harabasz Score: {ch_score}\")\n",
        "print(f\"Adjusted Rand Index: {ari}\")\n",
        "print(f\"Normalized Mutual Information: {nmi}\")\n",
        "\n",
        "data = [\n",
        "    ['Silhouette Score', sil_score],\n",
        "    ['Davies-Bouldin Score', db_score],\n",
        "    ['Calinski-Harabasz Score', ch_score],\n",
        "    ['Adjusted Rand Index', ari],\n",
        "    ['Normalized Mutual Information', nmi],\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Metric', 'Value'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJgD52OZWoBq"
      },
      "source": [
        "## Finetune 1.3M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RlUCfuHAWpk-"
      },
      "outputs": [],
      "source": [
        "# @title Load Embeddings.\n",
        "\n",
        "# A full list of these XID / WID pairs can be found in constants\n",
        "xid_wid = '126268296/1'\n",
        "\n",
        "file_name = os.path.join('/cns/dz-d/home/xliucs/lsm/xm/', xid_wid)\n",
        "# embedding_dump_fname = os.path.join(file_name, f'full_train_embeddeding_300.npy')\n",
        "embedding_dump_fname = os.path.join(file_name, f'pooled_train_embeddeding_300.npy')\n",
        "metadata_name = os.path.join(file_name, f'metadata_300.npy')\n",
        "\n",
        "print('Reading Full (Pooled) Embedding File:', embedding_dump_fname)\n",
        "with gfile.Open(embedding_dump_fname, 'rb') as f:\n",
        "  embedding_arr = np.load(f)\n",
        "\n",
        "print('Reading Metadata File:', metadata_name)\n",
        "with gfile.Open(metadata_name, 'rb') as f:\n",
        "  metadata_arr = np.load(f)\n",
        "\n",
        "print('\\nPooled Embedding shape', embedding_arr.shape)\n",
        "print('Metadata shape', metadata_arr.shape)\n",
        "\n",
        "# Parse meta data\n",
        "targets = metadata_arr[0, :]\n",
        "preds = metadata_arr[1, :]\n",
        "subj_id = metadata_arr[2, :]\n",
        "age = metadata_arr[3, :]\n",
        "weight = metadata_arr[4, :]\n",
        "gender = metadata_arr[5, :]\n",
        "\n",
        "# Setup\n",
        "labels = targets.tolist()\n",
        "print(f'\\nTotal Count {len(labels)}\\n')\n",
        "y, X = [], []\n",
        "for actName, act in actOHEDict.items():\n",
        "  indices = [i for i, x in enumerate(labels) if x == act]\n",
        "  print(actName, str(len(indices)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RW_lA2IKWzFn"
      },
      "outputs": [],
      "source": [
        "# @title ACTIVITY RECOGNITION\n",
        "\n",
        "Xd = embedding_arr\n",
        "yd = targets\n",
        "names = list(actOHEDict.keys())\n",
        "colors = sns.color_palette(\"Set2\", n_colors=8).as_hex()\n",
        "embedding_xt_FT_1M = plot_embeddings(Xd, yd, colors, names)\n",
        "\n",
        "yd_FT_1M = yd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n0BGJ80LmzYD"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Quality\n",
        "\n",
        "# get kmeans\n",
        "num_classes = 8\n",
        "kmeans_FT_1M = KMeans(n_clusters=8, random_state=42).fit_predict(embedding_xt_FT_1M)\n",
        "\n",
        "sil_score = silhouette_score(embedding_xt_FT_1M, kmeans_FT_1M)\n",
        "db_score = davies_bouldin_score(embedding_xt_FT_1M, kmeans_FT_1M)\n",
        "ch_score = calinski_harabasz_score(embedding_xt_FT_1M, kmeans_FT_1M)\n",
        "ari = adjusted_rand_score(yd_FT_1M, kmeans_FT_1M)\n",
        "nmi = normalized_mutual_info_score(yd_FT_1M, kmeans_FT_1M)\n",
        "\n",
        "print('1.3 M Pretrain / No Finetune')\n",
        "print(f\"Silhouette Score: {sil_score}\")\n",
        "print(f\"Davies-Bouldin Score: {db_score}\")\n",
        "print(f\"Calinski-Harabasz Score: {ch_score}\")\n",
        "print(f\"Adjusted Rand Index: {ari}\")\n",
        "print(f\"Normalized Mutual Information: {nmi}\")\n",
        "\n",
        "data = [\n",
        "    ['Silhouette Score', sil_score],\n",
        "    ['Davies-Bouldin Score', db_score],\n",
        "    ['Calinski-Harabasz Score', ch_score],\n",
        "    ['Adjusted Rand Index', ari],\n",
        "    ['Normalized Mutual Information', nmi],\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Metric', 'Value'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MlwoKgYbkgO"
      },
      "source": [
        "## Finetune 1K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "06GMgyjcbl8-"
      },
      "outputs": [],
      "source": [
        "# @title Load Embeddings.\n",
        "\n",
        "# A full list of these XID / WID pairs can be found in constants\n",
        "xid_wid = '127526958/1'\n",
        "\n",
        "file_name = os.path.join('/cns/dz-d/home/xliucs/lsm/xm/', xid_wid)\n",
        "# embedding_dump_fname = os.path.join(file_name, f'full_train_embeddeding_300.npy')\n",
        "embedding_dump_fname = os.path.join(file_name, f'pooled_train_embeddeding_300.npy')\n",
        "metadata_name = os.path.join(file_name, f'metadata_300.npy')\n",
        "\n",
        "print('Reading Full (Pooled) Embedding File:', embedding_dump_fname)\n",
        "with gfile.Open(embedding_dump_fname, 'rb') as f:\n",
        "  embedding_arr = np.load(f)\n",
        "\n",
        "print('Reading Metadata File:', metadata_name)\n",
        "with gfile.Open(metadata_name, 'rb') as f:\n",
        "  metadata_arr = np.load(f)\n",
        "\n",
        "print('\\nPooled Embedding shape', embedding_arr.shape)\n",
        "print('Metadata shape', metadata_arr.shape)\n",
        "\n",
        "# Parse meta data\n",
        "targets = metadata_arr[0, :]\n",
        "preds = metadata_arr[1, :]\n",
        "subj_id = metadata_arr[2, :]\n",
        "age = metadata_arr[3, :]\n",
        "weight = metadata_arr[4, :]\n",
        "gender = metadata_arr[5, :]\n",
        "\n",
        "# Setup\n",
        "labels = targets.tolist()\n",
        "print(f'\\nTotal Count {len(labels)}\\n')\n",
        "y, X = [], []\n",
        "for actName, act in actOHEDict.items():\n",
        "  indices = [i for i, x in enumerate(labels) if x == act]\n",
        "  print(actName, str(len(indices)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x2PePtZb5FyB"
      },
      "outputs": [],
      "source": [
        "# @title ACTIVITY RECOGNITION\n",
        "\n",
        "Xd = embedding_arr\n",
        "yd = targets\n",
        "names = list(actOHEDict.keys())\n",
        "colors = sns.color_palette(\"Set2\", n_colors=8).as_hex()\n",
        "embedding_xt_FT_1K = plot_embeddings(Xd, yd, colors, names)\n",
        "yd_FT_1K = yd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5TKG3ZLr5NLF"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Quality\n",
        "\n",
        "# get kmeans\n",
        "num_classes = 8\n",
        "kmeans_FT_1K = KMeans(n_clusters=8, random_state=42).fit_predict(embedding_xt_FT_1K)\n",
        "\n",
        "sil_score = silhouette_score(embedding_xt_FT_1K, kmeans_FT_1K)\n",
        "db_score = davies_bouldin_score(embedding_xt_FT_1K, kmeans_FT_1K)\n",
        "ch_score = calinski_harabasz_score(embedding_xt_FT_1K, kmeans_FT_1K)\n",
        "ari = adjusted_rand_score(yd_FT_1K, kmeans_FT_1K)\n",
        "nmi = normalized_mutual_info_score(yd_FT_1K, kmeans_FT_1K)\n",
        "\n",
        "print('1.3 M Pretrain / No Finetune')\n",
        "print(f\"Silhouette Score: {sil_score}\")\n",
        "print(f\"Davies-Bouldin Score: {db_score}\")\n",
        "print(f\"Calinski-Harabasz Score: {ch_score}\")\n",
        "print(f\"Adjusted Rand Index: {ari}\")\n",
        "print(f\"Normalized Mutual Information: {nmi}\")\n",
        "\n",
        "data = [\n",
        "    ['Silhouette Score', sil_score],\n",
        "    ['Davies-Bouldin Score', db_score],\n",
        "    ['Calinski-Harabasz Score', ch_score],\n",
        "    ['Adjusted Rand Index', ari],\n",
        "    ['Normalized Mutual Information', nmi],\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Metric', 'Value'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8X8TNwVl3nI"
      },
      "source": [
        "# SANDBOX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYSy_KEDl3Ta"
      },
      "outputs": [],
      "source": [
        "# x = [1191, 152, 332, 229, 2332, 1860, 6887, 669 ]\n",
        "x = [412, 49, 104, 425, 441, 315, 1301, 98]\n",
        "total = sum(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k7gKxq3msHF"
      },
      "outputs": [],
      "source": [
        "total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvDvDteOmsva"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for i in x:\n",
        "  z = int(i/total * 10000) / 100\n",
        "  print(z)\n",
        "  count += z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwDU4cdYmwDz"
      },
      "outputs": [],
      "source": [
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9M-KkRNnEO6"
      },
      "outputs": [],
      "source": [
        "21.17 + 13.37 + 11.63 + 22.25 + 31.57"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFJM0OAZoJ_m"
      },
      "outputs": [],
      "source": [
        "20.71 + 13.22 + 12.15 + 22.04 + 31.87"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZYzJTMyojf8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BTBP0OGCK-o6",
        "ehjgkRPBJKG6"
      ],
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
