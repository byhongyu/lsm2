{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_2cKO5pj9bE"
      },
      "source": [
        "## LSM Patch Scaling and Feature Order Analysis\n",
        "##### Colab Kernel (Brainframe GPU)\n",
        "##### Dataset (Electrodes)\n",
        "\n",
        "Grants command for Access on Demand (AoD):\n",
        "\n",
        "https://grants.corp.google.com/#/grants?request=20h%2Fchr-ards-electrodes-deid-colab-jobs\u0026reason=b%2F314799341\n",
        "\n",
        "### About This Notebook:\n",
        "**Patch Scaling:** This notebook analyzes patch scaling experiments, where we test how changing the patch size along the time-axis and the feature-axis, independently, affect the overall validation loss, and the the loss on down-stream reconstruction tasks (eg. Imputation and Forecasting).\n",
        "\n",
        "**Masking Ratio Sweep.** This notebook analyzes the masking ratio and its affect on downstream tasks (eg. imputation and forecasting). We iterate over random masking (30% - 90%). And also structured masking (bar masking along the feature axis, and along the time axis) (30% - 90%)\n",
        "\n",
        "**Randomized Feature Order:** Further, this explore how ordered features (default), compare against randomized features, for the same above evaluation tasks and for the patch scaling. To specifiy: randomized features are a shuffling of feature rows. This new shuffled order is used for ALL experiments. This feature order is:\n",
        "\n",
        "`[10, 14, 22, 21, 8, 11, 5, 24, 20, 4, 17, 0, 15, 9, 7, 3, 18, 23, 2, 13, 25, 1, 6, 16, 19, 12]`\n",
        "\n",
        "and equivalently:\n",
        "\n",
        "`['hrvRRMean', 'hrvRMSSD', 'zeroCrossingStd', 'logEnergyRatio', 'hrvRR20thPercentile', 'hrvShannonEntropyRR', 'skinTempValue', 'axisMean', 'grok_covariance', 'sclSlope', 'jerkAuto', 'hrvPercentGood', 'hrvSDNN', 'hrvRRMedian', 'hrvRR80thPercentile', 'sclValue', 'stepCount', 'zeroCrossingAvg', 'altimStdNorm', 'hrvPNN30', 'grok_kurtosis', 'onWrist', 'hr', 'sleepCoefficient', 'logEnergy', 'hrvShannonEntropyRRDiffs']`\n",
        "\n",
        "This notebook draw from results from the following xmanager experiments:\n",
        "1. [Patch scaling (ordered features)](https://xmanager.corp.google.com/experiments/120664779)\n",
        "2. [Patch scaling (randomized features)](https://xmanager.corp.google.com/experiments/120685218)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w3x__zT2WTjS"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RC_E4xYL3VXV"
      },
      "outputs": [],
      "source": [
        "# @title Plot Formatting\n",
        "\n",
        "MEDIUM_SIZE = 18\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = MEDIUM_SIZE\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0bAuakU7WYXi"
      },
      "outputs": [],
      "source": [
        "# @title Helpers\n",
        "\n",
        "def read_xm_metrics(example_xid, metric_name, unit_id, lowest=True):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if series.label == metric_name:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "      if lowest:\n",
        "        return min(all_measurements)\n",
        "      else:\n",
        "        return all_measurements\n",
        "\n",
        "\n",
        "def add_min_columns(df):\n",
        "  # Function to calculate the minimum value in each list\n",
        "  def min_of_list(lst):\n",
        "    return min(lst)\n",
        "\n",
        "  def min_idx_of_list(lst):\n",
        "    min_idx = np.argmin(lst)\n",
        "    return min_idx\n",
        "\n",
        "  def last_of_list(lst):\n",
        "    return lst[-1]\n",
        "\n",
        "  # Calculate minimum values and add as new columns\n",
        "  for col in df.columns:\n",
        "    if 'error' in col:\n",
        "      new_col_name = 'min_' + col\n",
        "      new_col_name_idx = 'min_idx_' + col\n",
        "      min_val = df[col].apply(min_of_list)\n",
        "      min_val_idx = df[col].apply(min_idx_of_list)\n",
        "      df[new_col_name] = min_val\n",
        "      df[new_col_name_idx] = min_val_idx\n",
        "\n",
        "      new_col_name = 'final_' + col\n",
        "      df[new_col_name] = df[col].apply(last_of_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def add_better_col_names(df):\n",
        "\n",
        "  def patch_col_name(patch_size):\n",
        "    return f'{patch_size[0]}x{patch_size[1]}'\n",
        "\n",
        "  for col in df.columns:\n",
        "    if col == 'config.model.patches.size':\n",
        "      df['patch_size'] = df[col].apply(patch_col_name)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_metrics_df(xm_dict):\n",
        "\n",
        "  # Get all metrics.\n",
        "  xm_exp_dict = collections.defaultdict(list)\n",
        "  for xid, values in xm_dict.items():\n",
        "    model_size = values['model_size']\n",
        "    feat_order = values['feature_order']\n",
        "\n",
        "    experiment = xm_client.get_experiment(xid)\n",
        "    num_of_units = experiment.get_num_work_units()\n",
        "\n",
        "    for wid in range(1, num_of_units + 1):\n",
        "      work_unit = experiment.get_work_unit(wid)\n",
        "      key_list = work_unit.parameters.keys()\n",
        "      xm_exp_dict['wid'].append(wid)\n",
        "      xm_exp_dict['xid'].append(xid)\n",
        "\n",
        "      xm_exp_dict['Model Size'].append(model_size)\n",
        "      xm_exp_dict['Feature Order'].append(feat_order)\n",
        "\n",
        "      for param_name in key_list:\n",
        "        xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "      for metric in data_field_names:\n",
        "        xm_exp_dict[metric].append(\n",
        "            read_xm_metrics(xid, metric, wid, lowest=False)\n",
        "        )\n",
        "  df = pd.DataFrame(xm_exp_dict)\n",
        "  df = add_min_columns(df)\n",
        "  df = add_better_col_names(df)\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lmDlIpAqTOZ"
      },
      "outputs": [],
      "source": [
        "feats = ['hrvPercentGood', 'onWrist', 'altimStdNorm', 'sclValue', 'sclSlope', 'skinTempValue', 'hr', 'hrvRR80thPercentile', 'hrvRR20thPercentile', 'hrvRRMedian', 'hrvRRMean', 'hrvShannonEntropyRR', 'hrvShannonEntropyRRDiffs', 'hrvPNN30', 'hrvRMSSD', 'hrvSDNN', 'sleepCoefficient', 'jerkAuto', 'stepCount', 'logEnergy', 'grok_covariance', 'logEnergyRatio', 'zeroCrossingStd', 'zeroCrossingAvg', 'axisMean', 'grok_kurtosis']\n",
        "\n",
        "reorder_idx = [10, 14, 22, 21, 8, 11, 5, 24, 20, 4, 17, 0, 15, 9, 7, 3, 18, 23, 2, 13, 25, 1, 6, 16, 19, 12]\n",
        "\n",
        "reorder_feats = [feats[i] for i in reorder_idx]\n",
        "\n",
        "print(reorder_feats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8ixTQAGmqqEA"
      },
      "outputs": [],
      "source": [
        "# @title Metrics and Field Names\n",
        "\n",
        "# Get metric names.\n",
        "metric_names = [\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_masked',\n",
        "    'valid_mean_squared_error_all',\n",
        "    'valid_mean_squared_error_masked',\n",
        "\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "meta_data_name = [\n",
        "    'num_trainable_params',\n",
        "    'core_hours',\n",
        "    'examples_seen',\n",
        "    'gflops',\n",
        "]\n",
        "\n",
        "data_field_names = meta_data_name + metric_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-cTA1zHtzun"
      },
      "outputs": [],
      "source": [
        "# Setup XM Client\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r3JMv8Ofr5jD"
      },
      "outputs": [],
      "source": [
        "# @title Getting Base Model Default\n",
        "\n",
        "default_baase_model_xm_id_dict = {\n",
        "    124248847: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Default base model',\n",
        "    },\n",
        "}\n",
        "\n",
        "default_df = get_metrics_df(default_baase_model_xm_id_dict)\n",
        "# Filter default df for models that train on the FULL dataset (1321235)\n",
        "default_df = default_df[\n",
        "    default_df['config.dataset_configs.train_num_samples'] == 1321235\n",
        "]\n",
        "default_df['config.model.patches.size'] = [[10, 5]]  # Set the default patch size\n",
        "default_df['config.masked_feature_loss.token_mask_probability'] = 'constant_0.8'\n",
        "default_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "G_hZDzQE669d"
      },
      "outputs": [],
      "source": [
        "# @title Plotting setup (metrics, colors, legend labels)\n",
        "\n",
        "plot_metric_names = [\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "prefix = 'final_'\n",
        "imputation_palette = ['lightsteelblue', 'cornflowerblue', 'steelblue']\n",
        "forecast_palette = ['lightcoral', 'indianred', 'firebrick']\n",
        "random_fill_pallete = ['lightgray']\n",
        "color_wheel = imputation_palette + forecast_palette + random_fill_pallete\n",
        "swept_time_patch_sizes = [[5, 5], [10, 5], [20, 5], [30, 5]]\n",
        "swept_feature_patch_sizes = [[10, 2], [10, 5], [10, 10], [10, 26]]\n",
        "\n",
        "legend_list = [\n",
        "    'imputation 0.1', 'imputation 0.2', 'imputation 0.4',\n",
        "    'forecast 0.1', 'forecast 0.2', 'forecast 0.4',\n",
        "    'random fill 0.8'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzzU4UE2pRz-"
      },
      "source": [
        "## Patch Size Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-z6YVzxHpVAg"
      },
      "outputs": [],
      "source": [
        "# @title Get Patch Sweep XM Metrics\n",
        "\n",
        "# XM ID Dict\n",
        "patch_size_sweep_xm_id_dict = {\n",
        "    125205101: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Extra Small patch size sweep',\n",
        "    },\n",
        "\n",
        "    125002746: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Small patch size sweep',\n",
        "    },\n",
        "\n",
        "    125002485: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Medium patch size sweep',\n",
        "    },\n",
        "\n",
        "    125001367: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Large patch size sweep',\n",
        "    },\n",
        "}\n",
        "\n",
        "patch_sweep_df = get_metrics_df(patch_size_sweep_xm_id_dict)\n",
        "patch_sweep_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTV4hALEufX3"
      },
      "outputs": [],
      "source": [
        "sweep_df = pd.concat([patch_sweep_df, default_df], ignore_index=True, sort=False)\n",
        "sweep_df['patch_area'] = sweep_df.apply(lambda row: row['config.model.patches.size'][0] * row['config.model.patches.size'][1], axis=1)\n",
        "sweep_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944k9Gpkvxa9"
      },
      "outputs": [],
      "source": [
        "sub_df = sweep_df[[\n",
        "    'config.model.patches.size', 'gflops',\n",
        "    'final_imputation_0.1_eval/valid_mean_absolute_error_masked', 'final_imputation_0.2_eval/valid_mean_absolute_error_masked', 'final_imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_imputation_0.1_eval/valid_mean_squared_error_masked', 'final_imputation_0.2_eval/valid_mean_squared_error_masked', 'final_imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'final_forecast_0.1_eval/valid_mean_absolute_error_masked', 'final_forecast_0.2_eval/valid_mean_absolute_error_masked', 'final_forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_forecast_0.1_eval/valid_mean_squared_error_masked', 'final_forecast_0.2_eval/valid_mean_squared_error_masked', 'final_forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'final_valid_mean_squared_error_masked',\n",
        "    'final_valid_mean_absolute_error_masked',\n",
        "\n",
        "]]\n",
        "sub_df['gflops'] = sweep_df.apply(lambda row: row['gflops'][0], axis=1)\n",
        "sub_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bil00Eau6uAM"
      },
      "outputs": [],
      "source": [
        "# @title Temporal Size Sweep\n",
        "\n",
        "temporal_sweep_df = sweep_df[sweep_df['config.model.patches.size'].isin(swept_time_patch_sizes)]\n",
        "xticks = [v[0] for v in swept_time_patch_sizes]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, m in enumerate(plot_metric_names):\n",
        "\n",
        "  m = prefix + m\n",
        "\n",
        "  # patch_size =  np.array(temporal_sweep_df['patch_area'])\n",
        "  patch_size =  np.array([v[0] for v in temporal_sweep_df['config.model.patches.size']])\n",
        "  compute = np.array([v[0] for v in temporal_sweep_df['gflops']])\n",
        "  metric_vals = np.array(temporal_sweep_df[m])\n",
        "\n",
        "  sorted_idx = np.argsort(patch_size)\n",
        "  patch_size = patch_size[sorted_idx]\n",
        "  compute = compute[sorted_idx]\n",
        "  metric_vals = metric_vals[sorted_idx]\n",
        "\n",
        "  # Plot\n",
        "  plt.scatter(patch_size, metric_vals, s=compute*10, alpha=0.5, color=color_wheel[i], label=legend_list[i])\n",
        "  plt.plot(patch_size, metric_vals, linestyle='-', color=color_wheel[i], linewidth=2, label='')\n",
        "\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlabel('Time Steps / Patch')\n",
        "plt.xticks(xticks)\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.legend(loc='best', bbox_to_anchor=(1, 1.04));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CgxYrpQeufKC"
      },
      "outputs": [],
      "source": [
        "# @title Feature Size Sweep\n",
        "\n",
        "feat_sweep_df = sweep_df[sweep_df['config.model.patches.size'].isin(swept_feature_patch_sizes)]\n",
        "xticks = [v[1] for v in swept_feature_patch_sizes]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, m in enumerate(plot_metric_names):\n",
        "\n",
        "  m = prefix + m\n",
        "\n",
        "  # patch_size =  np.array(feat_sweep_df['patch_area'])\n",
        "  patch_size =  np.array([v[1] for v in feat_sweep_df['config.model.patches.size']])\n",
        "  compute = np.array([v[0] for v in feat_sweep_df['gflops']])\n",
        "  metric_vals = np.array(feat_sweep_df[m])\n",
        "\n",
        "  sorted_idx = np.argsort(patch_size)\n",
        "  patch_size = patch_size[sorted_idx]\n",
        "  compute = compute[sorted_idx]\n",
        "  metric_vals = metric_vals[sorted_idx]\n",
        "\n",
        "  # Plot\n",
        "  plt.scatter(patch_size, metric_vals, s=compute*10, alpha=0.5, color=color_wheel[i])\n",
        "  plt.plot(patch_size, metric_vals, linestyle='-', color=color_wheel[i], linewidth=2)\n",
        "\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlabel('Features / Patch')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.xticks(xticks);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-XNJWYwNQJL"
      },
      "source": [
        "## Masking Ratio Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "86qowq5Ot_kY"
      },
      "outputs": [],
      "source": [
        "# @title Random Sweep Masking Ratio\n",
        "\n",
        "mask_ratio_sweep_xm_id_dict = {\n",
        "    125004844: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'mask ratio sweep',\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "masking_sweep_df = get_metrics_df(mask_ratio_sweep_xm_id_dict)\n",
        "masking_sweep_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TbZRyS4WNjOU"
      },
      "outputs": [],
      "source": [
        "# @title Default Base Model XM\n",
        "\n",
        "sweep_df = pd.concat([masking_sweep_df, default_df], ignore_index=True, sort=False)\n",
        "sweep_df['mask_ratio'] = sweep_df.apply(lambda row: float(row['config.masked_feature_loss.token_mask_probability'][-3:]), axis=1)\n",
        "sweep_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE393MVwsD2g"
      },
      "outputs": [],
      "source": [
        "sub_df = sweep_df[[\n",
        "    'mask_ratio',\n",
        "    'final_imputation_0.1_eval/valid_mean_absolute_error_masked', 'final_imputation_0.2_eval/valid_mean_absolute_error_masked', 'final_imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_imputation_0.1_eval/valid_mean_squared_error_masked', 'final_imputation_0.2_eval/valid_mean_squared_error_masked', 'final_imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'final_forecast_0.1_eval/valid_mean_absolute_error_masked', 'final_forecast_0.2_eval/valid_mean_absolute_error_masked', 'final_forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_forecast_0.1_eval/valid_mean_squared_error_masked', 'final_forecast_0.2_eval/valid_mean_squared_error_masked', 'final_forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'final_valid_mean_squared_error_masked',\n",
        "    'final_valid_mean_absolute_error_masked',\n",
        "\n",
        "]]\n",
        "sub_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OVY49x8ejhVx"
      },
      "outputs": [],
      "source": [
        "# @title Bar Mask Sweep\n",
        "\n",
        "bar_mask_ratio_sweep_xm_id_dict = {\n",
        "    125114553: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'bar mask ratio sweep',\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "bar_masking_sweep_df = get_metrics_df(bar_mask_ratio_sweep_xm_id_dict)\n",
        "bar_masking_sweep_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2w462CnlNfB"
      },
      "outputs": [],
      "source": [
        "time_bar_masks = ['constant_0.3_bar', 'constant_0.4_bar', 'constant_0.5_bar', 'constant_0.6_bar', 'constant_0.7_bar', 'constant_0.8_bar', 'constant_0.9_bar']\n",
        "feat_bar_masks = ['constant_0.3_bar_w', 'constant_0.4_bar_w', 'constant_0.5_bar_w', 'constant_0.7_bar_w', 'constant_0.9_bar_w']\n",
        "\n",
        "time_bar_mask_df = bar_masking_sweep_df[bar_masking_sweep_df['config.masked_feature_loss.token_mask_probability'].isin(time_bar_masks)]\n",
        "feat_bar_mask_df = bar_masking_sweep_df[bar_masking_sweep_df['config.masked_feature_loss.token_mask_probability'].isin(feat_bar_masks)]\n",
        "\n",
        "time_bar_mask_df['mask_ratio'] = time_bar_mask_df.apply(lambda row: float(row['config.masked_feature_loss.token_mask_probability'][9:12]), axis=1)\n",
        "feat_bar_mask_df['mask_ratio'] = feat_bar_mask_df.apply(lambda row: float(row['config.masked_feature_loss.token_mask_probability'][9:12]), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DghG9M9_N7va"
      },
      "outputs": [],
      "source": [
        "# @title Mask Ratio Sweep\n",
        "\n",
        "plot_metric_names = [\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    # 'valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "plot_metric_names = [\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "skip_list = [\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    # 'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    # 'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, m in enumerate(plot_metric_names):\n",
        "  if m in skip_list:\n",
        "    continue\n",
        "  m = prefix + m\n",
        "\n",
        "  mask_ratio = np.array(sweep_df['mask_ratio'])\n",
        "  metric_vals = np.array(sweep_df[m])\n",
        "\n",
        "  sorted_idx = np.argsort(mask_ratio)\n",
        "  mask_ratio = mask_ratio[sorted_idx]\n",
        "  metric_vals = metric_vals[sorted_idx]\n",
        "\n",
        "  print(f'{m}, {metric_vals[5]}')\n",
        "\n",
        "  # Plot\n",
        "  plt.scatter(mask_ratio, metric_vals, s=100, alpha=0.5, color=color_wheel[i], label='')\n",
        "  plt.plot(mask_ratio, metric_vals, linestyle='-', color=color_wheel[i], linewidth=2, label='rand_' + legend_list[i])\n",
        "\n",
        "print()\n",
        "for i, m in enumerate(plot_metric_names):\n",
        "  if m in skip_list:\n",
        "    continue\n",
        "  m = prefix + m\n",
        "\n",
        "  mask_ratio = np.array(time_bar_mask_df['mask_ratio'])\n",
        "  metric_vals = np.array(time_bar_mask_df[m])\n",
        "\n",
        "  sorted_idx = np.argsort(mask_ratio)\n",
        "  mask_ratio = mask_ratio[sorted_idx]\n",
        "  metric_vals = metric_vals[sorted_idx]\n",
        "\n",
        "  print(f'{m}, {metric_vals[5]}')\n",
        "\n",
        "\n",
        "  # Plot\n",
        "  plt.scatter(mask_ratio, metric_vals, s=100, alpha=0.5, color=color_wheel[i], label='')\n",
        "  plt.plot(mask_ratio, metric_vals, linestyle='--', color=color_wheel[i], linewidth=2, label='bar_' + legend_list[i])\n",
        "\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlabel('Masking Ratio')\n",
        "plt.ylim(bottom=0)\n",
        "plt.xticks([0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "plt.legend(loc='best', bbox_to_anchor=(1, 1.04));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zqyav8X-v1V"
      },
      "source": [
        "## Feature Order Ablation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g_4gdceN-6j9"
      },
      "outputs": [],
      "source": [
        "# @title Random Sweep Masking Ratio\n",
        "feats_order_xm_id_dict = {\n",
        "    125296318: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Random',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'random feature order sweep',\n",
        "    },\n",
        "\n",
        "    125246122: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Max Entropy',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'max entropy feature order',\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "feats_order_df = get_metrics_df(feats_order_xm_id_dict)\n",
        "feats_order_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSVu70hL__ZG"
      },
      "outputs": [],
      "source": [
        "# @title Default Base Model XM\n",
        "\n",
        "sweep_df = pd.concat([feats_order_df, default_df], ignore_index=True, sort=False)\n",
        "sweep_df = sweep_df[[\n",
        "    'Feature Order',\n",
        "    'final_imputation_0.1_eval/valid_mean_absolute_error_masked', 'final_imputation_0.2_eval/valid_mean_absolute_error_masked', 'final_imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_imputation_0.1_eval/valid_mean_squared_error_masked', 'final_imputation_0.2_eval/valid_mean_squared_error_masked', 'final_imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'final_forecast_0.1_eval/valid_mean_absolute_error_masked', 'final_forecast_0.2_eval/valid_mean_absolute_error_masked', 'final_forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_forecast_0.1_eval/valid_mean_squared_error_masked', 'final_forecast_0.2_eval/valid_mean_squared_error_masked', 'final_forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'final_valid_mean_absolute_error_masked',\n",
        "    'final_valid_mean_squared_error_masked',\n",
        "]]\n",
        "\n",
        "rand_order_df = sweep_df[sweep_df['Feature Order'] == 'Random']\n",
        "\n",
        "sweep_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVFqoGf2A9SZ"
      },
      "outputs": [],
      "source": [
        "rand_sub_df = rand_order_df.drop('Feature Order', axis='columns', inplace=False)\n",
        "rand_sub_df.mean()\n",
        "\n",
        "rand_sub_df[0:4].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzHLuJNtopyC"
      },
      "source": [
        "## Get XM Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9MAVXXbWyPL3"
      },
      "outputs": [],
      "source": [
        "# @title Get XM Metrics\n",
        "\n",
        "# Setup XM client\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')\n",
        "\n",
        "# XM ID Dict\n",
        "xm_id_dict = {\n",
        "    120664779: {\n",
        "        'model_size': 'Tiny',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True\n",
        "    },\n",
        "    120685218: {\n",
        "        'model_size': 'Tiny',\n",
        "        'feature_order': 'Random',\n",
        "        'loss_only_masked_patches': True\n",
        "    },\n",
        "}\n",
        "\n",
        "# Get metric names.\n",
        "metric_names = [\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_masked',\n",
        "    'valid_mean_squared_error_all',\n",
        "    'valid_mean_squared_error_masked',\n",
        "\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "meta_data_name = [\n",
        "    'num_trainable_params',\n",
        "    'core_hours',\n",
        "    'examples_seen',\n",
        "    'gflops',\n",
        "]\n",
        "\n",
        "data_field_names = meta_data_name + metric_names\n",
        "\n",
        "# Get all metrics.\n",
        "xm_exp_dict = collections.defaultdict(list)\n",
        "for xid, values in xm_id_dict.items():\n",
        "  model_size = values['model_size']\n",
        "  feat_order = values['feature_order']\n",
        "\n",
        "  experiment = xm_client.get_experiment(xid)\n",
        "  num_of_units = experiment.get_num_work_units()\n",
        "\n",
        "  for wid in range(1, num_of_units + 1):\n",
        "    work_unit = experiment.get_work_unit(wid)\n",
        "    key_list = work_unit.parameters.keys()\n",
        "    xm_exp_dict['wid'].append(wid)\n",
        "    xm_exp_dict['xid'].append(xid)\n",
        "\n",
        "    xm_exp_dict['Model Size'].append(model_size)\n",
        "    xm_exp_dict['Feature Order'].append(feat_order)\n",
        "\n",
        "    for param_name in key_list:\n",
        "      xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "    for metric in data_field_names:\n",
        "      xm_exp_dict[metric].append(\n",
        "          read_xm_metrics(xid, metric, wid, lowest=False)\n",
        "      )\n",
        "df = pd.DataFrame(xm_exp_dict)\n",
        "df = add_min_columns(df)\n",
        "df = add_better_col_names(df)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmXGGSVAokUv"
      },
      "source": [
        "## Sandbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XKb1xF-gDTm0"
      },
      "outputs": [],
      "source": [
        "# @title Ablation on Patch Sizes (Ordered Features)\n",
        "\n",
        "feat_order = 'Ordered'\n",
        "metric_name = 'valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches'\n",
        "\n",
        "subset = df[\n",
        "    (df['Feature Order'] == feat_order)\n",
        "]\n",
        "\n",
        "time_patch_sizes = [[5, 5], [10, 5], [20, 5]]\n",
        "feat_patch_sizes = [[10, 1], [10, 2], [10, 5], [10, 10]]\n",
        "time_idx = 0\n",
        "feat_idx = 1\n",
        "\n",
        "time_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(time_patch_sizes))\n",
        "]\n",
        "feat_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(feat_patch_sizes))\n",
        "]\n",
        "\n",
        "# Create a figure with three subplots in a row\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6), dpi=600)\n",
        "x = [row['patch_size'] for _, row in time_subset.iterrows()]\n",
        "y = [min(row[metric_name]) for _, row in time_subset.iterrows()]\n",
        "idx = np.argsort([int(i.split('x')[time_idx]) for i in x])\n",
        "x = [x[i] for i in idx]\n",
        "y = [y[i] for i in idx]\n",
        "\n",
        "sns.barplot(x=x, y=y, palette='Blues')\n",
        "axes.set_title('Path Size Scaling')\n",
        "axes.set_xlabel('Patch Size')\n",
        "axes.set_ylabel(metric_name_short)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a figure with three subplots in a row\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6), dpi=600)\n",
        "x = [row['patch_size'] for _, row in feat_subset.iterrows()]\n",
        "y = [min(row[metric_name]) for _, row in feat_subset.iterrows()]\n",
        "idx = np.argsort([int(i.split('x')[feat_idx]) for i in x])\n",
        "x = [x[i] for i in idx]\n",
        "y = [y[i] for i in idx]\n",
        "\n",
        "sns.barplot(x=x, y=y, palette='Blues')\n",
        "axes.set_title('Path Size Scaling')\n",
        "axes.set_xlabel('Patch Size')\n",
        "axes.set_ylabel(metric_name_short)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FZbqmyOjK4V-"
      },
      "outputs": [],
      "source": [
        "# @title Ablation on Patch Sizes (Random Features)\n",
        "\n",
        "feat_order = 'Random'\n",
        "metric_name = 'valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches'\n",
        "\n",
        "subset = df[\n",
        "    (df['Feature Order'] == feat_order)\n",
        "]\n",
        "\n",
        "time_patch_sizes = [[5, 5], [10, 5], [20, 5]]\n",
        "feat_patch_sizes = [[10, 1], [10, 2], [10, 5], [10, 10]]\n",
        "time_idx = 0\n",
        "feat_idx = 1\n",
        "\n",
        "time_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(time_patch_sizes))\n",
        "]\n",
        "feat_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(feat_patch_sizes))\n",
        "]\n",
        "\n",
        "metric_name = 'valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches'\n",
        "# Create a figure with three subplots in a row\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6), dpi=600)\n",
        "x = [row['patch_size'] for _, row in time_subset.iterrows()]\n",
        "y = [min(row[metric_name]) for _, row in time_subset.iterrows()]\n",
        "idx = np.argsort([int(i.split('x')[time_idx]) for i in x])\n",
        "x = [x[i] for i in idx]\n",
        "y = [y[i] for i in idx]\n",
        "\n",
        "sns.barplot(x=x, y=y, palette='Blues')\n",
        "axes.set_title('Path Size Scaling')\n",
        "axes.set_xlabel('Patch Size')\n",
        "axes.set_ylabel(metric_name_short)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "metric_name = 'valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches'\n",
        "# Create a figure with three subplots in a row\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6), dpi=600)\n",
        "x = [row['patch_size'] for _, row in feat_subset.iterrows()]\n",
        "y = [min(row[metric_name]) for _, row in feat_subset.iterrows()]\n",
        "idx = np.argsort([int(i.split('x')[feat_idx]) for i in x])\n",
        "x = [x[i] for i in idx]\n",
        "y = [y[i] for i in idx]\n",
        "\n",
        "sns.barplot(x=x, y=y, palette='Blues')\n",
        "axes.set_title('Path Size Scaling')\n",
        "axes.set_xlabel('Patch Size')\n",
        "axes.set_ylabel(metric_name_short)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS8WzfQsoiC0"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OKeP1oueNTC5"
      },
      "outputs": [],
      "source": [
        "# @title Ablation on Patch Sizes (Ordered vs Random)\n",
        "\n",
        "metric_name = 'min_valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches (Min)'\n",
        "\n",
        "time_patch_sizes = [[5, 5], [10, 5], [20, 5]]\n",
        "feat_patch_sizes = [[10, 1], [10, 2], [10, 5], [10, 10]]\n",
        "time_idx = 0\n",
        "feat_idx = 1\n",
        "\n",
        "time_subset = df[\n",
        "    (df['config.model.patches.size'].isin(time_patch_sizes))\n",
        "]\n",
        "feat_subset = df[\n",
        "    (df['config.model.patches.size'].isin(feat_patch_sizes))\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=500)\n",
        "barplot = sns.barplot(\n",
        "    data=time_subset,\n",
        "    x='patch_size',\n",
        "    y=metric_name,\n",
        "    hue='Feature Order',\n",
        "    palette='Blues',\n",
        "    order=[f'{i[0]}x{i[1]}' for i in time_patch_sizes[::-1]],\n",
        "    errorbar=('ci', 95),\n",
        "    width=0.7,\n",
        ")\n",
        "plt.ylabel(metric_name_short)\n",
        "plt.title('Temporal Patch Size Scaling')\n",
        "plt.legend(frameon=False, ncol=1, loc='upper right', bbox_to_anchor=(1.3, 1))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=500)\n",
        "barplot = sns.barplot(\n",
        "    data=feat_subset,\n",
        "    x='patch_size',\n",
        "    y=metric_name,\n",
        "    hue='Feature Order',\n",
        "    palette='Blues',\n",
        "    order=[f'{i[0]}x{i[1]}' for i in feat_patch_sizes[::-1]],\n",
        "    errorbar=('ci', 95),\n",
        "    width=0.7,\n",
        ")\n",
        "plt.ylabel(metric_name_short)\n",
        "plt.title('Feature Patch Size Scaling')\n",
        "plt.legend(frameon=False, ncol=1, loc='upper right', bbox_to_anchor=(1.3, 1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JGhK6VTJX3An"
      },
      "outputs": [],
      "source": [
        "# @title Ablation on Patch Sizes (Imputation Features)\n",
        "\n",
        "metric_name = 'valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches (Min)'\n",
        "metric_type = 'final'  # min or final\n",
        "task_horizons = [0.1, 0.2, 0.4]\n",
        "feat_order = 'Ordered'\n",
        "task = 'imputation'\n",
        "\n",
        "time_patch_sizes = [[5, 5], [10, 5], [20, 5]]\n",
        "feat_patch_sizes = [[10, 1], [10, 2], [10, 5], [10, 10]]\n",
        "\n",
        "subset = pd.DataFrame()\n",
        "for i, row in df.iterrows():\n",
        "  for hrzn in task_horizons:\n",
        "\n",
        "    imputation_metric_name = f'{metric_type}_imputation_{hrzn}_eval/{metric_name}'\n",
        "    forecast_metric_name = f'{metric_type}_forecast_{hrzn}_eval/{metric_name}'\n",
        "\n",
        "    imp_row = pd.DataFrame(\n",
        "        {\n",
        "            'task': ['imputation'],\n",
        "            'horizon': [hrzn],\n",
        "            'error': [row[imputation_metric_name]],\n",
        "            'Model Size': [row['Model Size']],\n",
        "            'patch_size': [row['patch_size']],\n",
        "            'config.model.patches.size': [row['config.model.patches.size']],\n",
        "            'Feature Order': row['Feature Order'],\n",
        "        }\n",
        "    )\n",
        "    for_row = pd.DataFrame(\n",
        "        {\n",
        "            'task': ['forecast'],\n",
        "            'horizon': [hrzn],\n",
        "            'error': [row[forecast_metric_name]],\n",
        "            'Model Size': [row['Model Size']],\n",
        "            'patch_size': [row['patch_size']],\n",
        "            'config.model.patches.size': [row['config.model.patches.size']],\n",
        "            'Feature Order': row['Feature Order'],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    subset = pd.concat([subset, imp_row], ignore_index=True)\n",
        "    subset = pd.concat([subset, for_row], ignore_index=True)\n",
        "\n",
        "# Get sweep subsets\n",
        "subset = subset[\n",
        "    (subset['task'] == task)\n",
        "]\n",
        "subset = subset[\n",
        "    (subset['Feature Order'] == feat_order)\n",
        "]\n",
        "time_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(time_patch_sizes))\n",
        "]\n",
        "feat_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(feat_patch_sizes))\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=500)\n",
        "barplot = sns.barplot(\n",
        "    data=time_subset,\n",
        "    x='patch_size',\n",
        "    y='error',\n",
        "    hue='horizon',\n",
        "    palette='Blues',\n",
        "    order=[f'{i[0]}x{i[1]}' for i in time_patch_sizes[::-1]],\n",
        "    errorbar=('ci', 1),\n",
        "    width=0.7,\n",
        ")\n",
        "plt.ylabel(metric_name_short)\n",
        "plt.xlabel('Patch Size')\n",
        "plt.title('Imputation: Temporal Patch Size Scaling')\n",
        "plt.legend(frameon=False, ncol=1, loc='upper right', bbox_to_anchor=(1.2, 1))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=500)\n",
        "barplot = sns.barplot(\n",
        "    data=feat_subset,\n",
        "    x='patch_size',\n",
        "    y='error',\n",
        "    hue='horizon',\n",
        "    palette='Blues',\n",
        "    order=[f'{i[0]}x{i[1]}' for i in feat_patch_sizes[::-1]],\n",
        "    errorbar=('ci', 1),\n",
        "    width=0.7,\n",
        ")\n",
        "plt.ylabel(metric_name_short)\n",
        "plt.xlabel('Patch Size')\n",
        "plt.title('Imputation: Feature Patch Size Scaling')\n",
        "plt.legend(frameon=False, ncol=1, loc='upper right', bbox_to_anchor=(1.2, 1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0NQ74ToQm_HE"
      },
      "outputs": [],
      "source": [
        "# @title Ablation on Patch Sizes (Forecast)\n",
        "\n",
        "metric_name = 'valid_mean_absolute_error_masked'\n",
        "metric_name_short = 'MAE Masked Patches (Min)'\n",
        "metric_type = 'final'  # min or final\n",
        "task_horizons = [0.1, 0.2, 0.4]\n",
        "feat_order = 'Ordered'\n",
        "task = 'forecast'\n",
        "\n",
        "time_patch_sizes = [[5, 5], [10, 5], [20, 5]]\n",
        "feat_patch_sizes = [[10, 1], [10, 2], [10, 5], [10, 10]]\n",
        "\n",
        "subset = pd.DataFrame()\n",
        "for i, row in df.iterrows():\n",
        "  for hrzn in task_horizons:\n",
        "\n",
        "    imputation_metric_name = f'{metric_type}_imputation_{hrzn}_eval/{metric_name}'\n",
        "    forecast_metric_name = f'{metric_type}_forecast_{hrzn}_eval/{metric_name}'\n",
        "\n",
        "    imp_row = pd.DataFrame(\n",
        "        {\n",
        "            'task': ['imputation'],\n",
        "            'horizon': [hrzn],\n",
        "            'error': [row[imputation_metric_name]],\n",
        "            'Model Size': [row['Model Size']],\n",
        "            'patch_size': [row['patch_size']],\n",
        "            'config.model.patches.size': [row['config.model.patches.size']],\n",
        "            'Feature Order': row['Feature Order'],\n",
        "        }\n",
        "    )\n",
        "    for_row = pd.DataFrame(\n",
        "        {\n",
        "            'task': ['forecast'],\n",
        "            'horizon': [hrzn],\n",
        "            'error': [row[forecast_metric_name]],\n",
        "            'Model Size': [row['Model Size']],\n",
        "            'patch_size': [row['patch_size']],\n",
        "            'config.model.patches.size': [row['config.model.patches.size']],\n",
        "            'Feature Order': row['Feature Order'],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    subset = pd.concat([subset, imp_row], ignore_index=True)\n",
        "    subset = pd.concat([subset, for_row], ignore_index=True)\n",
        "\n",
        "# Get sweep subsets\n",
        "subset = subset[\n",
        "    (subset['task'] == task)\n",
        "]\n",
        "subset = subset[\n",
        "    (subset['Feature Order'] == feat_order)\n",
        "]\n",
        "time_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(time_patch_sizes))\n",
        "]\n",
        "feat_subset = subset[\n",
        "    (subset['config.model.patches.size'].isin(feat_patch_sizes))\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=500)\n",
        "barplot = sns.barplot(\n",
        "    data=time_subset,\n",
        "    x='patch_size',\n",
        "    y='error',\n",
        "    hue='horizon',\n",
        "    palette='Blues',\n",
        "    order=[f'{i[0]}x{i[1]}' for i in time_patch_sizes[::-1]],\n",
        "    errorbar=('ci', 1),\n",
        "    width=0.7,\n",
        ")\n",
        "plt.ylabel(metric_name_short)\n",
        "plt.xlabel('Patch Size')\n",
        "plt.title('Forecast: Temporal Patch Size Scaling')\n",
        "plt.legend(frameon=False, ncol=1, loc='upper right', bbox_to_anchor=(1.2, 1))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=500)\n",
        "barplot = sns.barplot(\n",
        "    data=feat_subset,\n",
        "    x='patch_size',\n",
        "    y='error',\n",
        "    hue='horizon',\n",
        "    palette='Blues',\n",
        "    order=[f'{i[0]}x{i[1]}' for i in feat_patch_sizes[::-1]],\n",
        "    errorbar=('ci', 1),\n",
        "    width=0.7,\n",
        ")\n",
        "plt.ylabel(metric_name_short)\n",
        "plt.xlabel('Patch Size')\n",
        "plt.title('Forecast: Feature Patch Size Scaling')\n",
        "plt.legend(frameon=False, ncol=1, loc='upper right', bbox_to_anchor=(1.2, 1))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZzHLuJNtopyC",
        "XmXGGSVAokUv",
        "FS8WzfQsoiC0"
      ],
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
