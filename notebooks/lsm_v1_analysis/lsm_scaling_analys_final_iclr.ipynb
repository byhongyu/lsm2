{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzh4DG0fCRQO"
      },
      "outputs": [],
      "source": [
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import re\n",
        "\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')\n",
        "MEDIUM_SIZE = 18\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = MEDIUM_SIZE\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE-5)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBQR_rQhVhd4"
      },
      "outputs": [],
      "source": [
        "def read_xm_metrics(example_xid, metric_name, unit_id, lowest=True):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if series.label == metric_name:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "      if lowest:\n",
        "        return min(all_measurements)\n",
        "      else:\n",
        "        return all_measurements\n",
        "\n",
        "\n",
        "def add_min_columns(df):\n",
        "  # Function to calculate the minimum value in each list\n",
        "  def min_of_list(lst):\n",
        "    return min(lst)\n",
        "\n",
        "  # Calculate minimum values and add as new columns\n",
        "  df['min_valid_mean_absolute_error_all'] = df[\n",
        "      'valid_mean_absolute_error_all'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_absolute_error_masked'] = df[\n",
        "      'valid_mean_absolute_error_masked'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_squared_error_all'] = df[\n",
        "      'valid_mean_squared_error_all'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_squared_error_masked'] = df[\n",
        "      'valid_mean_squared_error_masked'\n",
        "  ].apply(min_of_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def process_string_metric(input_string):\n",
        "  # Define the mapping of long error names to their abbreviations\n",
        "  error_map = {'mean_absolute_error': 'mae', 'mean_squared_error': 'mse'}\n",
        "\n",
        "  # Replace the errors in the string using the map\n",
        "  for long_error, short_error in error_map.items():\n",
        "    input_string = re.sub(long_error, short_error, input_string)\n",
        "\n",
        "  # Remove 'valid_' and replace '/' with '_'\n",
        "  input_string = input_string.replace('valid_', '').replace('/', '_')\n",
        "\n",
        "  return input_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6m9nh51kpZY"
      },
      "outputs": [],
      "source": [
        "# @title Data Scaling\n",
        "\n",
        "# Get unique learning rates\n",
        "\n",
        "\n",
        "xm_id_dict = {  # Model Size, ParamSize, PatchSize\n",
        "    # 122552298: ['Deb', 0.11, '10x5'],\n",
        "    122552990: ['Tiny', 2.21, '10x5'],\n",
        "    122552440: ['ExtraSmall', 7.3, '10x5'],\n",
        "    122552749: ['Small', 24.6, '10x5'],\n",
        "    122527956: ['Base', 110.74, '10x5'],\n",
        "    # 122528949: ['Large', 328.13, '10x5'],\n",
        "}\n",
        "\n",
        "\n",
        "metric_names = [\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_masked',\n",
        "    'valid_mean_squared_error_all',\n",
        "    'valid_mean_squared_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_all',\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_all',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_all',\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_all',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "xm_exp_dict = collections.defaultdict(list)\n",
        "for key, values in xm_id_dict.items():\n",
        "  xm_id = key\n",
        "  model_size = values[0]\n",
        "  param_size = values[1]\n",
        "  patch_size = values[2]\n",
        "  experiment = xm_client.get_experiment(xm_id)\n",
        "  num_of_units = experiment.get_num_work_units()\n",
        "  for id in range(num_of_units):\n",
        "    real_id = id + 1\n",
        "    work_unit = experiment.get_work_unit(real_id)\n",
        "    key_list = work_unit.parameters.keys()\n",
        "    xm_exp_dict['unit_id'].append(id)\n",
        "    xm_exp_dict['xm_id'].append(xm_id)\n",
        "    xm_exp_dict['Param Size'].append(param_size)\n",
        "    xm_exp_dict['Model Size'].append(model_size)\n",
        "    xm_exp_dict['Patch Size'].append(patch_size)\n",
        "    for param_name in key_list:\n",
        "      xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "    for metric in metric_names:\n",
        "      xm_exp_dict[metric].append(\n",
        "          read_xm_metrics(xm_id, metric, real_id, lowest=False)\n",
        "      )\n",
        "df = pd.DataFrame(xm_exp_dict)\n",
        "df = add_min_columns(df)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBRK2XS94uJL"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUkXpva9E3u_"
      },
      "outputs": [],
      "source": [
        "use_aug = True\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours = [1000, 5000, 10000, 15000, 25000, 30000, 40000, 50000]\n",
        "default_marker_color = '#1967d2'\n",
        "for metric_name in metric_names:\n",
        "  displayed_metric = process_string_metric(metric_name)\n",
        "  # Create a figure with three subplots in a row\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(18, 6), dpi=600)\n",
        "  # Figure 1: Compute Scaling\n",
        "  for data_size in df['config.dataset_configs.train_num_samples'].unique():\n",
        "    for model_size in df['Model Size'].unique():\n",
        "      subset = df[\n",
        "          (df['Model Size'] == model_size)\n",
        "          \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "          \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "      ]\n",
        "      num_of_logging = len(subset.iloc[0][metric_name])\n",
        "      logging_in_steps = [\n",
        "          int((idx - 1) / 100000 * num_of_logging) for idx in compute_hours\n",
        "      ]\n",
        "      x = [int(x / 600) for x in compute_hours]\n",
        "      y = [subset.iloc[0][metric_name][idx] for idx in logging_in_steps]\n",
        "\n",
        "      sns.scatterplot(\n",
        "          x=x,\n",
        "          y=y[: len(x)],\n",
        "          color=default_marker_color,\n",
        "          ax=axes[0],\n",
        "          s=150,\n",
        "          alpha=0.5,\n",
        "      )\n",
        "      sns.lineplot(\n",
        "          x=x, y=y[: len(x)], color=default_marker_color, ax=axes[0], alpha=0.2\n",
        "      )\n",
        "      axes[0].set_title(f'Compute Scaling')\n",
        "      axes[0].set_xlabel(r'$\\mathbf{Compute}$' + '\\n TPU v5 VLP core hours')\n",
        "      axes[0].set_ylabel(displayed_metric)\n",
        "  # Figure 2: Data Scaling\n",
        "  for model_size in df['Model Size'].unique():\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "    x = [\n",
        "        round(\n",
        "            row['config.dataset_configs.train_num_samples'] / 1_000_000 * 5, 2\n",
        "        )\n",
        "        for _, row in subset.iterrows()\n",
        "    ]\n",
        "    if use_last:\n",
        "      y = [row[metric_name][-1] for _, row in subset.iterrows()]\n",
        "    else:\n",
        "      y = [min(row[metric_name]) for _, row in subset.iterrows()]\n",
        "    sns.scatterplot(\n",
        "        x=x, y=y, color=default_marker_color, ax=axes[1], s=150, alpha=0.5\n",
        "    )\n",
        "    sns.lineplot(x=x, y=y, color=default_marker_color, ax=axes[1], alpha=0.2)\n",
        "    axes[1].set_title(f'Data Scaling')\n",
        "    axes[1].set_xlabel(r'$\\mathbf{Data\\ Size}$' + '\\n(Million Hours)')\n",
        "  # Figure 3: Model Scaling\n",
        "  for data_size in df['config.dataset_configs.train_num_samples'].unique():\n",
        "    subset = df[\n",
        "        (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "    x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "    if use_last:\n",
        "      y = [row[metric_name][-1] for _, row in subset.iterrows()]\n",
        "    else:\n",
        "      y = [min(row[metric_name]) for _, row in subset.iterrows()]\n",
        "    sns.scatterplot(\n",
        "        x=x, y=y, color=default_marker_color, ax=axes[2], s=150, alpha=0.5\n",
        "    )\n",
        "    sns.lineplot(x=x, y=y, color=default_marker_color, ax=axes[2], alpha=0.2)\n",
        "    axes[2].set_title('Model Size Scaling')\n",
        "    axes[2].set_xlabel(r'$\\mathbf{Model\\ Size}$' + '\\n(Million of Params)')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH9J24LR1SOy"
      },
      "outputs": [],
      "source": [
        "use_aug = False\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours = [1000, 5000, 10000, 15000, 25000, 30000, 40000, 50000]\n",
        "default_marker_color = '#1967d2'\n",
        "for metric_name in metric_names:\n",
        "  displayed_metric = process_string_metric(metric_name)\n",
        "  # Create a figure with three subplots in a row\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(18, 6), dpi=600)\n",
        "  # Figure 1: Compute Scaling\n",
        "  for data_size in df['config.dataset_configs.train_num_samples'].unique():\n",
        "    for model_size in df['Model Size'].unique():\n",
        "      subset = df[\n",
        "          (df['Model Size'] == model_size)\n",
        "          \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "          \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "      ]\n",
        "      num_of_logging = len(subset.iloc[0][metric_name])\n",
        "      logging_in_steps = [\n",
        "          int((idx - 1) / 100000 * num_of_logging) for idx in compute_hours\n",
        "      ]\n",
        "      x = [int(x / 600) for x in compute_hours]\n",
        "      y = [subset.iloc[0][metric_name][idx] for idx in logging_in_steps]\n",
        "\n",
        "      sns.scatterplot(\n",
        "          x=x,\n",
        "          y=y[: len(x)],\n",
        "          color=default_marker_color,\n",
        "          ax=axes[0],\n",
        "          s=150,\n",
        "          alpha=0.5,\n",
        "      )\n",
        "      sns.lineplot(\n",
        "          x=x, y=y[: len(x)], color=default_marker_color, ax=axes[0], alpha=0.2\n",
        "      )\n",
        "      axes[0].set_title(f'Compute Scaling')\n",
        "      axes[0].set_xlabel(r'$\\mathbf{Compute}$' + '\\n TPU v5 VLP core hours')\n",
        "      axes[0].set_ylabel(displayed_metric)\n",
        "  # Figure 2: Data Scaling\n",
        "  for model_size in df['Model Size'].unique():\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "    x = [\n",
        "        round(\n",
        "            row['config.dataset_configs.train_num_samples'] / 1_000_000 * 5, 2\n",
        "        )\n",
        "        for _, row in subset.iterrows()\n",
        "    ]\n",
        "    if use_last:\n",
        "      y = [row[metric_name][-1] for _, row in subset.iterrows()]\n",
        "    else:\n",
        "      y = [min(row[metric_name]) for _, row in subset.iterrows()]\n",
        "    sns.scatterplot(\n",
        "        x=x, y=y, color=default_marker_color, ax=axes[1], s=150, alpha=0.5\n",
        "    )\n",
        "    sns.lineplot(x=x, y=y, color=default_marker_color, ax=axes[1], alpha=0.2)\n",
        "    axes[1].set_title(f'Data Scaling')\n",
        "    axes[1].set_xlabel(r'$\\mathbf{Data\\ Size}$' + '\\n(Million Hours)')\n",
        "  # Figure 3: Model Scaling\n",
        "  for data_size in df['config.dataset_configs.train_num_samples'].unique():\n",
        "    subset = df[\n",
        "        (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "    x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "    if use_last:\n",
        "      y = [row[metric_name][-1] for _, row in subset.iterrows()]\n",
        "    else:\n",
        "      y = [min(row[metric_name]) for _, row in subset.iterrows()]\n",
        "    sns.scatterplot(\n",
        "        x=x, y=y, color=default_marker_color, ax=axes[2], s=150, alpha=0.5\n",
        "    )\n",
        "    sns.lineplot(x=x, y=y, color=default_marker_color, ax=axes[2], alpha=0.2)\n",
        "    axes[2].set_title('Model Size Scaling')\n",
        "    axes[2].set_xlabel(r'$\\mathbf{Model\\ Size}$' + '\\n(Million of Params)')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "lsm_scaling_analys_final_iclr.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data_size.ipynb?workspaceId=xliucs:scaling_analysis_new_pretrain::citc",
          "timestamp": 1723419354747
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data_size.ipynb",
          "timestamp": 1723071326500
        },
        {
          "file_id": "1Q3nbnc5dYAV6pyHWeKKXRVbxMwBPPQuB",
          "timestamp": 1719441633704
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data.ipynb",
          "timestamp": 1719435410567
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analysis_parameter_sweep.ipynb?workspaceId=xliucs:lsm_notebooks_scaling_june22::citc",
          "timestamp": 1719177613159
        },
        {
          "file_id": "1avNG7EtMynPa2U-GHj2nd4nWWdGzcFq3",
          "timestamp": 1719177577595
        },
        {
          "file_id": "1WdhekZ_TCf-uOIWufr8RjKRHUcB0jzoZ",
          "timestamp": 1719170535908
        },
        {
          "file_id": "1rMS2cnwRlpP6NSfAA_mDuXFnbLEc6UnM",
          "timestamp": 1718735304309
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
