{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_2cKO5pj9bE"
      },
      "source": [
        "## LSM Patch Scaling and Feature Order Analysis\n",
        "##### Colab Kernel (Brainframe GPU)\n",
        "##### Dataset (Electrodes)\n",
        "\n",
        "Grants command for Access on Demand (AoD):\n",
        "\n",
        "https://grants.corp.google.com/#/grants?request=20h%2Fchr-ards-electrodes-deid-colab-jobs\u0026reason=b%2F314799341\n",
        "\n",
        "### About This Notebook:\n",
        "This notebook runs down-stream task analysis on Vit-MAE LSM V1 model.\n",
        "These tasks include:\n",
        "* I. Classification Fewshot Experiments (Activity Recognition and Exercise Detection)\n",
        "* II. (Pretrain) Data Scaling Experiments (Activity Recognition and Exercise Detection)\n",
        "* III. Remedies to previously incorrect mAP classifcation results (for sections I and II - further discussed in section III)\n",
        "* IV. Generative Task Experiments (Forecasting, Time and Sensor Imputation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3S5-w6LK23"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w3x__zT2WTjS"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "from google3.pyglib import gfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "\n",
        "from typing import Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RC_E4xYL3VXV"
      },
      "outputs": [],
      "source": [
        "# @title Plot Formatting\n",
        "\n",
        "MEDIUM_SIZE = 18\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = MEDIUM_SIZE\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8ixTQAGmqqEA"
      },
      "outputs": [],
      "source": [
        "# @title Metrics and Field Names\n",
        "\n",
        "# Get metric names.\n",
        "metric_names = [\n",
        "    'valid_accuracy',\n",
        "    'valid_mAP',\n",
        "\n",
        "    'valid_mean_absolute_error_masked',\n",
        "    'valid_mean_squared_error_masked',\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'valid_mean_squared_error_all',\n",
        "\n",
        "    # Generative Task Metrics\n",
        "    # Forecast\n",
        "    'forecast_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    # Imputation\n",
        "    'imputation_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    # Sensor Imputation Metrics\n",
        "    'sensor_imputation_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.5_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.5_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'sensor_imputation_0.2_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.2_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.4_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.4_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.5_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.5_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.7_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.7_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.9_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.9_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_1.0_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_1.0_0.034_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'sensor_imputation_0.2_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.2_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.4_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.4_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.5_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.5_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.7_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.7_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.9_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.9_0.067_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_1.0_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_1.0_0.067_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'sensor_imputation_0.2_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.2_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.4_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.4_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.5_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.5_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.7_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.7_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.9_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.9_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_1.0_0.1_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_1.0_0.1_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'sensor_imputation_0.2_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.2_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.4_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.4_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.5_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.5_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.7_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.7_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.9_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.9_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_1.0_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_1.0_0.2_eval/valid_mean_squared_error_masked',\n",
        "\n",
        "    'sensor_imputation_0.2_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.2_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.4_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.4_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.5_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.5_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.7_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.7_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_0.9_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_0.9_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'sensor_imputation_1.0_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'sensor_imputation_1.0_0.4_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "\n",
        "meta_data_name = [\n",
        "    'num_trainable_params',\n",
        "    'core_hours',\n",
        "    'examples_seen',\n",
        "    'gflops',\n",
        "]\n",
        "\n",
        "data_field_names = meta_data_name + metric_names\n",
        "\n",
        "print('Data fields to fetch:\\n', data_field_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0bAuakU7WYXi"
      },
      "outputs": [],
      "source": [
        "# @title Helpers\n",
        "\n",
        "def read_xm_metrics(example_xid, metric_name, unit_id, lowest=True):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if series.label == metric_name:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "      if lowest:\n",
        "        return min(all_measurements)\n",
        "      else:\n",
        "        return all_measurements\n",
        "\n",
        "\n",
        "def add_min_columns(df):\n",
        "  # Function to calculate the minimum value in each list\n",
        "  def min_of_list(lst):\n",
        "    return min(lst)\n",
        "\n",
        "  def min_idx_of_list(lst):\n",
        "    min_idx = np.argmin(lst)\n",
        "    return min_idx\n",
        "\n",
        "  def last_of_list(lst):\n",
        "    if lst is not None:\n",
        "      return lst[-1]\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  # Calculate minimum values and add as new columns\n",
        "  for col in df.columns:\n",
        "    if col in metric_names:\n",
        "      new_col_name = 'final_' + col\n",
        "      df[new_col_name] = df[col].apply(last_of_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def add_better_col_names(df):\n",
        "\n",
        "  def patch_col_name(patch_size):\n",
        "    return f'{patch_size[0]}x{patch_size[1]}'\n",
        "\n",
        "  for col in df.columns:\n",
        "    if col == 'config.model.patches.size':\n",
        "      df['patch_size'] = df[col].apply(patch_col_name)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_metrics_df(xm_dict):\n",
        "\n",
        "  # Get all metrics.\n",
        "  xm_exp_dict = collections.defaultdict(list)\n",
        "  for xid, values in xm_dict.items():\n",
        "    model_size = values['model_size']\n",
        "    feat_order = values['feature_order']\n",
        "\n",
        "    experiment = xm_client.get_experiment(xid)\n",
        "    num_of_units = experiment.get_num_work_units()\n",
        "\n",
        "    for wid in range(1, num_of_units + 1):\n",
        "      work_unit = experiment.get_work_unit(wid)\n",
        "      key_list = work_unit.parameters.keys()\n",
        "      xm_exp_dict['wid'].append(wid)\n",
        "      xm_exp_dict['xid'].append(xid)\n",
        "\n",
        "      xm_exp_dict['Model Size'].append(model_size)\n",
        "      xm_exp_dict['Feature Order'].append(feat_order)\n",
        "\n",
        "      if 'spc' in values.keys():\n",
        "        xm_exp_dict['fewshot_samples_per_class'].append(values['spc'])\n",
        "\n",
        "      if 'train_data_size' in values.keys():\n",
        "        xm_exp_dict['train_data_size'].append(values['train_data_size'])\n",
        "\n",
        "      if 'config.init_from.checkpoint_step' in values.keys():\n",
        "        xm_exp_dict['config.init_from.checkpoint_step'].append(values['config.init_from.checkpoint_step'])\n",
        "\n",
        "      for param_name in key_list:\n",
        "        xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "      for metric in data_field_names:\n",
        "        xm_exp_dict[metric].append(\n",
        "            read_xm_metrics(xid, metric, wid, lowest=False)\n",
        "        )\n",
        "\n",
        "  df = pd.DataFrame(xm_exp_dict)\n",
        "  df = add_min_columns(df)\n",
        "  df = add_better_col_names(df)\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DpRnZFXKO_4V"
      },
      "outputs": [],
      "source": [
        "# @title CM Plotting Fn\n",
        "\n",
        "def confusion_matrix_fig(\n",
        "    confusion_matrix: tf.Tensor, labels: Sequence[str], scale: float = 0.8\n",
        ") -\u003e plt.Figure:\n",
        "  \"\"\"Returns a matplotlib plot of the given confusion matrix.\n",
        "\n",
        "  Forked from:\n",
        "  google3/fitbit/research/sensor_algorithms/training/logging/\n",
        "  confusion_matrix_logging.py\n",
        "\n",
        "  Args:\n",
        "      confusion_matrix: Confusion matrix as 2D numpy array.\n",
        "      labels: List of class names, will be used as axis labels.\n",
        "      scale: Scale for the image size.\n",
        "  \"\"\"\n",
        "  label_totals = np.sum(confusion_matrix, axis=1, keepdims=True)\n",
        "  prediction_totals = np.sum(confusion_matrix, axis=0, keepdims=True)\n",
        "\n",
        "  cm_normalized = np.nan_to_num(confusion_matrix / label_totals)\n",
        "\n",
        "  num_labels = len(labels)\n",
        "  longest_label = max([len(label) for label in labels])\n",
        "\n",
        "  # Guesstimating an appropriate size.\n",
        "  image_size = scale * (num_labels + (longest_label / 8.0))\n",
        "\n",
        "  fig = plt.figure(\n",
        "      figsize=(image_size, image_size), facecolor='w', edgecolor='k'\n",
        "  )\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.imshow(cm_normalized, cmap='Blues')\n",
        "\n",
        "  tick_marks = np.arange(num_labels)\n",
        "\n",
        "  ax.set_xlabel('Predicted')\n",
        "  ax.set_xticks(tick_marks)\n",
        "  x_labels = (\n",
        "      f'{label} ({int(count):,})'\n",
        "      for label, count in zip(labels, prediction_totals[0, :])\n",
        "  )\n",
        "  ax.set_xticklabels(x_labels, rotation=-45, ha='center')\n",
        "  ax.xaxis.set_label_position('bottom')\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ax.set_ylabel('True Label')\n",
        "  ax.set_yticks(tick_marks)\n",
        "  y_labels = (\n",
        "      f'{label} ({int(count):,})'\n",
        "      for label, count in zip(labels, label_totals[:, 0])\n",
        "  )\n",
        "  ax.set_yticklabels(y_labels, va='center')\n",
        "  ax.yaxis.set_label_position('left')\n",
        "  ax.yaxis.tick_left()\n",
        "\n",
        "  for row_idx, col_idx in itertools.product(\n",
        "      range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])\n",
        "  ):\n",
        "    text_color = 'white' if cm_normalized[row_idx, col_idx] \u003e= 0.5 else 'black'\n",
        "    if confusion_matrix[row_idx, col_idx] == 0:\n",
        "      text_str = '.'\n",
        "    else:\n",
        "      text_str = (\n",
        "          f'{cm_normalized[row_idx,col_idx]:2.0%}\\n'\n",
        "          f'({int(confusion_matrix[row_idx, col_idx]):,})'\n",
        "      )\n",
        "    ax.text(\n",
        "        col_idx,\n",
        "        row_idx,\n",
        "        text_str,\n",
        "        horizontalalignment='center',\n",
        "        verticalalignment='center',\n",
        "        color=text_color,\n",
        "    )\n",
        "\n",
        "  fig.set_tight_layout(True)\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "egJ3ll__Ii7C"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Plotting Setup\n",
        "\n",
        "# Imports\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "# Constants\n",
        "ALL_FEATURE_NAMES = ['sclValue', 'sclSlope', 'skinTempValue',\n",
        "                    'hr', 'hrvPercentGood','hrvRR80thPercentile', 'hrvRR20thPercentile',\n",
        "                    'hrvRRMedian', 'hrvRRMean', 'hrvShannonEntropyRR', 'hrvShannonEntropyRRDiffs',\n",
        "                    'hrvPNN30', 'hrvRMSSD', 'hrvSDNN', 'sleepCoefficient', 'onWrist',\n",
        "                    'jerkAuto', 'stepCount', 'logEnergy', 'grok_covariance', 'logEnergyRatio',\n",
        "                    'zeroCrossingStd', 'zeroCrossingAvg', 'axisMean', 'altimStdNorm', 'grok_kurtosis']\n",
        "\n",
        "actDict = {'Yoga': 52000, 'Pilates': 53000, 'Bike':90001,\n",
        "            'Run':90009,'Hike':90012,'Walk':90013,'Elliptical':90017,'Treadmill':90019,\n",
        "            'Swim':90024,'HIIT':91040,'Weightlifting':91043,'Core training':91046}\n",
        "\n",
        "actOHEDict = {\n",
        "    'Weightlifting': 0, 'Swim': 1, 'Elliptical': 2, 'Walk': 3,\n",
        "    'Run': 4, 'Bike': 5, 'HIIT': 6, 'Strength training': 7\n",
        "}\n",
        "\n",
        "\n",
        "def plot_embeddings(Xd, yd, colors, names):\n",
        "  if len(names) != len(colors):\n",
        "    raise ValueError(f'names ({len(names)}) and colors ({len(colors)}) must have the same length.')\n",
        "\n",
        "\n",
        "  # PCA\n",
        "  pca = PCA()\n",
        "  pipe = Pipeline([('scaler', StandardScaler()), ('pca', pca)])\n",
        "  plt.figure(figsize=(8,6))\n",
        "  Xt = pipe.fit_transform(Xd)\n",
        "  plot = plt.scatter(Xt[:,2], Xt[:,3], c=yd);\n",
        "  plt.xlabel('PCA Dim 1')\n",
        "  plt.ylabel('PCA Dim 2')\n",
        "  plt.legend(\n",
        "      handles=plot.legend_elements()[0],\n",
        "      labels=names,\n",
        "      loc='upper left',\n",
        "      bbox_to_anchor=(1, 1)\n",
        "  );\n",
        "  plt.show()\n",
        "  print('\\n\\n')\n",
        "\n",
        "\n",
        "  # LDA\n",
        "  clf = LDA()\n",
        "  clf.fit(Xd, yd)\n",
        "  lda = LDA(n_components=None, priors=None, shrinkage=None, solver='svd',store_covariance=False, tol=0.0001)\n",
        "  X_r2 = lda.fit(Xd, yd).transform(Xd)\n",
        "\n",
        "  plt.figure(figsize=(8,6))\n",
        "  for i in range(len(names)):\n",
        "    plt.scatter(X_r2[yd == i, 0], X_r2[yd == i, 1], label=names[i], alpha=0.3, c=colors[i])\n",
        "\n",
        "  plt.xlabel('LDA Dim 1')\n",
        "  plt.ylabel('LDA Dim 2')\n",
        "  plt.legend(\n",
        "      loc='upper left',\n",
        "      bbox_to_anchor=(1, 1),\n",
        "      shadow=False,\n",
        "      scatterpoints=1\n",
        "  );\n",
        "  plt.show()\n",
        "  print('\\n\\n')\n",
        "\n",
        "\n",
        "  # LDA 1D Distributions\n",
        "  plt.figure(figsize=(8,6))\n",
        "  for i in range(len(names)):\n",
        "    plt.hist(X_r2[yd == i, 0],20, density=True, label=names[i], alpha=0.5, color=colors[i])\n",
        "\n",
        "  plt.xlabel('LDA Dim 1')\n",
        "  plt.ylabel('Frac. of Examples Per Class')\n",
        "  plt.legend(\n",
        "      loc='upper left',\n",
        "      bbox_to_anchor=(1, 1),\n",
        "      shadow=False,\n",
        "      scatterpoints=1\n",
        "  );\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  # TSNE\n",
        "  tsne = TSNE(n_components=2, random_state=0)\n",
        "  Xt = tsne.fit_transform(Xd)\n",
        "\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  for i in range(len(names)):\n",
        "    plt.scatter(Xt[yd == i, 0], Xt[yd == i, 1], label=names[i], alpha=0.3, c=colors[i])\n",
        "\n",
        "  plt.xlabel('t-SNE Dim 1')\n",
        "  plt.ylabel('t-SNE Dim 2')\n",
        "  plt.legend(\n",
        "      loc='upper left',\n",
        "      bbox_to_anchor=(1, 1),\n",
        "      shadow=False,\n",
        "      scatterpoints=1\n",
        "  );\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def reshape_time_crop_patch_embeddings(\n",
        "    x,\n",
        "    patch_reorder_shape,\n",
        "    start=None,\n",
        "    end=None,\n",
        "):\n",
        "  \"\"\"Reshape n_token embeddeding into an image of embeddedings.\"\"\"\n",
        "  # Get patch and input shape.\n",
        "  n_h, n_w = patch_reorder_shape\n",
        "  n_batch, n_tokens, embedding_dim = x.shape  # pylint: disable=unused-variable\n",
        "\n",
        "  # Get start and end crop (along time axis).\n",
        "  if end is None:\n",
        "    end = 1\n",
        "  if start is None:\n",
        "    start = 0\n",
        "  if start \u003e= end:\n",
        "    raise ValueError(f'start {start}, is greater than end {end}.')\n",
        "  if start \u003e 1 or end \u003e 1:\n",
        "    raise ValueError(f'start {start} and end {end} cannot be greater than 1.')\n",
        "\n",
        "  # reorganize patches into image:\n",
        "  x = jnp.reshape(x, [n_batch, n_h, n_w, embedding_dim])\n",
        "\n",
        "  # Time Crop image based on horizon\n",
        "  start_idx = int(start * n_h)\n",
        "  end_idx = int(end * n_h)\n",
        "  x = x[:, start_idx:end_idx, :, :]\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-cTA1zHtzun"
      },
      "outputs": [],
      "source": [
        "# Setup XM Client\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF5YVaty_9cX"
      },
      "outputs": [],
      "source": [
        "datasizes = [1000, 10000, 100000, 750000, 1321235]\n",
        "step_scaling = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-bFJ1xafI1M"
      },
      "source": [
        "# Confusion Matrix Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTBP0OGCK-o6"
      },
      "source": [
        "## LSM (Base) Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-HfpX7r8AIr"
      },
      "outputs": [],
      "source": [
        "XID = 126268296\n",
        "WID = 1\n",
        "\n",
        "lsm_ft_xm_id_dict = {\n",
        "    XID: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Activity finetune',\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_ft_df = get_metrics_df(lsm_ft_xm_id_dict)\n",
        "lsm_ft_df = lsm_ft_df[lsm_ft_df['wid'] == WID]\n",
        "lsm_ft_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDTcbGZYK_6X"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "step = 300\n",
        "file_name = os.path.join('/cns/dz-d/home/xliucs/lsm/xm/', str(XID), str(WID))\n",
        "cm_file_name = os.path.join(file_name, f'valid_confusion_matrix_{step}.npy')\n",
        "cm_labels_file_name = os.path.join(file_name, f'valid_confusion_matrix_labels_{step}.npy')\n",
        "\n",
        "print('Reading CM File:', cm_file_name)\n",
        "with gfile.Open(cm_file_name, 'rb') as f:\n",
        "  cm = np.load(f)\n",
        "\n",
        "print('Reading CM Labels File:', cm_labels_file_name)\n",
        "with gfile.Open(cm_labels_file_name, 'rb') as f:\n",
        "  cm_labels = np.load(f)\n",
        "\n",
        "confusion_matrix_fig(cm, cm_labels, scale=1.2);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehjgkRPBJKG6"
      },
      "source": [
        "## LSM (Base) Linear Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7OUB1BjJNAu"
      },
      "outputs": [],
      "source": [
        "XID = 126388131\n",
        "WID = 1\n",
        "\n",
        "lsm_lp_xm_id_dict = {\n",
        "    XID: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "        'meta_data': 'Activity linear probe',\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_lp_df = get_metrics_df(lsm_lp_xm_id_dict)\n",
        "lsm_lp_df = lsm_lp_df[lsm_lp_df['wid'] == WID]\n",
        "lsm_lp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qROwwl7bJh96"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "step = 300\n",
        "file_name = os.path.join('/cns/dz-d/home/xliucs/lsm/xm/', str(XID), str(WID))\n",
        "cm_file_name = os.path.join(file_name, f'valid_confusion_matrix_{step}.npy')\n",
        "cm_labels_file_name = os.path.join(file_name, f'valid_confusion_matrix_labels_{step}.npy')\n",
        "\n",
        "print('Reading CM File:', cm_file_name)\n",
        "with gfile.Open(cm_file_name, 'rb') as f:\n",
        "  cm = np.load(f)\n",
        "\n",
        "print('Reading CM Labels File:', cm_labels_file_name)\n",
        "with gfile.Open(cm_labels_file_name, 'rb') as f:\n",
        "  cm_labels = np.load(f)\n",
        "\n",
        "confusion_matrix_fig(cm, cm_labels, scale=1.2);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bba-V8_aXEiD"
      },
      "source": [
        "# I. Classification Fewshot Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tvMVm7_qq9i"
      },
      "source": [
        "## Activity Recognition Fewshot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Bg7V9qa0Icpy"
      },
      "outputs": [],
      "source": [
        "# @title Linear Probe Fewshot Results\n",
        "\n",
        "fewshot_lp_xm_id_dict = {\n",
        "    126994618: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    126994444: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    126993637: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    126993590: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "    126993446: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 1\n",
        "    },\n",
        "}\n",
        "\n",
        "fewshot_lp_df = get_metrics_df(fewshot_lp_xm_id_dict)\n",
        "fewshot_lp_df = fewshot_lp_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.005\n",
        "plt_fewshot_lp_df = fewshot_lp_df[fewshot_lp_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_lp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zVQ8kZLbJI-E"
      },
      "outputs": [],
      "source": [
        "# @title Linear Finetune Fewshot Results\n",
        "\n",
        "fewshot_ft_xm_id_dict = {\n",
        "    126950705: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'fine tune',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    126949674: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'fine tune',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    126949222: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'fine tune',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    126948854: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'fine tune',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "    126947854: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'fine tune',\n",
        "        'spc': 1\n",
        "    },\n",
        "}\n",
        "\n",
        "fewshot_ft_df = get_metrics_df(fewshot_ft_xm_id_dict)\n",
        "fewshot_ft_df = fewshot_ft_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.0005\n",
        "plt_fewshot_ft_df = fewshot_ft_df[fewshot_ft_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_ft_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZEbBXLntI8TG"
      },
      "outputs": [],
      "source": [
        "# @title Conv Probe Fewshot Results\n",
        "\n",
        "fewshot_cp_xm_id_dict = {\n",
        "    126972479: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    126993248: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    126971980: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    126971054: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "    126970538: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "        'spc': 1\n",
        "    },\n",
        "}\n",
        "\n",
        "fewshot_cp_df = get_metrics_df(fewshot_cp_xm_id_dict)\n",
        "fewshot_cp_df = fewshot_cp_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.0005\n",
        "plt_fewshot_cp_df = fewshot_cp_df[fewshot_cp_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_cp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xQRFEPrNGDFJ"
      },
      "outputs": [],
      "source": [
        "# @title Supervised Fewshot Results\n",
        "\n",
        "fewshot_supervised_xm_id_dict = {\n",
        "    127069108: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'supervised',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    127068936: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'supervised',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    127068506: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'supervised',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    127063814: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'supervised',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "    127068122: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'supervised',\n",
        "        'spc': 1\n",
        "    },\n",
        "}\n",
        "\n",
        "fewshot_supervised_df = get_metrics_df(fewshot_supervised_xm_id_dict)\n",
        "fewshot_supervised_df = fewshot_supervised_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.005\n",
        "plt_fewshot_supervised_df = fewshot_supervised_df[fewshot_supervised_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_supervised_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i3fteqHJLY7j"
      },
      "outputs": [],
      "source": [
        "# @title Plotting of AR Fewshotting\n",
        "\n",
        "# Linear Probe\n",
        "lp_spc = plt_fewshot_lp_df['fewshot_samples_per_class']\n",
        "lp_acc = plt_fewshot_lp_df['final_valid_accuracy'] * 100\n",
        "lp_map = plt_fewshot_lp_df['final_valid_mAP'] * 100\n",
        "\n",
        "# Convolutional Probe\n",
        "cp_spc = plt_fewshot_cp_df['fewshot_samples_per_class']\n",
        "cp_acc = plt_fewshot_cp_df['final_valid_accuracy'] * 100\n",
        "cp_map = plt_fewshot_cp_df['final_valid_mAP'] * 100\n",
        "\n",
        "# Finetune\n",
        "ft_spc = plt_fewshot_ft_df['fewshot_samples_per_class']\n",
        "ft_acc = plt_fewshot_ft_df['final_valid_accuracy'] * 100\n",
        "ft_map = plt_fewshot_ft_df['final_valid_mAP'] * 100\n",
        "\n",
        "# Supervised\n",
        "sup_spc = plt_fewshot_supervised_df['fewshot_samples_per_class']\n",
        "sup_acc = plt_fewshot_supervised_df['final_valid_accuracy'] * 100\n",
        "sup_map = plt_fewshot_supervised_df['final_valid_mAP'] * 100\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ft_spc, ft_acc, '--o', color='r', label='fine-tune')\n",
        "plt.plot(cp_spc, cp_acc, '--o', color='cornflowerblue', label='convolutional probe')\n",
        "plt.plot(lp_spc, lp_acc, '--o', color='gold', label='linear probe')\n",
        "plt.plot(sup_spc, sup_acc, '--o', color='black', label='supervised')\n",
        "plt.xlabel('Fewshot Samples Per Class')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ft_spc, ft_map, '--o', color='r', label='fine-tune')\n",
        "plt.plot(cp_spc, cp_map, '--o', color='cornflowerblue', label='convolutional probe')\n",
        "plt.plot(lp_spc, lp_map, '--o', color='gold', label='linear probe')\n",
        "plt.plot(sup_spc, sup_map, '--o', color='black', label='supervised')\n",
        "plt.xlabel('Fewshot Samples Per Class')\n",
        "plt.ylabel('mAP')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q48mDauaQzpN"
      },
      "source": [
        "## Exercise Detection (Activity vs Mood Events) Fewshot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s4JlZv_TQyuh"
      },
      "outputs": [],
      "source": [
        "# @title Linear Probe Fewshot Results\n",
        "\n",
        "fewshot_lp_xm_id_dict = {\n",
        "    128157854: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    128162567: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    128162668: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    128163759: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "    128162732: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'spc': 1\n",
        "    },\n",
        "}\n",
        "\n",
        "fewshot_lp_df = get_metrics_df(fewshot_lp_xm_id_dict)\n",
        "fewshot_lp_df = fewshot_lp_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.005\n",
        "plt_fewshot_lp_df = fewshot_lp_df[fewshot_lp_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_lp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pWmr4PXCeUbz"
      },
      "outputs": [],
      "source": [
        "# @title Finetune Fewshot Results\n",
        "\n",
        "fewshot_ft_xm_id_dict = {\n",
        "    128423107: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    128424721: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    128425248: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    128426616: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "fewshot_ft_df = get_metrics_df(fewshot_ft_xm_id_dict)\n",
        "fewshot_ft_df = fewshot_ft_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.0005\n",
        "plt_fewshot_ft_df = fewshot_ft_df[fewshot_ft_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_ft_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ojdl19NPgHHT"
      },
      "outputs": [],
      "source": [
        "# @title Conv Probe Fewshot Results\n",
        "\n",
        "fewshot_cp_xm_id_dict = {\n",
        "    128427223: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    128427386: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    128427409: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    128427562: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "fewshot_cp_df = get_metrics_df(fewshot_cp_xm_id_dict)\n",
        "fewshot_cp_df = fewshot_cp_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.005\n",
        "plt_fewshot_cp_df = fewshot_cp_df[fewshot_cp_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_cp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_E7ikW2HIk7N"
      },
      "outputs": [],
      "source": [
        "# @title Supervised VIT Fewshot Results\n",
        "\n",
        "fewshot_sup_xm_id_dict = {\n",
        "    128448867: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 20\n",
        "    },\n",
        "\n",
        "    128448952: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 15\n",
        "    },\n",
        "\n",
        "    128449985: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 10\n",
        "    },\n",
        "\n",
        "    128451858: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'spc': 5\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "fewshot_sup_df = get_metrics_df(fewshot_sup_xm_id_dict)\n",
        "fewshot_sup_df = fewshot_sup_df.sort_values(by='fewshot_samples_per_class', ascending=True)\n",
        "\n",
        "lr = 0.00005\n",
        "plt_fewshot_sup_df = fewshot_sup_df[fewshot_sup_df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "plt_fewshot_sup_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hB0s0HEFVhDd"
      },
      "outputs": [],
      "source": [
        "# @title Plotting of ED Fewshotting\n",
        "\n",
        "# Linear Probe\n",
        "lp_spc = plt_fewshot_lp_df['fewshot_samples_per_class']\n",
        "lp_acc = plt_fewshot_lp_df['final_valid_accuracy'] * 100\n",
        "lp_map = plt_fewshot_lp_df['final_valid_mAP'] * 100\n",
        "\n",
        "# Convolutional Probe\n",
        "cp_spc = plt_fewshot_cp_df['fewshot_samples_per_class']\n",
        "cp_acc = plt_fewshot_cp_df['final_valid_accuracy'] * 100\n",
        "cp_map = plt_fewshot_cp_df['final_valid_mAP'] * 100\n",
        "\n",
        "# Finetune\n",
        "ft_spc = plt_fewshot_ft_df['fewshot_samples_per_class']\n",
        "ft_acc = plt_fewshot_ft_df['final_valid_accuracy'] * 100\n",
        "ft_map = plt_fewshot_ft_df['final_valid_mAP'] * 100\n",
        "\n",
        "# Supervised\n",
        "sup_spc = plt_fewshot_supervised_df['fewshot_samples_per_class']\n",
        "sup_acc = plt_fewshot_supervised_df['final_valid_accuracy'] * 100\n",
        "sup_map = plt_fewshot_supervised_df['final_valid_mAP'] * 100\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ft_spc, ft_acc, '--o', color='r', label='fine-tune')\n",
        "plt.plot(cp_spc, cp_acc, '--o', color='cornflowerblue', label='convolutional probe')\n",
        "plt.plot(lp_spc, lp_acc, '--o', color='gold', label='linear probe')\n",
        "plt.plot(sup_spc, sup_acc, '--o', color='black', label='supervised')\n",
        "plt.xlabel('Fewshot Samples Per Class')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ft_spc, ft_map, '--o', color='r', label='fine-tune')\n",
        "plt.plot(cp_spc, cp_map, '--o', color='cornflowerblue', label='convolutional probe')\n",
        "plt.plot(lp_spc, lp_map, '--o', color='gold', label='linear probe')\n",
        "plt.plot(sup_spc, sup_map, '--o', color='black', label='supervised')\n",
        "plt.xlabel('Fewshot Samples Per Class')\n",
        "plt.ylabel('mAP')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0sUrfwd-rOJ"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/128157854/3', 'spc':20},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/128162567/3', 'spc':15},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/128162668/3', 'spc':10},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/128163759/3', 'spc':5},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_lp_xm_id_dict = {\n",
        "    128411339: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_lp_df = get_metrics_df(lsm_lp_xm_id_dict)\n",
        "lsm_lp_df\n",
        "\n",
        "merged_df = pd.merge(lsm_lp_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n",
        "merged_df[merged_df['spc'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGvo47AvXfYr"
      },
      "source": [
        "# II. Classification (Pre-train) Data Scaling Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0uBl4mc2uNl"
      },
      "source": [
        "## Acitivity Recongition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MIBXWHlf2wYi"
      },
      "outputs": [],
      "source": [
        "# @title Finetune results\n",
        "\n",
        "act_xm_id_dict = {\n",
        "    127126620: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "act_sweep_df = get_metrics_df(act_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['train_data_size'].astype(int)\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "\n",
        "# Add table results (for best model), run in a different XM job\n",
        "table_results_act_xm_id_dict = {\n",
        "    125999449: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "        'train_data_size': datasizes[-1],\n",
        "        'config.init_from.checkpoint_step': 50000,\n",
        "    }\n",
        "}\n",
        "\n",
        "table_act_sweep_df = get_metrics_df(table_results_act_xm_id_dict)\n",
        "table_act_sweep_df = table_act_sweep_df[table_act_sweep_df['config.linear_dropout_rate'] == 0.3]\n",
        "table_act_sweep_df\n",
        "\n",
        "# Merge tables\n",
        "merge_cols = ['config.init_from.checkpoint_step', 'train_data_size']\n",
        "act_sweep_df = pd.concat([act_sweep_df, table_act_sweep_df], ignore_index=True)\n",
        "act_finetune_sweep_df = act_sweep_df.drop_duplicates(subset=merge_cols, keep='last')\n",
        "act_finetune_sweep_df\n",
        "\n",
        "ft_sub_df = act_finetune_sweep_df[act_finetune_sweep_df['config.init_from.checkpoint_step'] == 50000]\n",
        "ft_train_size = ft_sub_df['train_data_size'].astype(int)\n",
        "ft_acc = ft_sub_df['final_valid_accuracy'] * 100\n",
        "ft_map = ft_sub_df['final_valid_mAP'] * 100\n",
        "ft_sub_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5CEZgRKRAmee"
      },
      "outputs": [],
      "source": [
        "# @title Linear Probe Results\n",
        "\n",
        "act_xm_id_dict = {\n",
        "    127224896: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "act_sweep_df = get_metrics_df(act_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['train_data_size'].astype(int)\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "\n",
        "# Add table results (for best model), run in a different XM job\n",
        "table_results_act_xm_id_dict = {\n",
        "    126009342: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "        'train_data_size': datasizes[-1],\n",
        "        'config.init_from.checkpoint_step': 50000,\n",
        "    }\n",
        "}\n",
        "\n",
        "table_act_sweep_df = get_metrics_df(table_results_act_xm_id_dict)\n",
        "table_act_sweep_df = table_act_sweep_df[table_act_sweep_df['config.linear_dropout_rate'] == 0.3]\n",
        "table_act_sweep_df\n",
        "\n",
        "# Merge tables\n",
        "merge_cols = ['config.init_from.checkpoint_step', 'train_data_size']\n",
        "act_sweep_df = pd.concat([act_sweep_df, table_act_sweep_df], ignore_index=True)\n",
        "act_linearprobe_sweep_df = act_sweep_df.drop_duplicates(subset=merge_cols, keep='last')\n",
        "act_linearprobe_sweep_df\n",
        "\n",
        "\n",
        "lp_sub_df = act_linearprobe_sweep_df[act_linearprobe_sweep_df['config.init_from.checkpoint_step'] == 50000]\n",
        "lp_train_size = lp_sub_df['train_data_size'].astype(int)\n",
        "lp_acc = lp_sub_df['final_valid_accuracy'] * 100\n",
        "lp_map = lp_sub_df['final_valid_mAP'] * 100\n",
        "lp_sub_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28vM-hN2Betk"
      },
      "outputs": [],
      "source": [
        "# @title Conv Probe Results\n",
        "\n",
        "act_xm_id_dict = {\n",
        "    127225258: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "act_sweep_df = get_metrics_df(act_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['train_data_size'].astype(int)\n",
        "act_sweep_df['train_data_size'] = act_sweep_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "\n",
        "# Add table results (for best model), run in a different XM job\n",
        "table_results_act_xm_id_dict = {\n",
        "    126030364: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "        'train_data_size': datasizes[-1],\n",
        "        'config.init_from.checkpoint_step': 50000,\n",
        "    }\n",
        "}\n",
        "\n",
        "table_act_sweep_df = get_metrics_df(table_results_act_xm_id_dict)\n",
        "table_act_sweep_df = table_act_sweep_df[table_act_sweep_df['config.linear_dropout_rate'] == 0.3]\n",
        "table_act_sweep_df\n",
        "\n",
        "# Merge tables\n",
        "merge_cols = ['config.init_from.checkpoint_step', 'train_data_size']\n",
        "act_sweep_df = pd.concat([act_sweep_df, table_act_sweep_df], ignore_index=True)\n",
        "act_convprobe_sweep_df = act_sweep_df.drop_duplicates(subset=merge_cols, keep='last')\n",
        "act_convprobe_sweep_df\n",
        "\n",
        "\n",
        "cp_sub_df = act_convprobe_sweep_df[act_convprobe_sweep_df['config.init_from.checkpoint_step'] == 50000]\n",
        "cp_train_size = cp_sub_df['train_data_size'].astype(int)\n",
        "cp_acc = cp_sub_df['final_valid_accuracy'] * 100\n",
        "cp_map = cp_sub_df['final_valid_mAP'] * 100\n",
        "cp_sub_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMOLAgN78m4w"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "# plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.plot(ft_train_size, ft_acc, '--o', color='r', label='fine tune')\n",
        "plt.plot(lp_train_size, lp_acc, '--o', color='cornflowerblue', label='linear probe')\n",
        "plt.plot(cp_train_size, cp_acc, '--o', color='gold', label='conv probe')\n",
        "plt.xlabel('Train Data Size')\n",
        "plt.ylabel('Acc.')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "# plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.plot(ft_train_size, ft_map, '--o', color='r', label='fine-tune')\n",
        "plt.plot(lp_train_size, lp_map, '--o', color='cornflowerblue', label='linear probe')\n",
        "plt.plot(cp_train_size, cp_map, '--o', color='gold', label='conv probe')\n",
        "plt.xlabel('Train Data Size')\n",
        "plt.ylabel('mAP')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSA3RctUIGA2"
      },
      "source": [
        "## Exercise Detection (Activity vs Mood Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x_dH4bdZIHl_"
      },
      "outputs": [],
      "source": [
        "# @title Finetune results\n",
        "\n",
        "mood_act_xm_id_dict = {\n",
        "    127138981: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'finetune',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "mood_act_sweep_df = get_metrics_df(mood_act_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['train_data_size'].astype(int)\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "mood_act_finetune_sweep_df = mood_act_sweep_df\n",
        "mood_act_finetune_sweep_df\n",
        "\n",
        "ft_sub_df = mood_act_finetune_sweep_df[mood_act_finetune_sweep_df['config.init_from.checkpoint_step'] == 50000]\n",
        "ft_train_size = ft_sub_df['train_data_size'].astype(int)\n",
        "ft_acc = ft_sub_df['final_valid_accuracy'] * 100\n",
        "ft_map = ft_sub_df['final_valid_mAP'] * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xpt55SUSEQle"
      },
      "outputs": [],
      "source": [
        "# @title Linear Probe results\n",
        "\n",
        "mood_act_xm_id_dict = {\n",
        "    127198831: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'linear probe',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "mood_act_sweep_df = get_metrics_df(mood_act_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['train_data_size'].astype(int)\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "mood_act_linearprobe_sweep_df = mood_act_sweep_df\n",
        "mood_act_linearprobe_sweep_df\n",
        "\n",
        "lp_sub_df = mood_act_linearprobe_sweep_df[mood_act_linearprobe_sweep_df['config.init_from.checkpoint_step'] == 50000]\n",
        "lp_train_size = lp_sub_df['train_data_size'].astype(int)\n",
        "lp_acc = lp_sub_df['final_valid_accuracy'] * 100\n",
        "lp_map = lp_sub_df['final_valid_mAP'] * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rTkv6U-EEjFN"
      },
      "outputs": [],
      "source": [
        "# @title Conv Probe results\n",
        "\n",
        "mood_act_xm_id_dict = {\n",
        "    127225558: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'conv probe',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "mood_act_sweep_df = get_metrics_df(mood_act_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['train_data_size'].astype(int)\n",
        "mood_act_sweep_df['train_data_size'] = mood_act_sweep_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "mood_act_convprobe_sweep_df = mood_act_sweep_df\n",
        "mood_act_convprobe_sweep_df\n",
        "\n",
        "cp_sub_df = mood_act_convprobe_sweep_df[mood_act_convprobe_sweep_df['config.init_from.checkpoint_step'] == 50000]\n",
        "cp_train_size = cp_sub_df['train_data_size'].astype(int)\n",
        "cp_acc = cp_sub_df['final_valid_accuracy'] * 100\n",
        "cp_map = cp_sub_df['final_valid_mAP'] * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkduLF_yI08c"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "# plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.plot(ft_train_size, ft_acc, '--o', color='r', label='fine tune')\n",
        "plt.plot(lp_train_size, lp_acc, '--o', color='cornflowerblue', label='linear probe')\n",
        "plt.plot(cp_train_size, cp_acc, '--o', color='gold', label='conv probe')\n",
        "plt.xlabel('Train Data Size')\n",
        "plt.ylabel('Acc.')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "# plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.plot(ft_train_size, ft_map, '--o', color='r', label='fine-tune')\n",
        "plt.plot(lp_train_size, lp_map, '--o', color='cornflowerblue', label='linear probe')\n",
        "plt.plot(cp_train_size, cp_map, '--o', color='gold', label='conv probe')\n",
        "plt.xlabel('Train Data Size')\n",
        "plt.ylabel('mAP')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZAl12TZPeOK"
      },
      "source": [
        "# III. Fixed Classification mAP Results\n",
        "\n",
        "The original immplementation of mAP was incorrect (based off predictions not logits). To remedy this eval was re-run for each AR / ED classification for both (Pre-train) Data Scaling and Fewshot experiments.\n",
        "\n",
        "NOTE:\n",
        "Fewshots experiment result need only be remedied for AR. ED fewshot results were run AFTER the bug was caught and fixed.\n",
        "\n",
        "The remedied results are presented below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1t3nA-LrwPN"
      },
      "source": [
        "## Activity Recognition (Fewshot and Data Scaling Experiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqpX9ZB4fXVE"
      },
      "source": [
        "### Linear Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYo70rzkPfTm"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126009342/2', 'data_size':1321235},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127224896/24', 'data_size':750000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127224896/18', 'data_size':100000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127224896/12', 'data_size':10000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127224896/6', 'data_size':1000},\n",
        "\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126994618/2', 'spc':20},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126994444/2', 'spc':15},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126993637/2', 'spc':10},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126993590/2', 'spc':5},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_lp_xm_id_dict = {\n",
        "    128247616: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_lp_df = get_metrics_df(lsm_lp_xm_id_dict)\n",
        "lsm_lp_df\n",
        "\n",
        "merged_df = pd.merge(lsm_lp_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waVqqtBtZ7_n"
      },
      "outputs": [],
      "source": [
        "# Fewshot results\n",
        "merged_df[merged_df['spc'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "596-mrVEanm_"
      },
      "outputs": [],
      "source": [
        "# Data scaling results\n",
        "merged_df[merged_df['data_size'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEQ3YAKXfa6W"
      },
      "source": [
        "### Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uNTguKocoTm"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/125999449/2', 'data_size':1321235},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127126620/24', 'data_size':750000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127126620/18', 'data_size':100000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127126620/12', 'data_size':10000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127126620/6', 'data_size':1000},\n",
        "\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126950705/1', 'spc':20},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126949674/1', 'spc':15},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126949222/1', 'spc':10},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126948854/1', 'spc':5},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_ft_xm_id_dict = {\n",
        "    128258737: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_ft_df = get_metrics_df(lsm_ft_xm_id_dict)\n",
        "lsm_ft_df\n",
        "\n",
        "merged_df = pd.merge(lsm_ft_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBGkEP6-aD3u"
      },
      "outputs": [],
      "source": [
        "# Fewshot results\n",
        "merged_df[merged_df['spc'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrPN31XOfzd4"
      },
      "outputs": [],
      "source": [
        "# Data scaling results\n",
        "merged_df[merged_df['data_size'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4p75F60iqfJ"
      },
      "source": [
        "### Conv Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJDLOQzZisCh"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126030364/6', 'data_size':1321235},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225258/24', 'data_size':750000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225258/18', 'data_size':100000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225258/12', 'data_size':10000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225258/6', 'data_size':1000},\n",
        "\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126972479/1', 'spc':20},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126993248/1', 'spc':15},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126971980/1', 'spc':10},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/126971054/1', 'spc':5},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_cp_xm_id_dict = {\n",
        "    128261369: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "    128368341: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_cp_df = get_metrics_df(lsm_cp_xm_id_dict)\n",
        "lsm_cp_df\n",
        "\n",
        "merged_df = pd.merge(lsm_cp_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n",
        "merged_df[merged_df['spc'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f-qk3ZyjFQJ"
      },
      "outputs": [],
      "source": [
        "# Fewshot results\n",
        "merged_df[merged_df['spc'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ytAZA-caKQc"
      },
      "outputs": [],
      "source": [
        "# Data scaling results\n",
        "merged_df[merged_df['data_size'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP119-OqrzFT"
      },
      "source": [
        "## Exercise Detection (Data Scaling Experiments)\n",
        "\n",
        "NOTE: ED Fewshot Results are Correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfWeHOj-z9xc"
      },
      "source": [
        "### Linear Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iSwvUknr0Jk"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127198831/30', 'data_size':1321235},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127198831/24', 'data_size':750000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127198831/18', 'data_size':100000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127198831/12', 'data_size':10000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127198831/6', 'data_size':1000},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_lp_xm_id_dict = {\n",
        "    128376553: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_lp_df = get_metrics_df(lsm_lp_xm_id_dict)\n",
        "lsm_lp_df\n",
        "\n",
        "merged_df = pd.merge(lsm_lp_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n",
        "merged_df[merged_df['data_size'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf6BYLwO09Rn"
      },
      "source": [
        "### Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl5jkZxS0-f6"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127138981/30', 'data_size':1321235},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127138981/24', 'data_size':750000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127138981/18', 'data_size':100000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127138981/12', 'data_size':10000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127138981/6', 'data_size':1000},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_ft_xm_id_dict = {\n",
        "    128377260: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_ft_df = get_metrics_df(lsm_ft_xm_id_dict)\n",
        "lsm_ft_df\n",
        "\n",
        "merged_df = pd.merge(lsm_ft_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n",
        "merged_df[merged_df['data_size'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiC7a2_H13zI"
      },
      "source": [
        "### Conv Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeIF16T2147H"
      },
      "outputs": [],
      "source": [
        "meta_data = [\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225558/30', 'data_size':1321235},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225558/24', 'data_size':750000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225558/18', 'data_size':100000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225558/12', 'data_size':10000},\n",
        "    {'config.init_from.checkpoint_dir': '/cns/dz-d/home/xliucs/lsm/xm/127225558/6', 'data_size':1000},\n",
        "]\n",
        "\n",
        "meta_df = pd.DataFrame(meta_data)\n",
        "\n",
        "lsm_cp_xm_id_dict = {\n",
        "    128377364: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'loss_only_masked_patches': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "lsm_cp_df = get_metrics_df(lsm_cp_xm_id_dict)\n",
        "lsm_cp_df\n",
        "\n",
        "merged_df = pd.merge(lsm_cp_df, meta_df, on='config.init_from.checkpoint_dir', how='inner')\n",
        "merged_df[merged_df['data_size'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_WD2jb_HeXD"
      },
      "source": [
        "# IV. Generative Eval\n",
        "\n",
        "Below is a supplemental analysis for generative eval.\n",
        "It focuses on adding 0.034 and 0.067 mask-percentage time-imputation/forecast tasks.\n",
        "\n",
        "It additionally adds a large sweep on the sensor imputation task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywAhbBzQxkrf"
      },
      "source": [
        "## Supplemental Generative Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRxiyYp1X0V7"
      },
      "outputs": [],
      "source": [
        "gen_eval_xm_id_dict = {\n",
        "    127392302: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'generative eval',\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "gen_eval_df = get_metrics_df(gen_eval_xm_id_dict)\n",
        "\n",
        "# Add train sizes\n",
        "gen_eval_df['train_data_size'] = gen_eval_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "gen_eval_df['train_data_size'] = gen_eval_df['train_data_size'].astype(int)\n",
        "gen_eval_df['train_data_size'] = gen_eval_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "\n",
        "# Cut down to 50K step pretraining, on max pretrain size (1.65M)\n",
        "sub_gen_eval_df = gen_eval_df[gen_eval_df['train_data_size'] == datasizes[-1]]\n",
        "sub_gen_eval_df = sub_gen_eval_df[sub_gen_eval_df['config.init_from.checkpoint_step'] == 50000]\n",
        "sub_gen_eval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxLSiauMLA7z"
      },
      "outputs": [],
      "source": [
        "sen_imp = [\n",
        "    'final_sensor_imputation_0.2_eval/valid_mean_absolute_error_masked',\n",
        "    'final_sensor_imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'final_sensor_imputation_0.4_eval/valid_mean_absolute_error_masked',\n",
        "    'final_sensor_imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'final_sensor_imputation_0.5_eval/valid_mean_absolute_error_masked',\n",
        "    'final_sensor_imputation_0.5_eval/valid_mean_squared_error_masked'\n",
        "]\n",
        "\n",
        "imp_10_20 = [\n",
        "    'final_imputation_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'final_imputation_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'final_imputation_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'final_imputation_0.067_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "for_10_20 = [\n",
        "    'final_forecast_0.034_eval/valid_mean_absolute_error_masked',\n",
        "    'final_forecast_0.034_eval/valid_mean_squared_error_masked',\n",
        "    'final_forecast_0.067_eval/valid_mean_absolute_error_masked',\n",
        "    'final_forecast_0.067_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "s = ''\n",
        "for metric in sen_imp:\n",
        "  s += f'{list(sub_gen_eval_df[metric])[0]} \u0026 '\n",
        "print(s)\n",
        "print('\\n\\n')\n",
        "\n",
        "print('IMP 10 20 mins')\n",
        "s = ''\n",
        "for metric in imp_10_20:\n",
        "  s += f'{list(sub_gen_eval_df[metric])[0]} \u0026 '\n",
        "print(s)\n",
        "print('\\n\\n')\n",
        "\n",
        "\n",
        "print('FOR 10 20 mins')\n",
        "s = ''\n",
        "for metric in for_10_20:\n",
        "  s += f'{list(sub_gen_eval_df[metric])[0]} \u0026 '\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5oFVtPL_GEe"
      },
      "source": [
        "## SENSOR IMPUTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "loB70w-V_N4x"
      },
      "outputs": [],
      "source": [
        "# @title Get results\n",
        "\n",
        "gen_eval_xm_id_dict = {\n",
        "    128010871: {\n",
        "        'model_size': 'Base',\n",
        "        'feature_order': 'Ordered',\n",
        "        'type': 'generative eval',\n",
        "    }\n",
        "}\n",
        "\n",
        "# Get data from XM\n",
        "gen_eval_df = get_metrics_df(gen_eval_xm_id_dict)\n",
        "gen_eval_df['train_data_size'] = gen_eval_df['config.init_from.checkpoint_dir'].str.extract(r'/(\\d+)$')\n",
        "gen_eval_df['train_data_size'] = gen_eval_df['train_data_size'].astype(int)\n",
        "gen_eval_df['train_data_size'] = gen_eval_df['train_data_size'].apply(lambda x: datasizes[x - 1])\n",
        "gen_eval_df\n",
        "\n",
        "# Generate DF from single row df:\n",
        "df_rows = []\n",
        "for c in gen_eval_df.columns:\n",
        "  if 'valid' in c and 'final' in c and 'error' in c:\n",
        "    if gen_eval_df[c][0] is not None:\n",
        "      if len(c.split('_')) != 10:\n",
        "        continue\n",
        "\n",
        "      row = {\n",
        "          'task': c.split('_')[2],\n",
        "          'metric': c.split('/')[1],\n",
        "          'values': gen_eval_df[c][0],\n",
        "          'sensor_horizon': float(c.split('_')[3]),\n",
        "          'time_horizon': float(c.split('_')[4]),\n",
        "      }\n",
        "      df_rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(df_rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "63QjYoxIBb9W"
      },
      "outputs": [],
      "source": [
        "# @title Plot sensor imputation trends\n",
        "\n",
        "time_horizons = [0.034, 0.067, 0.1, 0.2, 0.4]\n",
        "sensor_horizons = [0.2, 0.4, 0.5, 0.7, 0.9, 1.0]\n",
        "metric = 'valid_mean_squared_error_masked'\n",
        "\n",
        "# Changing time horizon\n",
        "cp = sns.light_palette(\"#69d\", len(time_horizons) * 2, reverse=False).as_hex()\n",
        "plt.figure()\n",
        "for i, t in enumerate(time_horizons):\n",
        "  sub_df = df[df['time_horizon'] == t]\n",
        "  sub_df = sub_df[sub_df['metric'] == metric]\n",
        "  plt.plot(\n",
        "      sub_df['sensor_horizon'] * 6 * 5,\n",
        "      sub_df['values'],\n",
        "      '-o',\n",
        "      label=f'{int(t*300)}mins',\n",
        "      color=cp[i*2 + 1]\n",
        "  )\n",
        "\n",
        "plt.xlabel('Imputated Sensors')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "\n",
        "# Changing time horizon\n",
        "cp = sns.light_palette(\"#69d\", len(sensor_horizons) * 2, reverse=False).as_hex()\n",
        "plt.figure()\n",
        "for i, s in enumerate(sensor_horizons):\n",
        "  sub_df = df[df['sensor_horizon'] == s]\n",
        "  sub_df = sub_df[sub_df['metric'] == metric]\n",
        "  plt.plot(\n",
        "      sub_df['time_horizon'] * 300,\n",
        "      sub_df['values'],\n",
        "      '-o',\n",
        "      label=f'{5*int(6*s)} sensors',\n",
        "      color=cp[i*2 + 1]\n",
        "  )\n",
        "\n",
        "plt.xlabel('Imputation Time Horizon (mins)')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend(title='Imputed Sensors', loc='upper left', bbox_to_anchor=(1, 1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fw3S5-w6LK23",
        "H-bFJ1xafI1M",
        "BTBP0OGCK-o6",
        "ehjgkRPBJKG6",
        "8tvMVm7_qq9i",
        "Q48mDauaQzpN",
        "NGvo47AvXfYr",
        "T0uBl4mc2uNl",
        "SSA3RctUIGA2",
        "gZAl12TZPeOK",
        "L1t3nA-LrwPN",
        "aqpX9ZB4fXVE",
        "IEQ3YAKXfa6W",
        "r4p75F60iqfJ",
        "tP119-OqrzFT",
        "HfWeHOj-z9xc",
        "Nf6BYLwO09Rn",
        "OiC7a2_H13zI",
        "ywAhbBzQxkrf"
      ],
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
