{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzh4DG0fCRQO"
      },
      "outputs": [],
      "source": [
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')\n",
        "MEDIUM_SIZE = 14\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = 20\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "SMALL_SIZE = 16\n",
        "MEDIUM_SIZE = 15\n",
        "BIGGER_SIZE = 20\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcscg9dz_FTO"
      },
      "outputs": [],
      "source": [
        "def read_xm_metrics(example_xid, metric_name, unit_id, lowest=True):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if series.label == metric_name:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "      if lowest:\n",
        "        return min(all_measurements)\n",
        "      else:\n",
        "        return all_measurements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBQR_rQhVhd4"
      },
      "outputs": [],
      "source": [
        "metric_names = [\n",
        "    'train_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'train_mean_absolute_error_masked',\n",
        "    'valid_mean_absolute_error_masked',\n",
        "    'learning_rate',\n",
        "    'l2_grads',\n",
        "    'examples_seen'\n",
        "]\n",
        "\n",
        "xm_id = 117045959\n",
        "experiment = xm_client.get_experiment(xm_id)\n",
        "num_of_units = experiment.get_num_work_units()\n",
        "xm_exp_dict = collections.defaultdict(list)\n",
        "\n",
        "for id in range(num_of_units):\n",
        "  real_id = id + 1\n",
        "  work_unit = experiment.get_work_unit(real_id)\n",
        "  key_list = work_unit.parameters.keys()\n",
        "  xm_exp_dict['unit_id'].append(id)\n",
        "  xm_exp_dict['xm_id'].append(xm_id)\n",
        "  for param_name in key_list:\n",
        "    xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "  for metric in metric_names:\n",
        "    xm_exp_dict[metric].append(read_xm_metrics(xm_id, metric, real_id, lowest=False))\n",
        "\n",
        "df = pd.DataFrame(xm_exp_dict)\n",
        "df.info(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6m9nh51kpZY"
      },
      "outputs": [],
      "source": [
        "# Get unique learning rates\n",
        "unique_lr = df['config.schedule.all.lr_configs.base_learning_rate'].unique()\n",
        "\n",
        "# Set an elegant color palette\n",
        "palette = sns.color_palette(\"Set2\")\n",
        "color_mapping = dict(zip(df['config.optimizer.weight_decay'].unique(), palette))\n",
        "\n",
        "# Create subplots\n",
        "# Metrics to plot\n",
        "metrics = [\n",
        "    'train_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'train_mean_absolute_error_masked',\n",
        "    'valid_mean_absolute_error_masked'\n",
        "]\n",
        "\n",
        "# Create subplots\n",
        "plt.figure(figsize=(6 * len(unique_lr), 6 * len(metrics)), dpi=600)\n",
        "\n",
        "for row_idx, metric_name in enumerate(metrics):\n",
        "    for i, lr in enumerate(unique_lr):\n",
        "        plt.subplot(len(metrics), len(unique_lr), row_idx * len(unique_lr) + i + 1)\n",
        "        subset = df[df['config.schedule.all.lr_configs.base_learning_rate'] == lr]\n",
        "        for _, row in subset.iterrows():\n",
        "            x = list(range(len(row[metric_name])))\n",
        "            y = row[metric_name]\n",
        "            weight_decay = row['config.optimizer.weight_decay']\n",
        "            plt.plot(x, y, label=f\"{weight_decay}\", color=color_mapping[weight_decay])\n",
        "        plt.title(f'LR: {lr}')\n",
        "        if row_idx == len(metrics) - 1:\n",
        "            plt.xlabel('Steps (k)')\n",
        "        else:\n",
        "            plt.xlabel('')\n",
        "        if i == 0:\n",
        "            plt.ylabel(metric_name)\n",
        "        else:\n",
        "            plt.ylabel('')\n",
        "        # if row_idx == 0 and i == len(unique_lr) - 1:\n",
        "        plt.legend(title='Weight Decay', frameon=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Ablation Study of Learning Rate and Weight Decay Across Metrics + 1M Dataset + Large ViT', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yflJEaAq1Gn2"
      },
      "outputs": [],
      "source": [
        "unique_wd = df['config.optimizer.weight_decay'].unique()\n",
        "palette = sns.color_palette(\"Set2\")\n",
        "color_mapping = dict(zip(df['config.schedule.all.lr_configs.base_learning_rate'].unique(), palette))\n",
        "\n",
        "# Metrics to plot\n",
        "metrics = [\n",
        "    'train_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'train_mean_absolute_error_masked',\n",
        "    'valid_mean_absolute_error_masked'\n",
        "]\n",
        "\n",
        "# Create subplots\n",
        "plt.figure(figsize=(6 * len(unique_wd), 6 * len(metrics)), dpi=600)\n",
        "\n",
        "for row_idx, metric_name in enumerate(metrics):\n",
        "    for i, wd in enumerate(unique_wd):\n",
        "        plt.subplot(len(metrics), len(unique_wd), row_idx * len(unique_wd) + i + 1)\n",
        "        subset = df[df['config.optimizer.weight_decay'] == wd]\n",
        "        for _, row in subset.iterrows():\n",
        "            x = list(range(len(row[metric_name])))\n",
        "            y = row[metric_name]\n",
        "            learning_rate = row['config.schedule.all.lr_configs.base_learning_rate']\n",
        "            plt.plot(x, y, label=f\"{learning_rate}\", color=color_mapping[learning_rate])\n",
        "        plt.title(f'WD: {wd}')\n",
        "        if row_idx == len(metrics) - 1:\n",
        "            plt.xlabel('Steps (k)')\n",
        "        else:\n",
        "            plt.xlabel('')\n",
        "        if i == 0:\n",
        "            plt.ylabel(metric_name)\n",
        "        else:\n",
        "            plt.ylabel('')\n",
        "        plt.legend(title='Learning Rate', frameon=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Ablation Study of Learning Rate and Weight Decay Across Metrics + 1M Dataset + Large ViT', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37n-Du4R8Jvn"
      },
      "source": [
        "## Numerical Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2aztA791Gx3"
      },
      "outputs": [],
      "source": [
        "metric_names = [\n",
        "    'valid_mean_absolute_error_all',\n",
        "    'valid_mean_absolute_error_masked',\n",
        "    'valid_mean_squared_error_all',\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "\n",
        "xm_id = 117045959\n",
        "experiment = xm_client.get_experiment(xm_id)\n",
        "num_of_units = experiment.get_num_work_units()\n",
        "xm_exp_dict = collections.defaultdict(list)\n",
        "\n",
        "for id in range(num_of_units):\n",
        "  real_id = id + 1\n",
        "  work_unit = experiment.get_work_unit(real_id)\n",
        "  key_list = work_unit.parameters.keys()\n",
        "  xm_exp_dict['unit_id'].append(id)\n",
        "  xm_exp_dict['xm_id'].append(xm_id)\n",
        "  for param_name in key_list:\n",
        "    xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "  for metric in metric_names:\n",
        "    xm_exp_dict[metric].append(read_xm_metrics(xm_id, metric, real_id, lowest=True))\n",
        "\n",
        "df = pd.DataFrame(xm_exp_dict)\n",
        "df.info(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk99aSiW_KsS"
      },
      "outputs": [],
      "source": [
        "#@title Overall Ranking\n",
        "\n",
        "# Rank the configurations for each validation loss metric\n",
        "df['rank_valid_mean_absolute_error_all'] = df['valid_mean_absolute_error_all'].rank(method='min')\n",
        "df['rank_valid_mean_absolute_error_masked'] = df['valid_mean_absolute_error_masked'].rank(method='min')\n",
        "df['rank_valid_mean_squared_error_all'] = df['valid_mean_squared_error_all'].rank(method='min')\n",
        "df['rank_valid_mean_squared_error_masked'] = df['valid_mean_squared_error_masked'].rank(method='min')\n",
        "\n",
        "# Create a DataFrame to store the rankings\n",
        "rankings_df = df[['config.optimizer.weight_decay', 'config.schedule.all.lr_configs.base_learning_rate',\n",
        "                  'rank_valid_mean_absolute_error_all', 'rank_valid_mean_absolute_error_masked',\n",
        "                  'rank_valid_mean_squared_error_all', 'rank_valid_mean_squared_error_masked']]\n",
        "\n",
        "# Sort the rankings DataFrame by each ranking metric for better visualization\n",
        "rankings_df = rankings_df.sort_values(by=['rank_valid_mean_absolute_error_all',\n",
        "                                          'rank_valid_mean_absolute_error_masked',\n",
        "                                          'rank_valid_mean_squared_error_all',\n",
        "                                          'rank_valid_mean_squared_error_masked'])\n",
        "rankings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHrQ3UJ78Lnc"
      },
      "outputs": [],
      "source": [
        "fixed_weight_decay = 1e-4\n",
        "\n",
        "# Filter the DataFrame for the fixed weight decay\n",
        "filtered_df = df[df['config.optimizer.weight_decay'] == fixed_weight_decay]\n",
        "# Sort the filtered_df by the validation loss\n",
        "sorted_df = filtered_df.sort_values(by='valid_mean_absolute_error_all')\n",
        "# Count which learning rate values appear most frequently in the top 3 entries\n",
        "most_common_learning_rate = (\n",
        "    sorted_df['config.schedule.all.lr_configs.base_learning_rate']\n",
        "    .value_counts()\n",
        "    .idxmax()\n",
        ")\n",
        "\n",
        "most_common_learning_rate_count = (\n",
        "    sorted_df['config.schedule.all.lr_configs.base_learning_rate']\n",
        "    .value_counts()\n",
        "    .max()\n",
        ")\n",
        "\n",
        "# Display the most common learning rate and its count\n",
        "print(\n",
        "    'The most common learning rate in the top 3 entries is'\n",
        "    f' {most_common_learning_rate} and it appears'\n",
        "    f' {most_common_learning_rate_count} times.'\n",
        ")\n",
        "sorted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwdhQr539WzR"
      },
      "outputs": [],
      "source": [
        "# Fixed learning rate value, for example 0.001\n",
        "fixed_learning_rate = 5e-3\n",
        "\n",
        "# Filter the DataFrame for the fixed learning rate\n",
        "filtered_df = df[\n",
        "    df['config.schedule.all.lr_configs.base_learning_rate']\n",
        "    == fixed_learning_rate\n",
        "]\n",
        "\n",
        "# Sort the filtered DataFrame by the validation loss\n",
        "sorted_df = filtered_df.sort_values(by='valid_mean_absolute_error_all')\n",
        "\n",
        "# Count which weight decay values appear most frequently in the top 3 entries\n",
        "most_common_weight_decay = (\n",
        "    sorted_df['config.optimizer.weight_decay'].value_counts().idxmax()\n",
        ")\n",
        "\n",
        "most_common_weight_decay_count = (\n",
        "    sorted_df['config.optimizer.weight_decay'].value_counts().max()\n",
        ")\n",
        "\n",
        "# Display the most common weight decay and its count\n",
        "print(\n",
        "    'The most common weight decay in the top 3 entries is'\n",
        "    f' {most_common_weight_decay} and it appears'\n",
        "    f' {most_common_weight_decay_count} times.'\n",
        ")\n",
        "sorted_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1avNG7EtMynPa2U-GHj2nd4nWWdGzcFq3",
          "timestamp": 1719177577595
        },
        {
          "file_id": "1WdhekZ_TCf-uOIWufr8RjKRHUcB0jzoZ",
          "timestamp": 1719170535908
        },
        {
          "file_id": "1rMS2cnwRlpP6NSfAA_mDuXFnbLEc6UnM",
          "timestamp": 1718735304309
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
