{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzh4DG0fCRQO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import tempfile\n",
        "import warnings\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "from google3.pyglib import gfile\n",
        "from google3.pyglib.function_utils import memoize\n",
        "from matplotlib import font_manager\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.lines as mlines\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import FixedLocator  # Import for the fix\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from matplotlib.ticker import LogLocator\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "# Suppress specific warning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "\n",
        "# Import Google font family\n",
        "_GOOGLE_SANS_PATH = (\n",
        "    'google3/third_party/googlefonts/api/googlerestricted/googlesans/'\n",
        ")\n",
        "\n",
        "@memoize.Memoize()\n",
        "def import_google3_fonts(font_path: str) -\u003e None:\n",
        "  \"\"\"Import fonts stored in google3 into Matplotlib for use in Colab.\n",
        "\n",
        "  Args:\n",
        "    font_path: google3 path to either a directory that contains .ttf fonts or to\n",
        "      a specific .ttf font file.\n",
        "  \"\"\"\n",
        "  if gfile.IsDirectory(font_path):\n",
        "    # Create a temp directory as a destination for copied font files.\n",
        "    tmp_dir = tempfile.mkdtemp()\n",
        "    # Copy font files from google3 to temp dir.\n",
        "    gfile.RecursivelyCopyDir(font_path, tmp_dir, overwrite=True)\n",
        "    # Add font files in directory to matplotlib font_manager.\n",
        "    font_files = font_manager.findSystemFonts(fontpaths=tmp_dir)\n",
        "  else:\n",
        "    # Assume the path points to a file if it's not a directory.\n",
        "    # Copy ttf file from google3 to temp location.\n",
        "    tmp_file = tempfile.NamedTemporaryFile(suffix='.ttf')\n",
        "    tmp_file.close()\n",
        "    gfile.Copy(font_path, tmp_file.name)\n",
        "    font_files = [tmp_file.name]\n",
        "\n",
        "  # Add fonts to default font manager.\n",
        "  for font_file in font_files:\n",
        "    font_manager.fontManager.addfont(font_file)\n",
        "\n",
        "\n",
        "def import_default_google_fonts() -\u003e None:\n",
        "  \"\"\"Register a set of default fonts (Roboto, Google Sans) with Matplotlib.\"\"\"\n",
        "  # Prepend google_src to google3 paths.\n",
        "  import_google3_fonts(os.path.join('/google_src/head/depot', _GOOGLE_SANS_PATH))\n",
        "\n",
        "\n",
        "# Import and register Google fonts with Matplotlib so we can use them.\n",
        "import_default_google_fonts()\n",
        "\n",
        "\n",
        "# Set up plot style\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')\n",
        "MEDIUM_SIZE = 12\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "# ['DejaVu Sans', 'Arial', 'Helvetica', 'Times New Roman', 'Verdana', 'Georgia']\n",
        "mpl.rcParams['font.family'] = 'Google Sans'\n",
        "plt.rcParams['font.family'] = 'Google Sans'\n",
        "plt.rcParams['font.size'] = MEDIUM_SIZE\n",
        "plt.rcParams['axes.linewidth'] = 1\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE-5)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBQR_rQhVhd4"
      },
      "outputs": [],
      "source": [
        "def read_xm_metrics(example_xid, metric_name, unit_id, lowest=True):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if series.label == metric_name:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "      if lowest:\n",
        "        return min(all_measurements)\n",
        "      else:\n",
        "        return all_measurements\n",
        "\n",
        "\n",
        "def add_min_columns(df):\n",
        "  # Function to calculate the minimum value in each list\n",
        "  def min_of_list(lst):\n",
        "    return min(lst)\n",
        "\n",
        "  # Calculate minimum values and add as new columns\n",
        "  df['min_valid_mean_absolute_error_all'] = df[\n",
        "      'valid_mean_absolute_error_all'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_absolute_error_masked'] = df[\n",
        "      'valid_mean_absolute_error_masked'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_squared_error_all'] = df[\n",
        "      'valid_mean_squared_error_all'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_squared_error_masked'] = df[\n",
        "      'valid_mean_squared_error_masked'\n",
        "  ].apply(min_of_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def process_string_metric(input_string):\n",
        "  # Define the mapping of long error names to their abbreviations\n",
        "  error_map = {'mean_absolute_error': 'mae', 'mean_squared_error': 'mse'}\n",
        "\n",
        "  # Replace the errors in the string using the map\n",
        "  for long_error, short_error in error_map.items():\n",
        "    input_string = re.sub(long_error, short_error, input_string)\n",
        "\n",
        "  # Remove 'valid_' and replace '/' with '_'\n",
        "  input_string = input_string.replace('valid_', '').replace('/', '_')\n",
        "\n",
        "  return input_string\n",
        "\n",
        "\n",
        "def generate_percentiled_numbers(max_value, percentiles):\n",
        "  \"\"\"Generate a list of integer numbers based on the given percentiles of the maximum value.\n",
        "\n",
        "  Parameters:\n",
        "  max_value (int): The maximum value to base the percentages on.\n",
        "  percentiles (list of float): A list of percentiles (0-100) to calculate.\n",
        "\n",
        "  Returns:\n",
        "  list of int: A list of integers corresponding to the given percentiles.\n",
        "  \"\"\"\n",
        "  return [round(max_value * (p / 100))-1 for p in percentiles]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "V6m9nh51kpZY"
      },
      "outputs": [],
      "source": [
        "# @title Data Scaling\n",
        "\n",
        "# Get unique learning rates\n",
        "\n",
        "\n",
        "xm_id_dict = {  # Model Size, ParamSize, PatchSize\n",
        "    124248449: ['Tiny', 2.21, '10x5'],\n",
        "    124248804: ['ExtraSmall', 7.3, '10x5'],\n",
        "    # 124142001: ['Small', 24.6, '10x5'],\n",
        "    124248847: ['Base', 110.74, '10x5'],\n",
        "}\n",
        "\n",
        "compute_metrics = [\n",
        "    'core_hours_TPU v5 lite',\n",
        "    'train_mean_absolute_error_all',\n",
        "    'train_mean_absolute_error_masked',\n",
        "    'train_mean_squared_error_all',\n",
        "    'train_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "\n",
        "metric_names = [\n",
        "    'valid_mean_squared_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "xm_exp_dict = collections.defaultdict(list)\n",
        "for key, values in xm_id_dict.items():\n",
        "  xm_id = key\n",
        "  model_size = values[0]\n",
        "  param_size = values[1]\n",
        "  patch_size = values[2]\n",
        "  experiment = xm_client.get_experiment(xm_id)\n",
        "  num_of_units = experiment.get_num_work_units()\n",
        "  for id in range(num_of_units):\n",
        "    real_id = id + 1\n",
        "    work_unit = experiment.get_work_unit(real_id)\n",
        "    key_list = work_unit.parameters.keys()\n",
        "    xm_exp_dict['unit_id'].append(id)\n",
        "    xm_exp_dict['xm_id'].append(xm_id)\n",
        "    xm_exp_dict['Param Size'].append(param_size)\n",
        "    xm_exp_dict['Model Size'].append(model_size)\n",
        "    xm_exp_dict['Patch Size'].append(patch_size)\n",
        "    for param_name in key_list:\n",
        "      xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "    for metric in metric_names + compute_metrics:\n",
        "      xm_exp_dict[metric].append(\n",
        "          read_xm_metrics(xm_id, metric, real_id, lowest=False)\n",
        "      )\n",
        "df = pd.DataFrame(xm_exp_dict)\n",
        "# df = add_min_columns(df)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irr0A2AZFV9o"
      },
      "outputs": [],
      "source": [
        "# @title Random Imputation (Val Loss) - Style Updated\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import linregress\n",
        "from scipy.spatial import ConvexHull\n",
        "\n",
        "\n",
        "def filter_pairs(x, y):\n",
        "  new_x, new_y = [], []\n",
        "\n",
        "  for xi, yi in zip(x, y):\n",
        "    if yi \u003e 0.5:\n",
        "      continue\n",
        "    if not (xi \u003c 0.6 and yi \u003c 0.4):\n",
        "      new_x.append(xi)\n",
        "      new_y.append(yi)\n",
        "\n",
        "  return new_x, new_y\n",
        "\n",
        "\n",
        "# Custom formatter function to display y-ticks as floats\n",
        "def log_float_formatter(y, pos):\n",
        "  return f'{y:.2f}'\n",
        "\n",
        "\n",
        "def log_float_formatter_3(y, pos):\n",
        "  return f'{y:.3f}'\n",
        "\n",
        "\n",
        "# Custom scaling function\n",
        "def scaling_function_full(C, a, b, c, d):\n",
        "  return a + b * ((C + d) ** c)\n",
        "\n",
        "\n",
        "# No saturation for lower end; remove d\n",
        "def scaling_function(C, a, b, c):\n",
        "  return a + b * (C ** c)\n",
        "\n",
        "\n",
        "# Function to filter for the lowest y for each unique x\n",
        "def filter_best_pairs(x, y):\n",
        "  unique_x = np.unique(x)\n",
        "  best_y = [\n",
        "      np.min([y_val for x_val, y_val in zip(x, y) if x_val == ux])\n",
        "      for ux in unique_x\n",
        "  ]\n",
        "  return unique_x, np.array(best_y)\n",
        "\n",
        "\n",
        "def filter_best_pairs(x, y):\n",
        "  # Sort the pairs based on x\n",
        "  sorted_pairs = sorted(zip(x, y), key=lambda pair: pair[0])\n",
        "  sorted_x, sorted_y = zip(*sorted_pairs)\n",
        "\n",
        "  # Initialize lists for valid x and y values\n",
        "  valid_x = []\n",
        "  valid_y = []\n",
        "\n",
        "  # Keep track of the previous y value, start with infinity to make sure first pair is always included\n",
        "  previous_y = float('inf')\n",
        "\n",
        "  # Iterate through sorted x and y values\n",
        "  for x_val, y_val in zip(sorted_x, sorted_y):\n",
        "    # Only keep the pair if y is less than or equal to the previous y\n",
        "    if y_val \u003c= previous_y:\n",
        "      valid_x.append(x_val)\n",
        "      valid_y.append(y_val)\n",
        "      previous_y = y_val  # Update previous_y to the current y\n",
        "\n",
        "  return np.array(valid_x), np.array(valid_y)\n",
        "\n",
        "\n",
        "def filter_best_pairs(x, y):\n",
        "  # Sort x and y together based on x (to ensure monotonic x values)\n",
        "  sorted_pairs = sorted(zip(x, y), key=lambda pair: pair[0])\n",
        "  sorted_x, sorted_y = zip(*sorted_pairs)\n",
        "\n",
        "  # Initialize lists for valid x and y values\n",
        "  valid_x = []\n",
        "  valid_y = []\n",
        "\n",
        "  # Keep track of the minimum y encountered so far\n",
        "  min_y = float('inf')\n",
        "\n",
        "  # Iterate through sorted x and y values\n",
        "  for x_val, y_val in zip(sorted_x, sorted_y):\n",
        "    # Only keep the pair if y decreases or stays the same\n",
        "    if y_val \u003c= min_y:\n",
        "      valid_x.append(x_val)\n",
        "      valid_y.append(y_val)\n",
        "      min_y = y_val  # Update the minimum y\n",
        "\n",
        "  return np.array(valid_x), np.array(valid_y)\n",
        "\n",
        "\n",
        "def format_scientific_latex(number):\n",
        "  \"\"\"Helper function to format numbers as scientific notation with 10^x.\"\"\"\n",
        "  exponent = int(np.floor(np.log10(abs(number)))) if number != 0 else 0\n",
        "  mantissa = number / 10**exponent\n",
        "  return r'{:.2f} \\times 10^{{{}}}'.format(mantissa, exponent)\n",
        "\n",
        "\n",
        "# Fit and plot the scaling function\n",
        "def fit_and_plot_custom_scaling(x, y, ax, color, p0=[0.22, 0.16, -0.79],\n",
        "                                label=None, xlabel='C'):\n",
        "  # Use curve_fit to fit the scaling function to the data\n",
        "  # p0 is the initial guess, which will be adjusted during fitting\n",
        "  params, _ = curve_fit(\n",
        "      scaling_function, x, y, p0=p0, maxfev=100000\n",
        "  )\n",
        "\n",
        "  # Print the optimized parameters for reference\n",
        "  print(\n",
        "      f'Optimized parameters: a = {params[0]}, b = {params[1]}, c = {params[2]}'\n",
        "  )\n",
        "  a = params[0]\n",
        "  b = params[1]\n",
        "  c = params[2]\n",
        "  # d = params[3]\n",
        "  formatted_b = format_scientific_latex(b)\n",
        "  # formatted_d = format_scientific_latex(d)\n",
        "\n",
        "  # Generate fitted values\n",
        "  plot_x = np.linspace(min(x), max(x), num=10000)\n",
        "  fitted_y = scaling_function(plot_x, *params)\n",
        "  # equation_text = r'$L = {:.2f} + {} \\cdot (x + {})^{{{:.2f}}}$'.format(\n",
        "  #     a, formatted_b, formatted_d, c\n",
        "  # )\n",
        "  equation_text = r'$L = {:.2f} + {:.2f} \\cdot {}^{{{:.2f}}}$'.format(\n",
        "      a, b, xlabel, c\n",
        "  )\n",
        "  ax.text(\n",
        "      0.95,\n",
        "      0.95,\n",
        "      equation_text,\n",
        "      transform=ax.transAxes,\n",
        "      fontsize=11,\n",
        "      verticalalignment='top',\n",
        "      horizontalalignment='right',\n",
        "      bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'),\n",
        "  )\n",
        "\n",
        "  # Plot the fitted line (no log transformation since we're debugging)\n",
        "  ax.plot(plot_x, fitted_y, color=color, label=label, alpha=0.8, linestyle = \"--\")\n",
        "\n",
        "\n",
        "def fit_and_plot_linear_scaling(x, y, ax, color, label=None):\n",
        "  # Ensure x and y are numpy arrays for element-wise operations\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "\n",
        "  # Perform linear regression\n",
        "  slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "\n",
        "  # Print the linear fit parameters (slope and intercept)\n",
        "  print(f'Linear fit: y = {slope} * x + {intercept}')\n",
        "\n",
        "  # Generate fitted y values based on the linear regression result\n",
        "  fitted_y = slope * x + intercept\n",
        "\n",
        "  # Plot the fitted line\n",
        "  ax.plot(x, fitted_y, color=color, label=f'Fit: slope={slope:.2f}', alpha=0.8)\n",
        "\n",
        "  # Create the LaTeX formatted equation text\n",
        "  equation_text = r'$y = {:.2f}x + {:.2f}$'.format(slope, intercept)\n",
        "\n",
        "  # Add the equation to the plot as a text annotation\n",
        "  ax.text(\n",
        "      0.55,\n",
        "      0.95,\n",
        "      equation_text,\n",
        "      transform=ax.transAxes,\n",
        "      fontsize=8,\n",
        "      verticalalignment='top',\n",
        "      horizontalalignment='left',\n",
        "      bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'),\n",
        "  )\n",
        "\n",
        "  return slope, intercept\n",
        "\n",
        "\n",
        "use_aug = True\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours_steps = [1, 5, 10, 20, 40, 80, 100]\n",
        "# colors = ['#d32f2f', '#388e3c', '#1976d2']  # Red, Green, Blue\n",
        "# colors = ['#465ece', '#bed2f6', '#f8ab8d']\n",
        "colors = [plt.cm.tab20c(i) for i in range(3)]\n",
        "\n",
        "other_metric_names = [\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "line_alpha = 1\n",
        "circle_alpha = 1\n",
        "\n",
        "\n",
        "# Create a figure with a custom layout\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
        "\n",
        "# Unpack the axes for easier access\n",
        "ax1, ax2, ax3 = axs\n",
        "\n",
        "\n",
        "# Define marker sizes based on model sizes\n",
        "marker_size_map = {\n",
        "    'Tiny': 25,\n",
        "    'ExtraSmall': 80,\n",
        "    'Base': 150,\n",
        "    100000: 25,\n",
        "    750000: 80,\n",
        "    1321235: 150,\n",
        "}\n",
        "color_map = {\n",
        "    'Tiny': colors[2],\n",
        "    'ExtraSmall': colors[1],\n",
        "    'Base': colors[0],\n",
        "}\n",
        "\n",
        "data_scaling_list = []\n",
        "model_scaling_list = []\n",
        "compute_scaling_list = []\n",
        "metric_name = 'valid_mean_squared_error_masked'\n",
        "displayed_metric = process_string_metric(metric_name)\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 1: Compute Scaling\n",
        "\n",
        "# Create lists to store all x and y values across subsets\n",
        "x_all, y_all, line_idx_all = [], [], []\n",
        "\n",
        "ax1.set(xscale=\"log\", yscale=\"log\")\n",
        "\n",
        "# Iterate over data sizes and model sizes\n",
        "line_idx = 0\n",
        "for data_size in [100000, 750000, 1321235]:\n",
        "  for model_size in ['ExtraSmall', 'Base', 'Tiny']:\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "\n",
        "    if not subset.empty:\n",
        "      compute_length = len(subset.iloc[0]['core_hours_TPU v5 lite'])\n",
        "\n",
        "      # Subsample the trajectory\n",
        "      idx_range = list(range(10)) + list(range(10, 50, 10)) + list(range(50, 100, 20)) + [compute_length - 1]\n",
        "      # idx_range = range(compute_length)\n",
        "\n",
        "      x = [\n",
        "          subset.iloc[0]['core_hours_TPU v5 lite'][idx]\n",
        "          for idx in idx_range\n",
        "      ]\n",
        "      y = [subset.iloc[0][metric_name][idx] for idx in idx_range]\n",
        "      x, y = filter_pairs(x, y)\n",
        "      # Append x and y to overall list\n",
        "      # Scatter plot and line plot for this subset\n",
        "      sns.scatterplot(\n",
        "          x=x,\n",
        "          y=y,\n",
        "          color=color_map[model_size],\n",
        "          ax=ax1,\n",
        "          s=marker_size_map[data_size],\n",
        "          alpha=circle_alpha,\n",
        "          legend=False,\n",
        "      )\n",
        "      if (len(x) \u003e 0):\n",
        "        x_all.extend(x)\n",
        "        y_all.extend(y)\n",
        "        line_idx_all.extend([line_idx for _ in range(len(x))])\n",
        "      line_idx += 1\n",
        "      sns.lineplot(\n",
        "          x=x,\n",
        "          y=y,\n",
        "          color=color_map[model_size],\n",
        "          ax=ax1,\n",
        "          linewidth=1,\n",
        "          alpha=line_alpha,\n",
        "      )\n",
        "\n",
        "\n",
        "df_xy = pd.DataFrame([x_all, y_all, line_idx_all]).T\n",
        "df_xy.columns = ['col_x', 'col_y', 'col_idx']\n",
        "hull = ConvexHull(df_xy[['col_x', 'col_y']])\n",
        "hull_points = df_xy.iloc[hull.vertices]\n",
        "\n",
        "def get_lower(polygon):\n",
        "    minx = np.argmin(polygon[:, 0])\n",
        "    maxx = np.argmax(polygon[:, 0]) + 1\n",
        "    if minx \u003e= maxx:\n",
        "        lower_curve = np.concatenate([polygon[minx:], polygon[:maxx]])\n",
        "    else:\n",
        "        lower_curve = polygon[minx:maxx]\n",
        "    return lower_curve\n",
        "lower_curve = get_lower(np.array(hull_points)[:,:-1])\n",
        "df_xy_fit = pd.DataFrame(lower_curve[:-1])\n",
        "df_xy_fit.columns = ['col_x', 'col_y',]\n",
        "\n",
        "# sns.lineplot(\n",
        "#     x=df_xy_fit['col_x'].values,\n",
        "#     y=df_xy_fit['col_y'].values,\n",
        "#     color='green',\n",
        "#     ax=ax1,\n",
        "#     linewidth = 1,\n",
        "#     alpha=line_alpha,\n",
        "# )\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    df_xy_fit['col_x'], df_xy_fit['col_y'], ax1, color='k', xlabel='C'\n",
        ")\n",
        "# ax1.set_ylim(ax1.get_ylim()[0], 0.41)\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 2: Data Scaling\n",
        "\n",
        "x_all, y_all = [], []\n",
        "\n",
        "marker_size_map_datascaling = {\n",
        "    5000: 25, 50000: 50, 500000: 80, 3750000: 120, 6606175: 150\n",
        "}\n",
        "\n",
        "ax2.set(xscale=\"log\", yscale=\"log\")\n",
        "\n",
        "for model_size in ['ExtraSmall', 'Base', 'Tiny']:\n",
        "  subset = df[\n",
        "      (df['Model Size'] == model_size)\n",
        "      # \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "      \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "  ]\n",
        "  if not subset.empty:\n",
        "    x = []\n",
        "    y = []\n",
        "    for _, row in subset.iterrows():\n",
        "      x.append(round(row['config.dataset_configs.train_num_samples'] * 5, 2))\n",
        "      y.append(row[metric_name][-1] if use_last else min(row[metric_name]))\n",
        "    if metric_name == 'valid_mean_squared_error_masked':\n",
        "      data_scaling_list.append((x, y))\n",
        "\n",
        "    # here data size should be based on x axis\n",
        "    scatter = sns.scatterplot(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        s=[marker_size_map_datascaling[i] for i in x],  # Use 's' instead of 'size' to set marker size directly\n",
        "        color=color_map[model_size],\n",
        "        ax=ax2,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "\n",
        "    if (len(x) \u003e 0):\n",
        "      x_all.extend(x)\n",
        "      y_all.extend(y)\n",
        "      sns.lineplot(\n",
        "          x=x,\n",
        "          y=y,\n",
        "          color=color_map[model_size],\n",
        "          ax=ax2,\n",
        "          linewidth=1,\n",
        "          alpha=line_alpha\n",
        "      )\n",
        "\n",
        "\n",
        "df_xy = pd.DataFrame([x_all, y_all]).T\n",
        "df_xy.columns = ['col_x', 'col_y']\n",
        "hull = ConvexHull(df_xy[['col_x', 'col_y']])\n",
        "hull_points = df_xy.iloc[hull.vertices]\n",
        "\n",
        "lower_curve = get_lower(np.array(hull_points)[:])\n",
        "df_xy_fit = pd.DataFrame(lower_curve[1:])\n",
        "df_xy_fit.columns = ['col_x', 'col_y']\n",
        "\n",
        "# sns.lineplot(\n",
        "#     x=df_xy_fit['col_x'].values,\n",
        "#     y=df_xy_fit['col_y'].values,\n",
        "#     color='green',\n",
        "#     ax=ax2,\n",
        "#     linewidth = 1,\n",
        "#     alpha=0.8,\n",
        "# )\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    df_xy_fit['col_x'], df_xy_fit['col_y'], ax2, color='k', xlabel='D'\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 3: Model Scaling\n",
        "x_all, y_all = [], []\n",
        "\n",
        "ax3.set(xscale=\"log\", yscale=\"log\")\n",
        "\n",
        "for data_size in [750000, 1321235]:\n",
        "  subset = df[\n",
        "      (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "      \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "  ]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "    y = [\n",
        "        row[metric_name][-1] if use_last else min(row[metric_name])\n",
        "        for _, row in subset.iterrows()\n",
        "    ]\n",
        "    sizes = [marker_size_map[row['Model Size']] for _, row in subset.iterrows()]\n",
        "\n",
        "    if metric_name == 'valid_mean_squared_error_masked':\n",
        "      model_scaling_list.append((x, y))\n",
        "    sns.scatterplot(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        s=marker_size_map[data_size],\n",
        "        color=list(color_map.values()),  # based on x axis\n",
        "        ax=ax3,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    sns.lineplot(x=x, y=y, color=colors[-1], ax=ax3, linewidth=1, alpha=line_alpha)\n",
        "    x_all.extend(x)\n",
        "    y_all.extend(y)\n",
        "\n",
        "df_xy = pd.DataFrame([x_all, y_all]).T\n",
        "df_xy.columns = ['col_x', 'col_y']\n",
        "hull = ConvexHull(df_xy[['col_x', 'col_y']])\n",
        "hull_points = df_xy.iloc[hull.vertices]\n",
        "\n",
        "lower_curve = get_lower(np.array(hull_points)[:])\n",
        "df_xy_fit = pd.DataFrame(lower_curve[1:-1])\n",
        "df_xy_fit.columns = ['col_x', 'col_y']\n",
        "\n",
        "# sns.lineplot(\n",
        "#     x=df_xy_fit['col_x'].values,\n",
        "#     y=df_xy_fit['col_y'].values,\n",
        "#     color='green',\n",
        "#     ax=ax3,\n",
        "#     linewidth = 1,\n",
        "#     alpha=0.8,\n",
        "# )\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    df_xy_fit['col_x'], df_xy_fit['col_y'], ax3, color='k', xlabel='N'\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "#####################################################################################\n",
        "# Titles and labels\n",
        "ax1.set_ylabel('Mean Squared Error')\n",
        "ax1.set_xlabel(r'$\\mathbf{Compute}$ [C]')\n",
        "ax1.text(0.5, -0.24, 'TPU v5e core hours', transform=ax1.transAxes, color='gray', ha='center')\n",
        "ax2.set_xlabel(r'$\\mathbf{Data\\ Size}$ [D]')\n",
        "ax2.text(0.5, -0.24, 'Hours', transform=ax2.transAxes, color='gray', ha='center')\n",
        "ax3.set_xlabel(r'$\\mathbf{Model\\ Size}$ [N]')\n",
        "ax3.text(0.5, -0.24, 'Million of Params', transform=ax3.transAxes, color='gray', ha='center')\n",
        "\n",
        "ax1.yaxis.set_major_locator(LogLocator(base=10.0, subs=np.arange(1, 10), numticks=10))\n",
        "ax1.yaxis.set_major_formatter(FuncFormatter(log_float_formatter))\n",
        "ax2.yaxis.set_major_locator(LogLocator(base=10.0, subs=np.arange(1, 10), numticks=10))\n",
        "ax2.yaxis.set_major_formatter(FuncFormatter(log_float_formatter))\n",
        "ax3.yaxis.set_major_locator(LogLocator(base=10.0, subs=np.arange(1, 10), numticks=10))\n",
        "ax3.yaxis.set_major_formatter(FuncFormatter(log_float_formatter_3))\n",
        "\n",
        "marker_sizes = [\n",
        "    marker_size_map['Tiny'],\n",
        "    marker_size_map['ExtraSmall'],\n",
        "    marker_size_map['Base'],\n",
        "]\n",
        "marker_labels = ['2M', '7M', '110M']\n",
        "\n",
        "marker_handles = [\n",
        "    plt.scatter([], [], s=size, color='black') for size in marker_sizes\n",
        "]\n",
        "\n",
        "# Combine handles and labels\n",
        "combined_handles = marker_handles\n",
        "combined_labels = marker_labels\n",
        "\n",
        "#####################################################################################\n",
        "# Legend\n",
        "marker_size_handle_labels = ['0.005M', '0.05M', '0.5M', '3.8M', '6.6M']\n",
        "marker_size_handles = [\n",
        "    mlines.Line2D([], [], color='black', marker='o', linestyle=':',\n",
        "                  markersize=np.sqrt(marker_size_map_datascaling[data_size]),\n",
        "                  label=marker_size_handle_labels[i])\n",
        "    for i, data_size in enumerate([5000, 50000, 500000, 3750000, 6606175])\n",
        "]\n",
        "color_handle_labels = ['ViT 2M', 'ViT 7M', 'ViT 110M']\n",
        "color_handles = [\n",
        "    mlines.Line2D([], [], color=color_map[model_size], marker='o', linestyle='-',\n",
        "                  label=color_handle_labels[i])\n",
        "    for i, model_size in enumerate(['Tiny', 'ExtraSmall', 'Base'])\n",
        "]\n",
        "\n",
        "# combined_handles = marker_size_handles + color_handles\n",
        "# combined_labels = [h.get_label() for h in combined_handles]\n",
        "# fig.legend(handles=combined_handles, labels=combined_labels, ncol=6, loc='upper center')\n",
        "legend1 = fig.legend(\n",
        "    handles=marker_size_handles, labels=[h.get_label() for h in marker_size_handles],\n",
        "    ncol=5, loc='upper left', bbox_to_anchor=(0.05, 1.1), fontsize=12, frameon=False)\n",
        "legend2 = fig.legend(\n",
        "    handles=color_handles, labels=[h.get_label() for h in color_handles],\n",
        "    ncol=3, loc='upper right', bbox_to_anchor=(0.96, 1.1), fontsize=12, frameon=False)\n",
        "plt.subplots_adjust(top=0.80)\n",
        "\n",
        "#####################################################################################\n",
        "# Final plot\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/tmp/teaser.pdf\", bbox_inches='tight', format=\"pdf\")\n",
        "%download_file /tmp/teaser.pdf\n",
        "plt.savefig(\"/tmp/teaser.svg\", bbox_inches='tight', format=\"svg\")\n",
        "%download_file /tmp/teaser.svg\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2KDBadal66Fw"
      },
      "outputs": [],
      "source": [
        "# @title Random Imputation (Val Loss)\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import linregress\n",
        "\n",
        "def filter_pairs(x, y):\n",
        "  new_x, new_y = [], []\n",
        "\n",
        "  for xi, yi in zip(x, y):\n",
        "    if not (xi \u003c 0.6 and yi \u003c 0.4):\n",
        "      new_x.append(xi)\n",
        "      new_y.append(yi)\n",
        "\n",
        "  return new_x, new_y\n",
        "\n",
        "\n",
        "# Define the correct custom scaling function\n",
        "def scaling_function(C, a, b, c, d):\n",
        "  return a + b * (C + d) ** c\n",
        "\n",
        "\n",
        "# Function to filter for the lowest y for each unique x\n",
        "def filter_best_pairs(x, y):\n",
        "  unique_x = np.unique(x)\n",
        "  best_y = [\n",
        "      np.min([y_val for x_val, y_val in zip(x, y) if x_val == ux])\n",
        "      for ux in unique_x\n",
        "  ]\n",
        "  return unique_x, np.array(best_y)\n",
        "\n",
        "\n",
        "def filter_best_pairs(x, y):\n",
        "  # Sort the pairs based on x\n",
        "  sorted_pairs = sorted(zip(x, y), key=lambda pair: pair[0])\n",
        "  sorted_x, sorted_y = zip(*sorted_pairs)\n",
        "\n",
        "  # Initialize lists for valid x and y values\n",
        "  valid_x = []\n",
        "  valid_y = []\n",
        "\n",
        "  # Keep track of the previous y value, start with infinity to make sure first pair is always included\n",
        "  previous_y = float('inf')\n",
        "\n",
        "  # Iterate through sorted x and y values\n",
        "  for x_val, y_val in zip(sorted_x, sorted_y):\n",
        "    # Only keep the pair if y is less than or equal to the previous y\n",
        "    if y_val \u003c= previous_y:\n",
        "      valid_x.append(x_val)\n",
        "      valid_y.append(y_val)\n",
        "      previous_y = y_val  # Update previous_y to the current y\n",
        "\n",
        "  return np.array(valid_x), np.array(valid_y)\n",
        "\n",
        "\n",
        "def filter_best_pairs(x, y):\n",
        "  # Sort x and y together based on x (to ensure monotonic x values)\n",
        "  sorted_pairs = sorted(zip(x, y), key=lambda pair: pair[0])\n",
        "  sorted_x, sorted_y = zip(*sorted_pairs)\n",
        "\n",
        "  # Initialize lists for valid x and y values\n",
        "  valid_x = []\n",
        "  valid_y = []\n",
        "\n",
        "  # Keep track of the minimum y encountered so far\n",
        "  min_y = float('inf')\n",
        "\n",
        "  # Iterate through sorted x and y values\n",
        "  for x_val, y_val in zip(sorted_x, sorted_y):\n",
        "    # Only keep the pair if y decreases or stays the same\n",
        "    if y_val \u003c= min_y:\n",
        "      valid_x.append(x_val)\n",
        "      valid_y.append(y_val)\n",
        "      min_y = y_val  # Update the minimum y\n",
        "\n",
        "  return np.array(valid_x), np.array(valid_y)\n",
        "\n",
        "\n",
        "def format_scientific_latex(number):\n",
        "  \"\"\"Helper function to format numbers as scientific notation with 10^x.\"\"\"\n",
        "  exponent = int(np.floor(np.log10(abs(number)))) if number != 0 else 0\n",
        "  mantissa = number / 10**exponent\n",
        "  return r'{:.2f} \\times 10^{{{}}}'.format(mantissa, exponent)\n",
        "\n",
        "\n",
        "# Fit and plot the scaling function\n",
        "def fit_and_plot_custom_scaling(x, y, ax, color, label=None):\n",
        "  # Use curve_fit to fit the scaling function to the data\n",
        "  # p0 is the initial guess, which will be adjusted during fitting\n",
        "  params, _ = curve_fit(\n",
        "      scaling_function, x, y, p0=[0.22, 0.16, -0.79, -0.07], maxfev=10000\n",
        "  )\n",
        "\n",
        "  # Print the optimized parameters for reference\n",
        "  print(\n",
        "      f'Optimized parameters: a = {params[0]}, b = {params[1]}, c ='\n",
        "      f' {params[2]}, d = {params[3]}'\n",
        "  )\n",
        "  a = params[0]\n",
        "  b = params[1]\n",
        "  c = params[2]\n",
        "  d = params[3]\n",
        "  formatted_b = format_scientific_latex(b)\n",
        "  formatted_d = format_scientific_latex(d)\n",
        "\n",
        "  # Generate fitted values\n",
        "  fitted_y = scaling_function(x, *params)\n",
        "  equation_text = r'$L = {:.2f} + {} \\cdot (x + {})^{{{:.2f}}}$'.format(\n",
        "      a, formatted_b, formatted_d, c\n",
        "  )\n",
        "  ax.text(\n",
        "      0.15,\n",
        "      0.90,\n",
        "      equation_text,\n",
        "      transform=ax.transAxes,\n",
        "      fontsize=8,\n",
        "      verticalalignment='top',\n",
        "      horizontalalignment='left',\n",
        "      bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'),\n",
        "  )\n",
        "\n",
        "  # Plot the fitted line (no log transformation since we're debugging)\n",
        "  ax.plot(np.log10(x), fitted_y, color=color, label=label, alpha=0.8)\n",
        "\n",
        "\n",
        "def fit_and_plot_linear_scaling(x, y, ax, color, label=None):\n",
        "  # Ensure x and y are numpy arrays for element-wise operations\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "\n",
        "  # Perform linear regression\n",
        "  slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "\n",
        "  # Print the linear fit parameters (slope and intercept)\n",
        "  print(f'Linear fit: y = {slope} * x + {intercept}')\n",
        "\n",
        "  # Generate fitted y values based on the linear regression result\n",
        "  fitted_y = slope * x + intercept\n",
        "\n",
        "  # Plot the fitted line\n",
        "  ax.plot(x, fitted_y, color=color, label=f'Fit: slope={slope:.2f}', alpha=0.8)\n",
        "\n",
        "  # Create the LaTeX formatted equation text\n",
        "  equation_text = r'$y = {:.2f}x + {:.2f}$'.format(slope, intercept)\n",
        "\n",
        "  # Add the equation to the plot as a text annotation\n",
        "  ax.text(\n",
        "      0.55,\n",
        "      0.95,\n",
        "      equation_text,\n",
        "      transform=ax.transAxes,\n",
        "      fontsize=8,\n",
        "      verticalalignment='top',\n",
        "      horizontalalignment='left',\n",
        "      bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'),\n",
        "  )\n",
        "\n",
        "  return slope, intercept\n",
        "\n",
        "\n",
        "use_aug = True\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours_steps = [1, 5, 10, 20, 40, 80, 100]\n",
        "# colors = ['#d32f2f', '#388e3c', '#1976d2']  # Red, Green, Blue\n",
        "colors = ['#465ece', '#bed2f6', '#f8ab8d']  # Red, Green, Blue\n",
        "\n",
        "# #465ece, #f8ab8d, #bed2f6\n",
        "other_metric_names = [\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "line_alpha = 0.2\n",
        "circle_alpha = 1\n",
        "\n",
        "\n",
        "# Create a figure with a custom layout\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
        "\n",
        "# Unpack the axes for easier access\n",
        "ax1, ax2, ax3 = axs\n",
        "\n",
        "# Define marker sizes based on model sizes\n",
        "marker_size_map = {\n",
        "    'Deb': 2,\n",
        "    'Tiny': 2,\n",
        "    'ExtraSmall': 2,\n",
        "    'Small': 2,\n",
        "    'Base': 2,\n",
        "    'Large': 2,\n",
        "}\n",
        "\n",
        "data_scaling_list = []\n",
        "model_scaling_list = []\n",
        "compute_scaling_list = []\n",
        "metric_name = 'valid_mean_squared_error_masked'\n",
        "displayed_metric = process_string_metric(metric_name)\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 1: Compute Scaling\n",
        "\n",
        "# Create lists to store all x and y values across subsets\n",
        "x_all, y_all = [], []\n",
        "\n",
        "# Iterate over data sizes and model sizes\n",
        "for data_size in [100000, 750000, 1321235]:\n",
        "  for model_size in ['ExtraSmall', 'Base', 'Tiny']:\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "\n",
        "    if not subset.empty:\n",
        "      compute_length = len(subset.iloc[0]['core_hours_TPU v5 lite'])\n",
        "      x = [\n",
        "          subset.iloc[0]['core_hours_TPU v5 lite'][idx]\n",
        "          for idx in range(compute_length)\n",
        "      ]\n",
        "      y = [subset.iloc[0][metric_name][idx] for idx in range(compute_length)]\n",
        "      x, y = filter_pairs(x, y)\n",
        "      # Append x and y to overall list\n",
        "      # Scatter plot and line plot for this subset\n",
        "      log_x = np.log10(x)\n",
        "      sns.scatterplot(\n",
        "          x=log_x,\n",
        "          y=y,\n",
        "          color='black',\n",
        "          ax=ax1,\n",
        "          s=marker_size_map[model_size],\n",
        "          alpha=circle_alpha,\n",
        "          legend=False,\n",
        "      )\n",
        "      if model_size == 'Tiny' and data_size == 100000:\n",
        "        color = 'red'\n",
        "        x_all.extend(x)\n",
        "        y_all.extend(y)\n",
        "      else:\n",
        "        color = 'black'\n",
        "      sns.lineplot(\n",
        "          x=log_x,\n",
        "          y=y,\n",
        "          color=color,\n",
        "          ax=ax1,\n",
        "          alpha=line_alpha,\n",
        "      )\n",
        "\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    x_all, y_all, ax1, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all),\n",
        "    y=y_all,\n",
        "    color='#217BFE',\n",
        "    ax=ax1,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 2: Data Scaling\n",
        "x_all_data, y_all_data = [], []\n",
        "\n",
        "for model_size in ['Base']:\n",
        "  subset = df[(df['Model Size'] == model_size)]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = []\n",
        "    y = []\n",
        "    for _, row in subset.iterrows():\n",
        "      x.append(round(row['config.dataset_configs.train_num_samples'] * 5, 2))\n",
        "      y.append(row[metric_name][-1] if use_last else min(row[metric_name]))\n",
        "    log_x = np.log10(x)\n",
        "    if metric_name == 'valid_mean_squared_error_masked':\n",
        "      data_scaling_list.append((x, y))\n",
        "    # Set the marker size based on the model size\n",
        "    marker_size = marker_size_map[model_size]\n",
        "    scatter = sns.scatterplot(\n",
        "        x=log_x,\n",
        "        y=y,\n",
        "        s=marker_size,  # Use 's' instead of 'size' to set marker size directly\n",
        "        color='black',\n",
        "        ax=ax2,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    x_all_data.extend(x)\n",
        "    y_all_data.extend(y)\n",
        "    sns.lineplot(x=log_x, y=y, color='black', ax=ax2, alpha=line_alpha)\n",
        "\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    x_all_data, y_all_data, ax2, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "# fit_and_plot_linear_scaling(\n",
        "#     np.log10(x_all_data), y_all_data, ax2, color='#217BFE', label='Best Fit'\n",
        "# )\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all_data),\n",
        "    y=y_all_data,\n",
        "    color='#217BFE',\n",
        "    ax=ax2,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 3: Model Scaling\n",
        "x_all, y_all = [], []\n",
        "for data_size in [1321235]:\n",
        "  subset = df[\n",
        "      (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "      \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "  ]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "    y = [\n",
        "        row[metric_name][-1] if use_last else min(row[metric_name])\n",
        "        for _, row in subset.iterrows()\n",
        "    ]\n",
        "    sizes = [marker_size_map[row['Model Size']] for _, row in subset.iterrows()]\n",
        "    if metric_name == 'valid_mean_squared_error_masked':\n",
        "      model_scaling_list.append((x, y))\n",
        "    x_log = np.log10(x)\n",
        "    sns.scatterplot(\n",
        "        x=x_log,\n",
        "        y=y,\n",
        "        size=sizes,\n",
        "        sizes=(75, 150),\n",
        "        color='black',\n",
        "        ax=ax3,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    # ax3.set_ylim(0, 0.65)\n",
        "    sns.lineplot(x=x_log, y=y, color='black', ax=ax3, alpha=line_alpha)\n",
        "    x_all.extend(x)\n",
        "    y_all.extend(y)\n",
        "\n",
        "fit_and_plot_linear_scaling(\n",
        "    np.log10(x_all), y_all, ax3, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all),\n",
        "    y=y_all,\n",
        "    color='#217BFE',\n",
        "    ax=ax3,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "#####################################################################################\n",
        "# Titles and labels\n",
        "ax1.set_xlabel(r'$\\mathbf{Compute}$' + '\\n TPU v5 VLP core hours')\n",
        "ax1.set_ylabel('Masked Mean Squared Error')\n",
        "ax2.set_xlabel(r'$\\mathbf{Data\\ Size}$' + '\\n(Hours)')\n",
        "ax3.set_xlabel(r'$\\mathbf{Model\\ Size}$' + '\\n(Million of Params)')\n",
        "\n",
        "# Set the number of ticks and ensure unique tick labels\n",
        "for ax in [ax1, ax2, ax3]:\n",
        "  ax.xaxis.set_major_locator(\n",
        "      MaxNLocator(integer=True, prune='both')\n",
        "  )  # Adjust to avoid repetitive ticks\n",
        "  xticks = ax.get_xticks()\n",
        "  ax.xaxis.set_major_locator(FixedLocator(xticks))\n",
        "  ax.set_xticklabels([\n",
        "      f'$10^{int(val)}$' if i == 0 or val != xticks[i - 1] else ''\n",
        "      for i, val in enumerate(xticks)\n",
        "  ])\n",
        "\n",
        "marker_sizes = [\n",
        "    marker_size_map['Tiny'],\n",
        "    marker_size_map['ExtraSmall'],\n",
        "    marker_size_map['Base'],\n",
        "]\n",
        "marker_labels = ['2M', '7M', '110M']\n",
        "\n",
        "marker_handles = [\n",
        "    plt.scatter([], [], s=size, color='black') for size in marker_sizes\n",
        "]\n",
        "\n",
        "# Combine handles and labels\n",
        "combined_handles = marker_handles\n",
        "combined_labels = marker_labels\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YgBZEBsvKyKW"
      },
      "outputs": [],
      "source": [
        "# @title Forecasting\n",
        "\n",
        "use_aug = True\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours_steps = [1, 5, 10, 20, 40, 80, 100]\n",
        "# colors = ['#d32f2f', '#388e3c', '#1976d2']  # Red, Green, Blue\n",
        "colors = ['#465ece', '#bed2f6', '#f8ab8d']  # Red, Green, Blue\n",
        "\n",
        "# #465ece, #f8ab8d, #bed2f6\n",
        "other_metric_names = [\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "metric_name = 'forecast_0.2_eval/valid_mean_squared_error_masked'\n",
        "line_alpha = 0.2\n",
        "circle_alpha = 1\n",
        "\n",
        "\n",
        "# Create a figure with a custom layout\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
        "\n",
        "# Unpack the axes for easier access\n",
        "ax1, ax2, ax3 = axs\n",
        "\n",
        "# Define marker sizes based on model sizes\n",
        "marker_size_map = {\n",
        "    'Deb': 2,\n",
        "    'Tiny': 2,\n",
        "    'ExtraSmall': 2,\n",
        "    'Small': 2,\n",
        "    'Base': 2,\n",
        "    'Large': 2,\n",
        "}\n",
        "\n",
        "data_scaling_list = []\n",
        "model_scaling_list = []\n",
        "compute_scaling_list = []\n",
        "displayed_metric = process_string_metric(metric_name)\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 1: Compute Scaling\n",
        "\n",
        "# Create lists to store all x and y values across subsets\n",
        "x_all, y_all = [], []\n",
        "\n",
        "# Iterate over data sizes and model sizes\n",
        "for data_size in [1321235]:\n",
        "  for model_size in ['Base']:\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "\n",
        "    if not subset.empty:\n",
        "      compute_length = len(subset.iloc[0]['core_hours_TPU v5 lite'])\n",
        "      metric_length = len(subset.iloc[0][metric_name])\n",
        "      min_length = min(compute_length, metric_length)\n",
        "      compute_list = subset.iloc[0]['core_hours_TPU v5 lite'][:min_length]\n",
        "      metric_list = subset.iloc[0][metric_name][:min_length]\n",
        "      x = [compute_list[idx] for idx in range(min_length)]\n",
        "      y = [metric_list[idx] for idx in range(min_length)]\n",
        "      x, y = filter_pairs(x, y)\n",
        "      # Append x and y to overall list\n",
        "      # Scatter plot and line plot for this subset\n",
        "      log_x = np.log10(x)\n",
        "      sns.scatterplot(\n",
        "          x=log_x,\n",
        "          y=y,\n",
        "          color='black',\n",
        "          ax=ax1,\n",
        "          s=marker_size_map[model_size],\n",
        "          alpha=circle_alpha,\n",
        "          legend=False,\n",
        "      )\n",
        "      if model_size == 'Tiny' and data_size == 100000:\n",
        "        color = 'red'\n",
        "        x_all.extend(x)\n",
        "        y_all.extend(y)\n",
        "      else:\n",
        "        color = 'black'\n",
        "      sns.lineplot(\n",
        "          x=log_x,\n",
        "          y=y,\n",
        "          color=color,\n",
        "          ax=ax1,\n",
        "          alpha=line_alpha,\n",
        "      )\n",
        "\n",
        "\n",
        "# fit_and_plot_custom_scaling(\n",
        "#     x_all, y_all, ax1, color='#217BFE', label='Best Fit'\n",
        "# )\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all),\n",
        "    y=y_all,\n",
        "    color='#217BFE',\n",
        "    ax=ax1,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 2: Data Scaling\n",
        "x_all_data, y_all_data = [], []\n",
        "\n",
        "for model_size in ['Base']:\n",
        "  subset = df[(df['Model Size'] == model_size)]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = []\n",
        "    y = []\n",
        "    for _, row in subset.iterrows():\n",
        "      x.append(round(row['config.dataset_configs.train_num_samples'] * 5, 2))\n",
        "      y.append(row[metric_name][-1] if use_last else min(row[metric_name]))\n",
        "    log_x = np.log10(x)\n",
        "    # Set the marker size based on the model size\n",
        "    marker_size = marker_size_map[model_size]\n",
        "    scatter = sns.scatterplot(\n",
        "        x=log_x,\n",
        "        y=y,\n",
        "        s=marker_size,  # Use 's' instead of 'size' to set marker size directly\n",
        "        color='black',\n",
        "        ax=ax2,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    x_all_data.extend(x)\n",
        "    y_all_data.extend(y)\n",
        "    sns.lineplot(x=log_x, y=y, color='black', ax=ax2, alpha=line_alpha)\n",
        "\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    x_all_data, y_all_data, ax2, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "# fit_and_plot_linear_scaling(\n",
        "#     np.log10(x_all_data), y_all_data, ax2, color='#217BFE', label='Best Fit'\n",
        "# )\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all_data),\n",
        "    y=y_all_data,\n",
        "    color='#217BFE',\n",
        "    ax=ax2,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 3: Model Scaling\n",
        "x_all, y_all = [], []\n",
        "for data_size in [1321235]:\n",
        "  subset = df[\n",
        "      (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "      \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "  ]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "    y = [\n",
        "        row[metric_name][-1] if use_last else min(row[metric_name])\n",
        "        for _, row in subset.iterrows()\n",
        "    ]\n",
        "    sizes = [marker_size_map[row['Model Size']] for _, row in subset.iterrows()]\n",
        "    x_log = np.log10(x)\n",
        "    sns.scatterplot(\n",
        "        x=x_log,\n",
        "        y=y,\n",
        "        size=sizes,\n",
        "        sizes=(75, 150),\n",
        "        color='black',\n",
        "        ax=ax3,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    # ax3.set_ylim(0, 0.65)\n",
        "    sns.lineplot(x=x_log, y=y, color='black', ax=ax3, alpha=line_alpha)\n",
        "    x_all.extend(x)\n",
        "    y_all.extend(y)\n",
        "\n",
        "fit_and_plot_linear_scaling(\n",
        "    np.log10(x_all), y_all, ax3, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all),\n",
        "    y=y_all,\n",
        "    color='#217BFE',\n",
        "    ax=ax3,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "#####################################################################################\n",
        "# Titles and labels\n",
        "ax1.set_xlabel(r'$\\mathbf{Compute}$' + '\\n TPU v5 VLP core hours')\n",
        "ax1.set_ylabel('Masked Mean Squared Error')\n",
        "ax2.set_xlabel(r'$\\mathbf{Data\\ Size}$' + '\\n(Hours)')\n",
        "ax3.set_xlabel(r'$\\mathbf{Model\\ Size}$' + '\\n(Million of Params)')\n",
        "\n",
        "# Set the number of ticks and ensure unique tick labels\n",
        "for ax in [ax1, ax2, ax3]:\n",
        "  ax.xaxis.set_major_locator(\n",
        "      MaxNLocator(integer=True, prune='both')\n",
        "  )  # Adjust to avoid repetitive ticks\n",
        "  xticks = ax.get_xticks()\n",
        "  ax.xaxis.set_major_locator(FixedLocator(xticks))\n",
        "  ax.set_xticklabels([\n",
        "      f'$10^{int(val)}$' if i == 0 or val != xticks[i - 1] else ''\n",
        "      for i, val in enumerate(xticks)\n",
        "  ])\n",
        "\n",
        "marker_sizes = [\n",
        "    marker_size_map['Tiny'],\n",
        "    marker_size_map['ExtraSmall'],\n",
        "    marker_size_map['Base'],\n",
        "]\n",
        "marker_labels = ['2M', '7M', '110M']\n",
        "\n",
        "marker_handles = [\n",
        "    plt.scatter([], [], s=size, color='black') for size in marker_sizes\n",
        "]\n",
        "\n",
        "# Combine handles and labels\n",
        "combined_handles = marker_handles\n",
        "combined_labels = marker_labels\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5x-Z5Jp0LL5M"
      },
      "outputs": [],
      "source": [
        "# @title Imputation\n",
        "\n",
        "use_aug = True\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours_steps = [1, 5, 10, 20, 40, 80, 100]\n",
        "# colors = ['#d32f2f', '#388e3c', '#1976d2']  # Red, Green, Blue\n",
        "colors = ['#465ece', '#bed2f6', '#f8ab8d']  # Red, Green, Blue\n",
        "\n",
        "# #465ece, #f8ab8d, #bed2f6\n",
        "other_metric_names = [\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "metric_name = 'imputation_0.2_eval/valid_mean_squared_error_masked'\n",
        "line_alpha = 0.2\n",
        "circle_alpha = 1\n",
        "\n",
        "\n",
        "# Create a figure with a custom layout\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
        "\n",
        "# Unpack the axes for easier access\n",
        "ax1, ax2, ax3 = axs\n",
        "\n",
        "# Define marker sizes based on model sizes\n",
        "marker_size_map = {\n",
        "    'Deb': 2,\n",
        "    'Tiny': 2,\n",
        "    'ExtraSmall': 2,\n",
        "    'Small': 2,\n",
        "    'Base': 2,\n",
        "    'Large': 2,\n",
        "}\n",
        "\n",
        "data_scaling_list = []\n",
        "model_scaling_list = []\n",
        "compute_scaling_list = []\n",
        "displayed_metric = process_string_metric(metric_name)\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 1: Compute Scaling\n",
        "\n",
        "# Create lists to store all x and y values across subsets\n",
        "x_all, y_all = [], []\n",
        "\n",
        "# Iterate over data sizes and model sizes\n",
        "for data_size in [1321235]:\n",
        "  for model_size in ['Base']:\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "\n",
        "    if not subset.empty:\n",
        "      compute_length = len(subset.iloc[0]['core_hours_TPU v5 lite'])\n",
        "      metric_length = len(subset.iloc[0][metric_name])\n",
        "      min_length = min(compute_length, metric_length)\n",
        "      compute_list = subset.iloc[0]['core_hours_TPU v5 lite'][:min_length]\n",
        "      metric_list = subset.iloc[0][metric_name][:min_length]\n",
        "      x = [compute_list[idx] for idx in range(min_length)]\n",
        "      y = [metric_list[idx] for idx in range(min_length)]\n",
        "      x, y = filter_pairs(x, y)\n",
        "      # Append x and y to overall list\n",
        "      # Scatter plot and line plot for this subset\n",
        "      log_x = np.log10(x)\n",
        "      sns.scatterplot(\n",
        "          x=log_x,\n",
        "          y=y,\n",
        "          color='black',\n",
        "          ax=ax1,\n",
        "          s=marker_size_map[model_size],\n",
        "          alpha=circle_alpha,\n",
        "          legend=False,\n",
        "      )\n",
        "      if model_size == 'Tiny' and data_size == 100000:\n",
        "        color = 'red'\n",
        "        x_all.extend(x)\n",
        "        y_all.extend(y)\n",
        "      else:\n",
        "        color = 'black'\n",
        "      sns.lineplot(\n",
        "          x=log_x,\n",
        "          y=y,\n",
        "          color=color,\n",
        "          ax=ax1,\n",
        "          alpha=line_alpha,\n",
        "      )\n",
        "\n",
        "\n",
        "# fit_and_plot_custom_scaling(\n",
        "#     x_all, y_all, ax1, color='#217BFE', label='Best Fit'\n",
        "# )\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all),\n",
        "    y=y_all,\n",
        "    color='#217BFE',\n",
        "    ax=ax1,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 2: Data Scaling\n",
        "x_all_data, y_all_data = [], []\n",
        "\n",
        "for model_size in ['Base']:\n",
        "  subset = df[(df['Model Size'] == model_size)]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = []\n",
        "    y = []\n",
        "    for _, row in subset.iterrows():\n",
        "      x.append(round(row['config.dataset_configs.train_num_samples'] * 5, 2))\n",
        "      y.append(row[metric_name][-1] if use_last else min(row[metric_name]))\n",
        "    log_x = np.log10(x)\n",
        "    # Set the marker size based on the model size\n",
        "    marker_size = marker_size_map[model_size]\n",
        "    scatter = sns.scatterplot(\n",
        "        x=log_x,\n",
        "        y=y,\n",
        "        s=marker_size,  # Use 's' instead of 'size' to set marker size directly\n",
        "        color='black',\n",
        "        ax=ax2,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    x_all_data.extend(x)\n",
        "    y_all_data.extend(y)\n",
        "    sns.lineplot(x=log_x, y=y, color='black', ax=ax2, alpha=line_alpha)\n",
        "\n",
        "\n",
        "fit_and_plot_custom_scaling(\n",
        "    x_all_data, y_all_data, ax2, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "# fit_and_plot_linear_scaling(\n",
        "#     np.log10(x_all_data), y_all_data, ax2, color='#217BFE', label='Best Fit'\n",
        "# )\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all_data),\n",
        "    y=y_all_data,\n",
        "    color='#217BFE',\n",
        "    ax=ax2,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "\n",
        "#####################################################################################\n",
        "# Figure 3: Model Scaling\n",
        "x_all, y_all = [], []\n",
        "for data_size in [1321235]:\n",
        "  subset = df[\n",
        "      (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "      \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "  ]\n",
        "\n",
        "  if not subset.empty:\n",
        "    x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "    y = [\n",
        "        row[metric_name][-1] if use_last else min(row[metric_name])\n",
        "        for _, row in subset.iterrows()\n",
        "    ]\n",
        "    sizes = [marker_size_map[row['Model Size']] for _, row in subset.iterrows()]\n",
        "    x_log = np.log10(x)\n",
        "    sns.scatterplot(\n",
        "        x=x_log,\n",
        "        y=y,\n",
        "        size=sizes,\n",
        "        sizes=(75, 150),\n",
        "        color='black',\n",
        "        ax=ax3,\n",
        "        alpha=circle_alpha,\n",
        "        legend=False,\n",
        "    )\n",
        "    # ax3.set_ylim(0, 0.65)\n",
        "    sns.lineplot(x=x_log, y=y, color='black', ax=ax3, alpha=line_alpha)\n",
        "    x_all.extend(x)\n",
        "    y_all.extend(y)\n",
        "\n",
        "fit_and_plot_linear_scaling(\n",
        "    np.log10(x_all), y_all, ax3, color='#217BFE', label='Best Fit'\n",
        ")\n",
        "sns.scatterplot(\n",
        "    x=np.log10(x_all),\n",
        "    y=y_all,\n",
        "    color='#217BFE',\n",
        "    ax=ax3,\n",
        "    s=30,\n",
        "    alpha=circle_alpha,\n",
        "    legend=False,\n",
        ")\n",
        "\n",
        "#####################################################################################\n",
        "# Titles and labels\n",
        "ax1.set_xlabel(r'$\\mathbf{Compute}$' + '\\n TPU v5 VLP core hours')\n",
        "ax1.set_ylabel('Masked Mean Squared Error')\n",
        "ax2.set_xlabel(r'$\\mathbf{Data\\ Size}$' + '\\n(Hours)')\n",
        "ax3.set_xlabel(r'$\\mathbf{Model\\ Size}$' + '\\n(Million of Params)')\n",
        "\n",
        "# Set the number of ticks and ensure unique tick labels\n",
        "for ax in [ax1, ax2, ax3]:\n",
        "  ax.xaxis.set_major_locator(\n",
        "      MaxNLocator(integer=True, prune='both')\n",
        "  )  # Adjust to avoid repetitive ticks\n",
        "  xticks = ax.get_xticks()\n",
        "  ax.xaxis.set_major_locator(FixedLocator(xticks))\n",
        "  ax.set_xticklabels([\n",
        "      f'$10^{int(val)}$' if i == 0 or val != xticks[i - 1] else ''\n",
        "      for i, val in enumerate(xticks)\n",
        "  ])\n",
        "\n",
        "marker_sizes = [\n",
        "    marker_size_map['Tiny'],\n",
        "    marker_size_map['ExtraSmall'],\n",
        "    marker_size_map['Base'],\n",
        "]\n",
        "marker_labels = ['2M', '7M', '110M']\n",
        "\n",
        "marker_handles = [\n",
        "    plt.scatter([], [], s=size, color='black') for size in marker_sizes\n",
        "]\n",
        "\n",
        "# Combine handles and labels\n",
        "combined_handles = marker_handles\n",
        "combined_labels = marker_labels\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4tc3oDDJ9Ln"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "iclr_scaling_figures.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/iclr_figures/iclr_scaling_law_figures.ipynb",
          "timestamp": 1726077021655
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/iclr_figures/iclr_scaling_law_figures.ipynb",
          "timestamp": 1725733386267
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_final_iclr.ipynb?workspaceId=xliucs:scaling_analysis::citc",
          "timestamp": 1725589233886
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_final_iclr.ipynb",
          "timestamp": 1723509130272
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data_size.ipynb?workspaceId=xliucs:scaling_analysis_new_pretrain::citc",
          "timestamp": 1723419354747
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data_size.ipynb",
          "timestamp": 1723071326500
        },
        {
          "file_id": "1Q3nbnc5dYAV6pyHWeKKXRVbxMwBPPQuB",
          "timestamp": 1719441633704
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data.ipynb",
          "timestamp": 1719435410567
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analysis_parameter_sweep.ipynb?workspaceId=xliucs:lsm_notebooks_scaling_june22::citc",
          "timestamp": 1719177613159
        },
        {
          "file_id": "1avNG7EtMynPa2U-GHj2nd4nWWdGzcFq3",
          "timestamp": 1719177577595
        },
        {
          "file_id": "1WdhekZ_TCf-uOIWufr8RjKRHUcB0jzoZ",
          "timestamp": 1719170535908
        },
        {
          "file_id": "1rMS2cnwRlpP6NSfAA_mDuXFnbLEc6UnM",
          "timestamp": 1718735304309
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
