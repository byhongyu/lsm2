{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzh4DG0fCRQO"
      },
      "outputs": [],
      "source": [
        "from google3.learning.deepmind.xmanager2.client import xmanager_api\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import re\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import warnings\n",
        "from matplotlib.ticker import FixedLocator  # Import for the fix\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "# Suppress specific warning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "\n",
        "xm_client = xmanager_api.XManagerApi(xm_deployment_env='alphabet')\n",
        "MEDIUM_SIZE = 12\n",
        "mpl.rcParams.update({\n",
        "    'font.size': MEDIUM_SIZE,\n",
        "    'axes.labelsize': MEDIUM_SIZE,\n",
        "    'axes.titlesize': MEDIUM_SIZE,\n",
        "})\n",
        "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = MEDIUM_SIZE\n",
        "plt.rcParams['axes.linewidth'] = 1\n",
        "plt.rcParams['axes.edgecolor'] = '#777777'\n",
        "plt.rcParams['axes.facecolor'] = '#FFFFFF'\n",
        "\n",
        "\n",
        "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=MEDIUM_SIZE-5)  # legend fontsize\n",
        "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
        "\n",
        "elegant_palette = sns.color_palette('muted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBQR_rQhVhd4"
      },
      "outputs": [],
      "source": [
        "def read_xm_metrics(example_xid, metric_name, unit_id, lowest=True):\n",
        "  experiment = xm_client.get_experiment(example_xid)\n",
        "  work_unit = experiment.get_work_unit(unit_id)\n",
        "  all_series = work_unit.list_measurement_series()\n",
        "  # Read measurement series metadata.\n",
        "  for series in all_series:\n",
        "    if series.label == metric_name:\n",
        "      # Read measurement points data.\n",
        "      all_measurements = []\n",
        "      for measurement in series.measurements:\n",
        "        all_measurements.append(measurement.objective_value)\n",
        "      if lowest:\n",
        "        return min(all_measurements)\n",
        "      else:\n",
        "        return all_measurements\n",
        "\n",
        "\n",
        "def add_min_columns(df):\n",
        "  # Function to calculate the minimum value in each list\n",
        "  def min_of_list(lst):\n",
        "    return min(lst)\n",
        "\n",
        "  # Calculate minimum values and add as new columns\n",
        "  df['min_valid_mean_absolute_error_all'] = df[\n",
        "      'valid_mean_absolute_error_all'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_absolute_error_masked'] = df[\n",
        "      'valid_mean_absolute_error_masked'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_squared_error_all'] = df[\n",
        "      'valid_mean_squared_error_all'\n",
        "  ].apply(min_of_list)\n",
        "  df['min_valid_mean_squared_error_masked'] = df[\n",
        "      'valid_mean_squared_error_masked'\n",
        "  ].apply(min_of_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def process_string_metric(input_string):\n",
        "  # Define the mapping of long error names to their abbreviations\n",
        "  error_map = {'mean_absolute_error': 'mae', 'mean_squared_error': 'mse'}\n",
        "\n",
        "  # Replace the errors in the string using the map\n",
        "  for long_error, short_error in error_map.items():\n",
        "    input_string = re.sub(long_error, short_error, input_string)\n",
        "\n",
        "  # Remove 'valid_' and replace '/' with '_'\n",
        "  input_string = input_string.replace('valid_', '').replace('/', '_')\n",
        "\n",
        "  return input_string\n",
        "\n",
        "\n",
        "def generate_percentiled_numbers(max_value, percentiles):\n",
        "  \"\"\"Generate a list of integer numbers based on the given percentiles of the maximum value.\n",
        "\n",
        "  Parameters:\n",
        "  max_value (int): The maximum value to base the percentages on.\n",
        "  percentiles (list of float): A list of percentiles (0-100) to calculate.\n",
        "\n",
        "  Returns:\n",
        "  list of int: A list of integers corresponding to the given percentiles.\n",
        "  \"\"\"\n",
        "  return [round(max_value * (p / 100))-1 for p in percentiles]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6m9nh51kpZY"
      },
      "outputs": [],
      "source": [
        "# @title Data Loading\n",
        "\n",
        "# Get unique learning rates\n",
        "\n",
        "\n",
        "xm_id_dict = {  # Model Size, ParamSize, PatchSize\n",
        "    124248449: ['Tiny', 2.21, '10x5'],\n",
        "    124248804: ['ExtraSmall', 7.3, '10x5'],\n",
        "    # 124142001: ['Small', 24.6, '10x5'], #ignore this for now.\n",
        "    124248847: ['Base', 110.74, '10x5'],\n",
        "}\n",
        "\n",
        "compute_metrics = [\n",
        "    'core_hours_TPU v5 lite',\n",
        "    'train_mean_absolute_error_all',\n",
        "    'train_mean_absolute_error_masked',\n",
        "    'train_mean_squared_error_all',\n",
        "    'train_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "\n",
        "metric_names = [\n",
        "    'valid_mean_squared_error_masked',\n",
        "    'forecast_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'forecast_0.4_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.1_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.4_eval/valid_mean_squared_error_masked',\n",
        "]\n",
        "\n",
        "xm_exp_dict = collections.defaultdict(list)\n",
        "for key, values in xm_id_dict.items():\n",
        "  xm_id = key\n",
        "  model_size = values[0]\n",
        "  param_size = values[1]\n",
        "  patch_size = values[2]\n",
        "  experiment = xm_client.get_experiment(xm_id)\n",
        "  num_of_units = experiment.get_num_work_units()\n",
        "  for id in range(num_of_units):\n",
        "    real_id = id + 1\n",
        "    work_unit = experiment.get_work_unit(real_id)\n",
        "    key_list = work_unit.parameters.keys()\n",
        "    xm_exp_dict['unit_id'].append(id)\n",
        "    xm_exp_dict['xm_id'].append(xm_id)\n",
        "    xm_exp_dict['Param Size'].append(param_size)\n",
        "    xm_exp_dict['Model Size'].append(model_size)\n",
        "    xm_exp_dict['Patch Size'].append(patch_size)\n",
        "    for param_name in key_list:\n",
        "      xm_exp_dict[param_name].append(work_unit.parameters[param_name])\n",
        "    for metric in metric_names + compute_metrics:\n",
        "      xm_exp_dict[metric].append(\n",
        "          read_xm_metrics(xm_id, metric, real_id, lowest=False)\n",
        "      )\n",
        "df = pd.DataFrame(xm_exp_dict)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tC3pxexbVmt"
      },
      "outputs": [],
      "source": [
        "# @title Plot Main Scaling\n",
        "\n",
        "use_aug = True\n",
        "use_last = True\n",
        "sample_size = 1321235\n",
        "compute_hours_steps = [1, 5, 10, 20, 40, 80, 100]\n",
        "colors = ['#465ece', '#bed2f6', '#f8ab8d']\n",
        "other_metric_names = [\n",
        "    'forecast_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'imputation_0.2_eval/valid_mean_squared_error_masked',\n",
        "    'valid_mean_squared_error_masked',\n",
        "]\n",
        "line_alpha = 0.2\n",
        "circle_alpha = 1\n",
        "# Create a figure with a custom layout\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
        "\n",
        "# Unpack the axes for easier access\n",
        "ax1, ax2, ax3 = axs\n",
        "\n",
        "# Define marker sizes based on model sizes\n",
        "marker_size_map = {\n",
        "    'Deb': 50,\n",
        "    'Tiny': 75,\n",
        "    'ExtraSmall': 100,\n",
        "    'Small': 125,\n",
        "    'Base': 150,\n",
        "    'Large': 175,\n",
        "}\n",
        "\n",
        "data_scaling_list = []\n",
        "model_scaling_list = []\n",
        "compute_scaling_list = []\n",
        "\n",
        "for idx, metric_name in enumerate(other_metric_names):\n",
        "  displayed_metric = process_string_metric(metric_name)\n",
        "  color = colors[idx]\n",
        "\n",
        "  # Figure 1: Compute Scaling\n",
        "  if metric_name in other_metric_names:\n",
        "    # for data_size in df['config.dataset_configs.train_num_samples'].unique():\n",
        "    #   for model_size in df['Model Size'].unique():\n",
        "    for data_size in [100000, 750000, 1321235]:\n",
        "      for model_size in ['ExtraSmall', 'Base']:\n",
        "        subset = df[\n",
        "            (df['Model Size'] == model_size)\n",
        "            \u0026 (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "            \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "        ]\n",
        "\n",
        "        if not subset.empty:\n",
        "          x_idx = generate_percentiled_numbers(\n",
        "              len(subset.iloc[0]['core_hours_TPU v5 lite']), compute_hours_steps\n",
        "          )\n",
        "          x = [subset.iloc[0]['core_hours_TPU v5 lite'][idx] for idx in x_idx]\n",
        "          y_idx = generate_percentiled_numbers(\n",
        "              len(subset.iloc[0][metric_name]), compute_hours_steps\n",
        "          )\n",
        "          y = [subset.iloc[0][metric_name][idx] for idx in y_idx]\n",
        "          y = y[: len(x)]\n",
        "          if (\n",
        "              metric_name == 'valid_mean_squared_error_masked'\n",
        "              and model_size == 'Base'\n",
        "              and data_size == 1321235\n",
        "          ):\n",
        "            compute_scaling_list.append((x, y))\n",
        "          x = np.log10(x)\n",
        "          sns.scatterplot(\n",
        "              x=x,\n",
        "              y=y,\n",
        "              color=color,\n",
        "              ax=ax1,\n",
        "              s=marker_size_map[model_size],\n",
        "              alpha=circle_alpha,\n",
        "              legend=False,  # Turn off the legend for markers\n",
        "          )\n",
        "          # ax1.set_ylim(0, 0.85)\n",
        "          sns.lineplot(\n",
        "              x=x,\n",
        "              y=y[: len(x)],\n",
        "              color=color,\n",
        "              ax=ax1,\n",
        "              alpha=line_alpha,\n",
        "          )\n",
        "\n",
        "  # Figure 2: Data Scaling\n",
        "  for model_size in df['Model Size'].unique():\n",
        "    subset = df[\n",
        "        (df['Model Size'] == model_size)\n",
        "        \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "    ]\n",
        "\n",
        "    if not subset.empty:\n",
        "      x = []\n",
        "      y = []\n",
        "      for _, row in subset.iterrows():\n",
        "        x.append(round(row['config.dataset_configs.train_num_samples'] * 5, 2))\n",
        "        y.append(row[metric_name][-1] if use_last else min(row[metric_name]))\n",
        "      x = np.log10(x)\n",
        "      if metric_name == 'valid_mean_squared_error_masked':\n",
        "        data_scaling_list.append((x, y))\n",
        "      # Set the marker size based on the model size\n",
        "      marker_size = marker_size_map[model_size]\n",
        "\n",
        "      scatter = sns.scatterplot(\n",
        "          x=x,\n",
        "          y=y,\n",
        "          s=marker_size,  # Use 's' instead of 'size' to set marker size directly\n",
        "          color=color,\n",
        "          ax=ax2,\n",
        "          alpha=circle_alpha,\n",
        "          legend=False,\n",
        "      )\n",
        "      # ax2.set_ylim(0, 0.85)\n",
        "      sns.lineplot(x=x, y=y, color=color, ax=ax2, alpha=line_alpha)\n",
        "\n",
        "  # Figure 3: Model Scaling\n",
        "  if metric_name in other_metric_names:\n",
        "    for data_size in [100000, 750000, 1321235]:\n",
        "      subset = df[\n",
        "          (df['config.dataset_configs.train_num_samples'] == data_size)\n",
        "          \u0026 (df['config.use_train_augmentations'] == use_aug)\n",
        "      ]\n",
        "\n",
        "      if not subset.empty:\n",
        "        x = [row['Param Size'] for _, row in subset.iterrows()]\n",
        "        y = [\n",
        "            row[metric_name][-1] if use_last else min(row[metric_name])\n",
        "            for _, row in subset.iterrows()\n",
        "        ]\n",
        "        sizes = [\n",
        "            marker_size_map[row['Model Size']] for _, row in subset.iterrows()\n",
        "        ]\n",
        "        if metric_name == 'valid_mean_squared_error_masked':\n",
        "          model_scaling_list.append((x, y))\n",
        "        x = np.log10(x)\n",
        "        sns.scatterplot(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            size=sizes,\n",
        "            sizes=(75, 150),\n",
        "            color=color,\n",
        "            ax=ax3,\n",
        "            alpha=circle_alpha,\n",
        "            legend=False,\n",
        "        )\n",
        "        # ax3.set_ylim(0, 0.65)\n",
        "        sns.lineplot(x=x, y=y, color=color, ax=ax3, alpha=line_alpha)\n",
        "\n",
        "\n",
        "# Titles and labels\n",
        "ax1.set_xlabel(r'$\\mathbf{Compute}$' + '\\n TPU v5 VLP core hours')\n",
        "ax1.set_ylabel('Masked Mean Squared Error')\n",
        "ax2.set_xlabel(r'$\\mathbf{Data\\ Size}$' + '\\n(Hours)')\n",
        "ax3.set_xlabel(r'$\\mathbf{Model\\ Size}$' + '\\n(Million of Params)')\n",
        "\n",
        "# Set the number of ticks and ensure unique tick labels\n",
        "for ax in [ax1, ax2, ax3]:\n",
        "  ax.xaxis.set_major_locator(\n",
        "      MaxNLocator(integer=True, prune='both')\n",
        "  )  # Adjust to avoid repetitive ticks\n",
        "  xticks = ax.get_xticks()\n",
        "  ax.xaxis.set_major_locator(FixedLocator(xticks))\n",
        "  ax.set_xticklabels([\n",
        "      f'$10^{int(val)}$' if i == 0 or val != xticks[i - 1] else ''\n",
        "      for i, val in enumerate(xticks)\n",
        "  ])\n",
        "\n",
        "marker_sizes = [\n",
        "    marker_size_map['Tiny'],\n",
        "    marker_size_map['ExtraSmall'],\n",
        "    marker_size_map['Base'],\n",
        "]\n",
        "marker_labels = ['2M', '7M', '110M']\n",
        "\n",
        "marker_handles = [\n",
        "    plt.scatter([], [], s=size, color='black') for size in marker_sizes\n",
        "]\n",
        "\n",
        "# Task legend\n",
        "task_handles = [\n",
        "    plt.Line2D([0], [0], color=color, linestyle='-', linewidth=2)\n",
        "    for color in colors\n",
        "]\n",
        "task_labels = ['Forecasting', 'Imputation', 'Random Filling']\n",
        "\n",
        "# Combine handles and labels\n",
        "combined_handles = marker_handles + task_handles\n",
        "combined_labels = marker_labels + task_labels\n",
        "\n",
        "# Add combined legend at the top center\n",
        "fig.legend(\n",
        "    combined_handles,\n",
        "    combined_labels,\n",
        "    title='',\n",
        "    loc='upper center',\n",
        "    bbox_to_anchor=(0.5, 1.06),  # Center the combined legend\n",
        "    ncol=len(combined_labels),\n",
        "    frameon=False,\n",
        "    fontsize=MEDIUM_SIZE,\n",
        "    handletextpad=0.4,\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/tmp/lsm_main_scaling.png\", bbox_inches='tight', format=\"png\")\n",
        "plt.show()\n",
        "%download_file /tmp/lsm_main_scaling.png\n",
        "plt.savefig(\"/tmp/lsm_main_scaling.pdf\", bbox_inches='tight', format=\"pdf\")\n",
        "%download_file /tmp/lsm_main_scaling.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY3xuX5I2zI5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "lsm_scaling_analys_final_iclr.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_final_iclr.ipynb?workspaceId=xliucs:scaling_analysis::citc",
          "timestamp": 1724963506034
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_final_iclr.ipynb",
          "timestamp": 1723509130272
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data_size.ipynb?workspaceId=xliucs:scaling_analysis_new_pretrain::citc",
          "timestamp": 1723419354747
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data_size.ipynb",
          "timestamp": 1723071326500
        },
        {
          "file_id": "1Q3nbnc5dYAV6pyHWeKKXRVbxMwBPPQuB",
          "timestamp": 1719441633704
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analys_data.ipynb",
          "timestamp": 1719435410567
        },
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/lsm_scaling_analysis_parameter_sweep.ipynb?workspaceId=xliucs:lsm_notebooks_scaling_june22::citc",
          "timestamp": 1719177613159
        },
        {
          "file_id": "1avNG7EtMynPa2U-GHj2nd4nWWdGzcFq3",
          "timestamp": 1719177577595
        },
        {
          "file_id": "1WdhekZ_TCf-uOIWufr8RjKRHUcB0jzoZ",
          "timestamp": 1719170535908
        },
        {
          "file_id": "1rMS2cnwRlpP6NSfAA_mDuXFnbLEc6UnM",
          "timestamp": 1718735304309
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
