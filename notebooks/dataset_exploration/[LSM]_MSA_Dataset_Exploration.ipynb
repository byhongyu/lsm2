{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc13zPnCGyLg"
      },
      "source": [
        "Grants command for Access on Demand (AoD)\n",
        "\n",
        "https://grants.corp.google.com/#/grants?request=20h%2Fchr-ards-electrodes-deid-colab-jobs\u0026reason=b%2F314799341\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AKnw0reDFr9"
      },
      "source": [
        "# Load TF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajpV4QpcGu8m"
      },
      "outputs": [],
      "source": [
        "from colabtools import adhoc_import\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google3.pyglib import gfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds = tfds.load('lsm_prod/lsm_300min_100K_unimpute', data_dir='/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/raw/datasets/msa_1_5/lsm_tfds_datasets', split='train', shuffle_files=True)\n",
        "assert isinstance(ds, tf.data.Dataset)\n",
        "print(ds)\n",
        "\n",
        "with gfile.Open('/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/raw/datasets/msa_1_5/lsm_tfds_datasets/lsm_prod/lsm_300min_100K_unimpute/1.0.0/Dataset_FeatureNames.csv', 'r') as f:\n",
        "  df = pd.read_csv(f)\n",
        "\n",
        "features = df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEWI5FvaDIrG"
      },
      "source": [
        "# Plot Minutely Data Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cypLVX61YpdU"
      },
      "outputs": [],
      "source": [
        "ds = ds.take(1)  # Only take a single example\n",
        "\n",
        "for example in ds:  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "  print(list(example.keys()))\n",
        "  inputs = example[\"input_signal\"]\n",
        "  label = example[\"label\"]\n",
        "  print(inputs.shape, label)\n",
        "\n",
        "  plt.figure(figsize=(15,10))\n",
        "  imgplot = plt.imshow(np.swapaxes(inputs,0,1))\n",
        "  plt.grid(None)\n",
        "  plt.xlabel('Time (minutes)')\n",
        "  plt.ylabel('Feature #')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsOo6cYU_11x"
      },
      "outputs": [],
      "source": [
        "ds = ds.take(1)  # Only take a single example\n",
        "\n",
        "for example in ds:  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "  print(list(example.keys()))\n",
        "  inputs = example[\"input_signal\"]\n",
        "  label = example[\"label\"]\n",
        "  print(inputs.shape, label)\n",
        "\n",
        "  fig, axs = plt.subplots(25, 1, figsize=(10,35))#, layout='constrained')\n",
        "  #plt.figure(figsize=(15,10))\n",
        "\n",
        "  for i, ax in enumerate(axs):\n",
        "    ax.plot(inputs[:,i])\n",
        "    ax.set_title(features[i])\n",
        "    if i \u003c len(axs) - 1:\n",
        "      ax.get_xaxis().set_ticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nnNv4f_nxQ3"
      },
      "source": [
        "# Example of Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6yz0V_jn1BE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from colabtools import adhoc_import\n",
        "with adhoc_import.Google3(behavior='preferred'):\n",
        "  import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "train_ds = tfds.load('lsm_prod/lsm_300min_100K_unimpute', data_dir='/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/raw/datasets/msa_1_5/lsm_tfds_datasets', split='train', shuffle_files=True)\n",
        "assert isinstance(ds, tf.data.Dataset)\n",
        "print(ds)\n",
        "test_ds = tfds.load('lsm_prod/lsm_300min_100K_unimpute', data_dir='/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/raw/datasets/msa_1_5/lsm_tfds_datasets', split='test', shuffle_files=True)\n",
        "\n",
        "train_ds = train_ds.map(lambda example: (tf.clip_by_value(tf.transpose(example['input_signal']+5, [1, 0, 2]),0, 10)))\n",
        "test_ds = test_ds.map(lambda example: (tf.clip_by_value(tf.transpose(example['input_signal']+5, [1, 0, 2]),0, 10)))\n",
        "\n",
        "examples = train_ds.take(1)  # Only take a single example\n",
        "\n",
        "for example in examples:\n",
        "  inputs = example\n",
        "  imgplot = plt.imshow(inputs)\n",
        "  plt.xlabel('Time (minutes)')\n",
        "  plt.ylabel('Feature #')\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "assert isinstance(train_ds, tf.data.Dataset)\n",
        "print(train_ds)\n",
        "\n",
        "\n",
        "\n",
        "# Create a Mirrored scope to allow for training across multiple GPUs\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "with mirrored_strategy.scope():\n",
        "\n",
        "    from tensorflow.keras import layers\n",
        "    #import tensorflow_addons as tfa\n",
        "    from tensorflow import keras\n",
        "    import tensorflow as tf\n",
        "\n",
        "    from datetime import datetime\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import random\n",
        "\n",
        "    # Setting seeds for reproducibility.\n",
        "    SEED = 42\n",
        "    tf.random.set_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    # DATA\n",
        "    BUFFER_SIZE = 1024\n",
        "    BATCH_SIZE = 32#256\n",
        "    AUTO = tf.data.AUTOTUNE\n",
        "    INPUT_SHAPE = (300, 26, 1)\n",
        "    NUM_CLASSES = 10\n",
        "\n",
        "    # OPTIMIZER\n",
        "    LEARNING_RATE = 5e-3\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # TRAINING\n",
        "    EPOCHS = 20\n",
        "\n",
        "    # AUGMENTATION\n",
        "    IMAGE_SIZE_1 = 25  # We'll resize input images to this size.\n",
        "    IMAGE_SIZE_2 = 300  # We'll resize input images to this size.\n",
        "    PATCH_SIZE_1 = 5  # Size of the patches to be extract from the input images.\n",
        "    PATCH_SIZE_2 = 10  # Size of the patches to be extract from the input images.\n",
        "    NO_CHANNELS = 1\n",
        "    NUM_PATCHES = (IMAGE_SIZE_1 // PATCH_SIZE_1) * (IMAGE_SIZE_2 // PATCH_SIZE_2) * NO_CHANNELS\n",
        "    MASK_PROPORTION = 0.75\n",
        "\n",
        "    # ENCODER and DECODER\n",
        "    LAYER_NORM_EPS = 1e-6\n",
        "    ENC_PROJECTION_DIM = 32#128\n",
        "    DEC_PROJECTION_DIM = 16#64\n",
        "    ENC_NUM_HEADS = 4\n",
        "    ENC_LAYERS = 3\n",
        "    DEC_NUM_HEADS = 4\n",
        "    DEC_LAYERS = 1 # The decoder is lightweight but should be reasonably deep for reconstruction.\n",
        "    ENC_TRANSFORMER_UNITS = [\n",
        "        ENC_PROJECTION_DIM * 2,\n",
        "        ENC_PROJECTION_DIM,\n",
        "    ]  # Size of the transformer layers.\n",
        "    DEC_TRANSFORMER_UNITS = [\n",
        "        DEC_PROJECTION_DIM * 2,\n",
        "        DEC_PROJECTION_DIM,\n",
        "    ]\n",
        "\n",
        "    def get_train_augmentation_model():\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                layers.Rescaling(1 / 10.0),\n",
        "                #layers.Resizing(INPUT_SHAPE[0] + 20, INPUT_SHAPE[0] + 20),\n",
        "                #layers.RandomCrop(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                #layers.RandomFlip(\"horizontal\"),\n",
        "            ],\n",
        "            name=\"train_data_augmentation\",\n",
        "        )\n",
        "        return model\n",
        "\n",
        "\n",
        "    def get_test_augmentation_model():\n",
        "        model = keras.Sequential(\n",
        "            [layers.Rescaling(1 / 10.0), ],#layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),],\n",
        "            name=\"test_data_augmentation\",\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    class Patches(layers.Layer):\n",
        "        def __init__(self, patch_size_1=PATCH_SIZE_1, patch_size_2=PATCH_SIZE_2, no_channels=NO_CHANNELS, img_size_1=IMAGE_SIZE_1, img_size_2=IMAGE_SIZE_2, **kwargs):\n",
        "            super().__init__(**kwargs)\n",
        "            self.patch_size_1 = patch_size_1\n",
        "            self.patch_size_2 = patch_size_2\n",
        "            self.img_size_1 = img_size_1\n",
        "            self.img_size_2 = img_size_2\n",
        "            self.no_channels = no_channels\n",
        "\n",
        "            # Assuming the image has three channels each patch would be\n",
        "            # of size (patch_size, patch_size, 3).\n",
        "            self.resize = layers.Reshape((-1, patch_size_1 * patch_size_2 * no_channels))\n",
        "\n",
        "        def call(self, images):\n",
        "            # Create patches from the input images\n",
        "            #print(images)\n",
        "            patches = tf.image.extract_patches(\n",
        "                images=images,\n",
        "                sizes=[1, self.patch_size_1, self.patch_size_2, 1],\n",
        "                strides=[1, self.patch_size_1, self.patch_size_2, 1],\n",
        "                rates=[1, 1, 1, 1],\n",
        "                padding=\"VALID\",\n",
        "            )\n",
        "\n",
        "            # Reshape the patches to (batch, num_patches, patch_area) and return it.\n",
        "            patches = self.resize(patches)\n",
        "            return patches\n",
        "\n",
        "        def show_patched_image(self, images, patches):\n",
        "            # This is a utility function which accepts a batch of images and its\n",
        "            # corresponding patches and help visualize one image and its patches\n",
        "            # side by side.\n",
        "            idx = np.random.choice(patches.shape[0])\n",
        "            #print(f\"Index selected: {idx}.\")\n",
        "\n",
        "            plt.figure(figsize=(4, 4))\n",
        "            plt.imshow(keras.utils.array_to_img(images[idx]))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "            n = int(np.sqrt(patches.shape[1]))\n",
        "            plt.figure(figsize=(4, 4))\n",
        "            for i, patch in enumerate(patches[idx]):\n",
        "                ax = plt.subplot(images[idx].shape[0]//self.patch_size_1, images[idx].shape[1]//self.patch_size_2, i + 1)\n",
        "                patch_img = tf.reshape(patch, (self.patch_size_1, self.patch_size_2, self.no_channels))\n",
        "                plt.imshow(keras.utils.img_to_array(patch_img))\n",
        "                plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "            # Return the index chosen to validate it outside the method.\n",
        "            return idx\n",
        "\n",
        "        # taken from https://stackoverflow.com/a/58082878/10319735\n",
        "        def reconstruct_from_patch(self, patch):\n",
        "            # This utility function takes patches from a *single* image and\n",
        "            # reconstructs it back into the image. This is useful for the train\n",
        "            # monitor callback.\n",
        "\n",
        "            num_patches = patch.shape[0]\n",
        "\n",
        "            num_patches_1 = self.img_size_1 // self.patch_size_1\n",
        "            num_patches_2 = self.img_size_2 // self.patch_size_2\n",
        "            #n = int(np.sqrt(num_patches))\n",
        "            patch = tf.reshape(patch, (num_patches, self.patch_size_1, self.patch_size_2, self.no_channels))\n",
        "            rows = tf.split(patch, num_patches_1, axis=0)\n",
        "            rows = [tf.concat(tf.unstack(x), axis=1) for x in rows]\n",
        "            reconstructed = tf.concat(rows, axis=0)\n",
        "            return reconstructed\n",
        "\n",
        "    # Get a batch of images.\n",
        "    train_ds = train_ds.batch(BATCH_SIZE)\n",
        "    val_ds = test_ds.batch(BATCH_SIZE)\n",
        "    image_batch = next(iter(train_ds))\n",
        "    #image_batch = image_batch[\"input_signal\"]\n",
        "    #image_batch = tf.transpose(image_batch, [0, 2, 1, 3])\n",
        "\n",
        "    # Augment the images.\n",
        "    augmentation_model = get_train_augmentation_model()\n",
        "    augmeneted_images = augmentation_model(image_batch)\n",
        "\n",
        "    # Define the patch layer.\n",
        "    patch_layer = Patches()\n",
        "\n",
        "    # Get the patches from the batched images.\n",
        "    patches = patch_layer(images=augmeneted_images)\n",
        "\n",
        "    # Now pass the images and the corresponding patches\n",
        "    # to the `show_patched_image` method.\n",
        "    random_index = patch_layer.show_patched_image(images=augmeneted_images, patches=patches)\n",
        "\n",
        "    # Chose the same chose image and try reconstructing the patches\n",
        "    # into the original image.\n",
        "    image = patch_layer.reconstruct_from_patch(patches[random_index])\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    class PatchEncoder(layers.Layer):\n",
        "        def __init__(\n",
        "            self,\n",
        "            patch_size_1=PATCH_SIZE_1,\n",
        "            patch_size_2=PATCH_SIZE_2,\n",
        "            no_channels=NO_CHANNELS,\n",
        "            projection_dim=ENC_PROJECTION_DIM,\n",
        "            mask_proportion=MASK_PROPORTION,\n",
        "            downstream=False,\n",
        "            **kwargs,\n",
        "        ):\n",
        "            super().__init__(**kwargs)\n",
        "            self.patch_size_1 = patch_size_1\n",
        "            self.patch_size_2 = patch_size_2\n",
        "            self.no_channels = no_channels\n",
        "            self.projection_dim = projection_dim\n",
        "            self.mask_proportion = mask_proportion\n",
        "            self.downstream = downstream\n",
        "\n",
        "            # This is a trainable mask token initialized randomly from a normal\n",
        "            # distribution.\n",
        "            self.mask_token = tf.Variable(\n",
        "                tf.random.normal([1, patch_size_1 * patch_size_2 * no_channels]), trainable=True\n",
        "            )\n",
        "\n",
        "        def build(self, input_shape):\n",
        "            (_, self.num_patches, self.patch_area) = input_shape\n",
        "\n",
        "            # Create the projection layer for the patches.\n",
        "            self.projection = layers.Dense(units=self.projection_dim)\n",
        "\n",
        "            # Create the positional embedding layer.\n",
        "            self.position_embedding = layers.Embedding(\n",
        "                input_dim=self.num_patches, output_dim=self.projection_dim\n",
        "            )\n",
        "\n",
        "            # Number of patches that will be masked.\n",
        "            self.num_mask = int(self.mask_proportion * self.num_patches)\n",
        "\n",
        "        def call(self, patches):\n",
        "            # Get the positional embeddings.\n",
        "            batch_size = tf.shape(patches)[0]\n",
        "            positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "            pos_embeddings = self.position_embedding(positions[tf.newaxis, ...])\n",
        "            pos_embeddings = tf.tile(\n",
        "                pos_embeddings, [batch_size, 1, 1]\n",
        "            )  # (B, num_patches, projection_dim)\n",
        "\n",
        "            # Embed the patches.\n",
        "            patch_embeddings = (\n",
        "                self.projection(patches) + pos_embeddings\n",
        "            )  # (B, num_patches, projection_dim)\n",
        "\n",
        "            if self.downstream:\n",
        "                return patch_embeddings\n",
        "            else:\n",
        "                mask_indices, unmask_indices = self.get_random_indices(batch_size)\n",
        "                # The encoder input is the unmasked patch embeddings. Here we gather\n",
        "                # all the patches that should be unmasked.\n",
        "                unmasked_embeddings = tf.gather(\n",
        "                    patch_embeddings, unmask_indices, axis=1, batch_dims=1\n",
        "                )  # (B, unmask_numbers, projection_dim)\n",
        "\n",
        "                # Get the unmasked and masked position embeddings. We will need them\n",
        "                # for the decoder.\n",
        "                unmasked_positions = tf.gather(\n",
        "                    pos_embeddings, unmask_indices, axis=1, batch_dims=1\n",
        "                )  # (B, unmask_numbers, projection_dim)\n",
        "                masked_positions = tf.gather(\n",
        "                    pos_embeddings, mask_indices, axis=1, batch_dims=1\n",
        "                )  # (B, mask_numbers, projection_dim)\n",
        "\n",
        "                # Repeat the mask token number of mask times.\n",
        "                # Mask tokens replace the masks of the image.\n",
        "                mask_tokens = tf.repeat(self.mask_token, repeats=self.num_mask, axis=0)\n",
        "                mask_tokens = tf.repeat(\n",
        "                    mask_tokens[tf.newaxis, ...], repeats=batch_size, axis=0\n",
        "                )\n",
        "\n",
        "                # Get the masked embeddings for the tokens.\n",
        "                masked_embeddings = self.projection(mask_tokens) + masked_positions\n",
        "                return (\n",
        "                    unmasked_embeddings,  # input to the encoder\n",
        "                    masked_embeddings,  # first part of input to the decoder\n",
        "                    unmasked_positions,  # added to the encoder outputs\n",
        "                    mask_indices,  # the indices that were masked\n",
        "                    unmask_indices,  # the indices that were unmaksed\n",
        "                )\n",
        "\n",
        "        def get_random_indices(self, batch_size):\n",
        "            # Create random indices from a uniform distribution and then split\n",
        "            # it into mask and unmask indices.\n",
        "            rand_indices = tf.argsort(\n",
        "                tf.random.uniform(shape=(batch_size, self.num_patches)), axis=-1\n",
        "            )\n",
        "            mask_indices = rand_indices[:, : self.num_mask]\n",
        "            unmask_indices = rand_indices[:, self.num_mask :]\n",
        "\n",
        "            return mask_indices, unmask_indices\n",
        "\n",
        "        def show_masked_image(self, patches, unmask_indices):\n",
        "            # choose a random patch and it corresponding unmask index\n",
        "            idx = np.random.choice(patches.shape[0])\n",
        "            patch = patches[idx]\n",
        "            unmask_index = unmask_indices[idx]\n",
        "\n",
        "            # build a numpy array of same shape as pathc\n",
        "            new_patch = np.zeros_like(patch)\n",
        "\n",
        "            # iterate of the new_patch and plug the unmasked patches\n",
        "            count = 0\n",
        "            for i in range(unmask_index.shape[0]):\n",
        "                new_patch[unmask_index[i]] = patch[unmask_index[i]]\n",
        "            return new_patch, idx\n",
        "\n",
        "    # Create the patch encoder layer.\n",
        "    patch_encoder = PatchEncoder()\n",
        "\n",
        "    # Get the embeddings and positions.\n",
        "    (\n",
        "        unmasked_embeddings,\n",
        "        masked_embeddings,\n",
        "        unmasked_positions,\n",
        "        mask_indices,\n",
        "        unmask_indices,\n",
        "    ) = patch_encoder(patches=patches)\n",
        "\n",
        "    # Show a maksed patch image.\n",
        "    new_patch, random_index = patch_encoder.show_masked_image(patches, unmask_indices)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    img = patch_layer.reconstruct_from_patch(new_patch)\n",
        "    plt.imshow(keras.utils.array_to_img(img))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Masked\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    img = augmeneted_images[random_index]\n",
        "    plt.imshow(keras.utils.array_to_img(img))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Original\")\n",
        "    plt.show()\n",
        "\n",
        "    def mlp(x, dropout_rate, hidden_units):\n",
        "        for units in hidden_units:\n",
        "            x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "        return x\n",
        "\n",
        "    def create_encoder(num_heads=ENC_NUM_HEADS, num_layers=ENC_LAYERS):\n",
        "        inputs = layers.Input((None, ENC_PROJECTION_DIM))\n",
        "        x = inputs\n",
        "\n",
        "        #x = layers.BatchNormalization()(x)\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            # Layer normalization 1.\n",
        "            x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
        "\n",
        "            # Create a multi-head attention layer.\n",
        "            attention_output = layers.MultiHeadAttention(\n",
        "                num_heads=num_heads, key_dim=ENC_PROJECTION_DIM, dropout=0.1\n",
        "            )(x1, x1)\n",
        "\n",
        "            # Skip connection 1.\n",
        "            x2 = layers.Add()([attention_output, x])\n",
        "\n",
        "            # Layer normalization 2.\n",
        "            x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
        "\n",
        "            # MLP.\n",
        "            x3 = mlp(x3, hidden_units=ENC_TRANSFORMER_UNITS, dropout_rate=0.1)\n",
        "\n",
        "            # Skip connection 2.\n",
        "            x = layers.Add()([x3, x2])\n",
        "\n",
        "        outputs = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
        "        return keras.Model(inputs, outputs, name=\"mae_encoder\")\n",
        "\n",
        "    def create_decoder(\n",
        "        num_layers=DEC_LAYERS, num_heads=DEC_NUM_HEADS, image_size_1=IMAGE_SIZE_1, image_size_2=IMAGE_SIZE_2, no_channels=NO_CHANNELS\n",
        "    ):\n",
        "        inputs = layers.Input((NUM_PATCHES, ENC_PROJECTION_DIM))\n",
        "        x = layers.Dense(DEC_PROJECTION_DIM)(inputs)\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            # Layer normalization 1.\n",
        "            x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
        "\n",
        "            # Create a multi-head attention layer.\n",
        "            attention_output = layers.MultiHeadAttention(\n",
        "                num_heads=num_heads, key_dim=DEC_PROJECTION_DIM, dropout=0.1\n",
        "            )(x1, x1)\n",
        "\n",
        "            # Skip connection 1.\n",
        "            x2 = layers.Add()([attention_output, x])\n",
        "\n",
        "            # Layer normalization 2.\n",
        "            x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
        "\n",
        "            # MLP.\n",
        "            x3 = mlp(x3, hidden_units=DEC_TRANSFORMER_UNITS, dropout_rate=0.1)\n",
        "\n",
        "            # Skip connection 2.\n",
        "            x = layers.Add()([x3, x2])\n",
        "\n",
        "        x = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
        "        x = layers.Flatten()(x)\n",
        "        pre_final = layers.Dense(units=image_size_1 * image_size_2 * no_channels, activation=\"sigmoid\")(x)\n",
        "        outputs = layers.Reshape((image_size_1, image_size_2, no_channels))(pre_final)\n",
        "\n",
        "        return keras.Model(inputs, outputs, name=\"mae_decoder\")\n",
        "\n",
        "    class MaskedAutoencoder(keras.Model):\n",
        "        def __init__(\n",
        "            self,\n",
        "            train_augmentation_model,\n",
        "            test_augmentation_model,\n",
        "            patch_layer,\n",
        "            patch_encoder,\n",
        "            encoder,\n",
        "            decoder,\n",
        "            **kwargs\n",
        "        ):\n",
        "            super().__init__(**kwargs)\n",
        "            self.train_augmentation_model = train_augmentation_model\n",
        "            self.test_augmentation_model = test_augmentation_model\n",
        "            self.patch_layer = patch_layer\n",
        "            self.patch_encoder = patch_encoder\n",
        "            self.encoder = encoder\n",
        "            self.decoder = decoder\n",
        "\n",
        "        def calculate_loss(self, images, test=False):\n",
        "            # Augment the input images.\n",
        "            if test:\n",
        "                augmeneted_images = self.test_augmentation_model(images)\n",
        "            else:\n",
        "                augmeneted_images = self.train_augmentation_model(images)\n",
        "\n",
        "            # Patch the augmented images.\n",
        "            patches = self.patch_layer(augmeneted_images)\n",
        "\n",
        "            # Encode the patches.\n",
        "            (\n",
        "                unmasked_embeddings,\n",
        "                masked_embeddings,\n",
        "                unmasked_positions,\n",
        "                mask_indices,\n",
        "                unmask_indices,\n",
        "            ) = self.patch_encoder(patches)\n",
        "\n",
        "            # Pass the unmaksed patche to the encoder.\n",
        "            encoder_outputs = self.encoder(unmasked_embeddings)\n",
        "\n",
        "            # Create the decoder inputs.\n",
        "            encoder_outputs = encoder_outputs + unmasked_positions\n",
        "            decoder_inputs = tf.concat([encoder_outputs, masked_embeddings], axis=1)\n",
        "\n",
        "            # Decode the inputs.\n",
        "            decoder_outputs = self.decoder(decoder_inputs)\n",
        "            decoder_patches = self.patch_layer(decoder_outputs)\n",
        "\n",
        "            loss_patch = tf.gather(patches, mask_indices, axis=1, batch_dims=1)\n",
        "            loss_output = tf.gather(decoder_patches, mask_indices, axis=1, batch_dims=1)\n",
        "\n",
        "            # Compute the total loss.\n",
        "            total_loss = self.compiled_loss(loss_patch, loss_output)\n",
        "\n",
        "            return total_loss, loss_patch, loss_output\n",
        "\n",
        "        def train_step(self, images):\n",
        "            with tf.GradientTape() as tape:\n",
        "                total_loss, loss_patch, loss_output = self.calculate_loss(images)\n",
        "\n",
        "            # Apply gradients.\n",
        "            train_vars = [\n",
        "                self.train_augmentation_model.trainable_variables,\n",
        "                self.patch_layer.trainable_variables,\n",
        "                self.patch_encoder.trainable_variables,\n",
        "                self.encoder.trainable_variables,\n",
        "                self.decoder.trainable_variables,\n",
        "            ]\n",
        "            grads = tape.gradient(total_loss, train_vars)\n",
        "            tv_list = []\n",
        "            for (grad, var) in zip(grads, train_vars):\n",
        "                for g, v in zip(grad, var):\n",
        "                    tv_list.append((g, v))\n",
        "            self.optimizer.apply_gradients(tv_list)\n",
        "\n",
        "            # Report progress.\n",
        "            self.compiled_metrics.update_state(loss_patch, loss_output)\n",
        "            return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        def test_step(self, images):\n",
        "            total_loss, loss_patch, loss_output = self.calculate_loss(images, test=True)\n",
        "\n",
        "            # Update the trackers.\n",
        "            self.compiled_metrics.update_state(loss_patch, loss_output)\n",
        "            return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    train_augmentation_model = get_train_augmentation_model()\n",
        "    test_augmentation_model = get_test_augmentation_model()\n",
        "    patch_layer = Patches()\n",
        "    patch_encoder = PatchEncoder()\n",
        "    encoder = create_encoder()\n",
        "    decoder = create_decoder()\n",
        "\n",
        "    mae_model = MaskedAutoencoder(\n",
        "        train_augmentation_model=train_augmentation_model,\n",
        "        test_augmentation_model=test_augmentation_model,\n",
        "        patch_layer=patch_layer,\n",
        "        patch_encoder=patch_encoder,\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "    )\n",
        "\n",
        "    # Taking a batch of test inputs to measure model's progress.\n",
        "    test_images = next(iter(val_ds))\n",
        "    #test_images = test_images[\"input_signal\"]\n",
        "\n",
        "    class TrainMonitor(tf.keras.callbacks.Callback):\n",
        "        def __init__(self, epoch_interval=None):\n",
        "            self.epoch_interval = epoch_interval\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            if self.epoch_interval and epoch % self.epoch_interval == 0:\n",
        "                test_augmeneted_images = self.model.test_augmentation_model(test_images)\n",
        "                test_patches = self.model.patch_layer(test_augmeneted_images)\n",
        "                (\n",
        "                    test_unmasked_embeddings,\n",
        "                    test_masked_embeddings,\n",
        "                    test_unmasked_positions,\n",
        "                    test_mask_indices,\n",
        "                    test_unmask_indices,\n",
        "                ) = self.model.patch_encoder(test_patches)\n",
        "                test_encoder_outputs = self.model.encoder(test_unmasked_embeddings)\n",
        "                test_encoder_outputs = test_encoder_outputs + test_unmasked_positions\n",
        "                test_decoder_inputs = tf.concat(\n",
        "                    [test_encoder_outputs, test_masked_embeddings], axis=1\n",
        "                )\n",
        "                test_decoder_outputs = self.model.decoder(test_decoder_inputs)\n",
        "\n",
        "                # Show a maksed patch image.\n",
        "                test_masked_patch, idx = self.model.patch_encoder.show_masked_image(\n",
        "                    test_patches, test_unmask_indices\n",
        "                )\n",
        "                print(f\"\\nIdx chosen: {idx}\")\n",
        "                original_image = test_augmeneted_images[idx]\n",
        "                masked_image = self.model.patch_layer.reconstruct_from_patch(\n",
        "                    test_masked_patch\n",
        "                )\n",
        "                reconstructed_image = test_decoder_outputs[idx]\n",
        "\n",
        "                fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "                ax[0].imshow(original_image)\n",
        "                ax[0].set_title(f\"Original: {epoch:03d}\")\n",
        "\n",
        "                ax[1].imshow(masked_image)\n",
        "                ax[1].set_title(f\"Masked: {epoch:03d}\")\n",
        "\n",
        "                ax[2].imshow(reconstructed_image)\n",
        "                ax[2].set_title(f\"Resonstructed: {epoch:03d}\")\n",
        "\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "\n",
        "\n",
        "    class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
        "        def __init__(\n",
        "            self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
        "        ):\n",
        "            super(WarmUpCosine, self).__init__()\n",
        "\n",
        "            self.learning_rate_base = learning_rate_base\n",
        "            self.total_steps = total_steps\n",
        "            self.warmup_learning_rate = warmup_learning_rate\n",
        "            self.warmup_steps = warmup_steps\n",
        "            self.pi = tf.constant(np.pi)\n",
        "\n",
        "        def __call__(self, step):\n",
        "            if self.total_steps \u003c self.warmup_steps:\n",
        "                raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
        "\n",
        "            cos_annealed_lr = tf.cos(\n",
        "                self.pi\n",
        "                * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
        "                / float(self.total_steps - self.warmup_steps)\n",
        "            )\n",
        "            learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
        "\n",
        "            if self.warmup_steps \u003e 0:\n",
        "                if self.learning_rate_base \u003c self.warmup_learning_rate:\n",
        "                    raise ValueError(\n",
        "                        \"Learning_rate_base must be larger or equal to \"\n",
        "                        \"warmup_learning_rate.\"\n",
        "                    )\n",
        "                slope = (\n",
        "                    self.learning_rate_base - self.warmup_learning_rate\n",
        "                ) / self.warmup_steps\n",
        "                warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
        "                learning_rate = tf.where(\n",
        "                    step \u003c self.warmup_steps, warmup_rate, learning_rate\n",
        "                )\n",
        "            return tf.where(\n",
        "                step \u003e self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
        "            )\n",
        "\n",
        "    total_steps = int((len(train_ds) / BATCH_SIZE) * EPOCHS)\n",
        "    warmup_steps = int(total_steps * 0.15)\n",
        "    scheduled_lrs = WarmUpCosine(\n",
        "        learning_rate_base=LEARNING_RATE,\n",
        "        total_steps=total_steps,\n",
        "        warmup_learning_rate=0.0,\n",
        "        warmup_steps=warmup_steps,\n",
        "    )\n",
        "\n",
        "    lrs = [scheduled_lrs(step) for step in range(total_steps)]\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel(\"Step\", fontsize=14)\n",
        "    plt.ylabel(\"LR\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    timestamp = datetime.utcnow().strftime(\"%y%m%d-%H%M%S\")\n",
        "\n",
        "    train_callbacks = [\n",
        "        keras.callbacks.TensorBoard(log_dir=f\"mae_logs_{timestamp}\"),\n",
        "        TrainMonitor(epoch_interval=1),\n",
        "    ]\n",
        "\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    mae_model.compile(\n",
        "        optimizer=optimizer, loss=keras.losses.MeanSquaredError(), metrics=[\"mae\"]\n",
        "    )\n",
        "\n",
        "    history = mae_model.fit(\n",
        "        train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=train_callbacks,\n",
        "    )\n",
        "\n",
        "    loss, mae = mae_model.evaluate(val_ds)\n",
        "    print(f\"Loss: {loss:.2f}\")\n",
        "    print(f\"MAE: {mae:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohzx5QpV0CUZ"
      },
      "source": [
        "# Move Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fucv0KE31Bg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google3.pyglib import gfile\n",
        "gfile.MakeDirs(\"/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/exp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lchAJXfY0vEL"
      },
      "outputs": [],
      "source": [
        "read_dir = \"/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/raw/datasets/msa_1_5/lsm_tfds_datasets/lsm_prod/lsm_300min_100K_unimpute\"\n",
        "\n",
        "\n",
        "\n",
        "from google3.pyglib.contrib.gfile_util import gfile_util\n",
        "gfile_util.CopyDir(read_dir, write_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9aTAfJ40EUw"
      },
      "outputs": [],
      "source": [
        "from colabtools import adhoc_import\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google3.pyglib import gfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds = tfds.load('lsm_prod/lsm_300min_100K_unimpute', data_dir='/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/raw/datasets/msa_1_5/lsm_tfds_datasets')\n",
        "print(ds)\n",
        "\n",
        "ds['train'].save('/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/exp/lsm_300min_100K_unimpute')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//fitbit/research/sensing/electrodes/colab:rl_colab",
        "kind": "shared"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/experimental/largesensormodels/notebooks/[LSM]_MSA_Dataset_Exploration.ipynb?workspaceId=dmcduff:Adding_training_to_lsm::citc",
          "timestamp": 1715888224647
        },
        {
          "file_id": "1VwtUXwpRNFuojHSF7hHPDImIKeY3Rlkd",
          "timestamp": 1715883900959
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
