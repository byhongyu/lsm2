{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl8y8d9po67C"
      },
      "source": [
        "# Exploring Reproducible Randomnenss\n",
        "##### Colab Kernel (Electrodes)\n",
        "##### Dataset (Electrodes)\n",
        "\n",
        "Grants command for Access on Demand (AoD):\n",
        "\n",
        "https://grants.corp.google.com/#/grants?request=20h%2Fchr-ards-electrodes-deid-colab-jobs\u0026reason=b%2F314799341\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GZBYUXeEUbg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1MCewaurabYh"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import io\n",
        "import functools\n",
        "from typing import Any, Callable, Dict, Iterator, Tuple, Optional, Type, Union\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "from absl import logging\n",
        "from clu import metric_writers\n",
        "from clu import periodic_actions\n",
        "from clu import platform\n",
        "\n",
        "import flax\n",
        "from flax import jax_utils\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.profiler\n",
        "\n",
        "import pandas as pd\n",
        "import ml_collections\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from colabtools import adhoc_import\n",
        "with adhoc_import.Google3():\n",
        "  from scenic.dataset_lib import dataset_utils\n",
        "  from scenic.google.xm import xm_utils\n",
        "  from scenic.model_lib.base_models import base_model\n",
        "  from scenic.model_lib.base_models import model_utils\n",
        "  from scenic.model_lib.layers import nn_ops\n",
        "  from scenic.model_lib.layers import nn_layers\n",
        "  from scenic.projects.baselines import vit\n",
        "  from scenic.train_lib import optax as scenic_optax\n",
        "  from scenic.train_lib import pretrain_utils\n",
        "  from scenic.train_lib import train_utils\n",
        "\n",
        "  from scenic.projects.multimask.models import model_utils as mm_model_utils\n",
        "\n",
        "  from google3.experimental.largesensormodels.scenic.datasets import dataset_constants\n",
        "  from google3.experimental.largesensormodels.scenic.datasets import lsm_tiny_dataset\n",
        "  from google3.experimental.largesensormodels.scenic.models import lsm_vit as lsm_vit_mae\n",
        "  from google3.experimental.largesensormodels.scenic.models.lsm_vit_utils import model_constants\n",
        "  from google3.experimental.largesensormodels.scenic.models.lsm_vit_utils import model_utils as lsm_model_utils\n",
        "  from google3.experimental.largesensormodels.scenic.trainers import lsm_mae_trainer\n",
        "\n",
        "  from google3.pyglib import gfile\n",
        "\n",
        "\n",
        "Batch = Dict[str, jnp.ndarray]\n",
        "MetricFn = Callable[\n",
        "    [jnp.ndarray, jnp.ndarray, Dict[str, jnp.ndarray]],\n",
        "    Dict[str, Tuple[float, int]],\n",
        "]\n",
        "LossFn = Callable[\n",
        "    [jnp.ndarray, Batch, Optional[jnp.ndarray], jnp.ndarray], float\n",
        "]\n",
        "LrFns = Dict[str, Callable[[jnp.ndarray], jnp.ndarray]]\n",
        "Patch = Union[Tuple[int, int], Tuple[int, int, int]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NiW84UC2pNCQ"
      },
      "outputs": [],
      "source": [
        "# @title Sample Model Config\n",
        "\n",
        "r\"\"\"A config to train a Tiny ViT MAE on LSM 5M dataset.\n",
        "\n",
        "Forked from google3/third_party/py/scenic/projects/multimask/configs/mae_cifar10_tiny.py\n",
        "\n",
        "To run on XManager:\n",
        "gxm third_party/py/scenic/google/xm/launch_xm.py -- \\\n",
        "--binary //experimental/largesensormodels/scenic:main \\\n",
        "--config=experimental/largesensormodels/scenic/configs/mae_lsm_tiny.py \\\n",
        "--platform=vlp_4x4 \\\n",
        "--exp_name=lsm_mae_tier2_TinyShallow_10_5_res \\\n",
        "--workdir=/cns/dz-d/home/xliucs/lsm/xm/\\{xid\\} \\\n",
        "--xm_resource_alloc=group:mobile-dynamic/h2o-ai-gqm-quota \\\n",
        "--priority=200\n",
        "\n",
        "To run locally:\n",
        "./third_party/py/scenic/google/runlocal.sh \\\n",
        "--uptc=\"\" \\\n",
        "--binary=//experimental/largesensormodels/scenic:main \\\n",
        "--config=$(pwd)/experimental/largesensormodels/scenic/configs/mae_lsm_tiny.py:runlocal\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# To set constants.\n",
        "DATASET_NAME = 'lsm_300min_10M_impute'\n",
        "CACHE_DATASET = False\n",
        "TRAIN_DATA_SIZE = 1000000  # 100k train samples\n",
        "BATCH_SIZE = 8\n",
        "NUMBER_OF_EPOCH = 100\n",
        "REPEAT_DATA = False\n",
        "\n",
        "# Model variant / patch H (time steps) / patch W (features)\n",
        "VARIANT = 'TiShallow/10/5'\n",
        "LRS = [1e-3]\n",
        "TOKEN_MASK_PROB = 'constant_0.8'\n",
        "LOSS_ONLY_MASKED_TOKENS = True\n",
        "USE_DATETIME_FEATURES = True\n",
        "USE_TRAIN_AUGMENTATIONS = True\n",
        "TRAIN_AUGMENTATIONS = ['stretch', 'flip', 'noise']\n",
        "OHE_LABELS = True\n",
        "\n",
        "# Derived constants.\n",
        "TRAIN_DATA_SIZE = min(\n",
        "    TRAIN_DATA_SIZE,\n",
        "    dataset_constants.lsm_dataset_constants[DATASET_NAME]['num_train_examples']\n",
        ")\n",
        "\n",
        "STEPS_PER_EPOCH = max(1, int(TRAIN_DATA_SIZE / BATCH_SIZE))\n",
        "NUM_TRAIN_STEPS = int(NUMBER_OF_EPOCH * STEPS_PER_EPOCH)\n",
        "\n",
        "LOG_EVAL_SUMMARY_STEPS = STEPS_PER_EPOCH\n",
        "LOG_CHECKPOINT_STEPS = LOG_EVAL_SUMMARY_STEPS * 5\n",
        "MAX_NUM_CHECKPOINTS = int(NUM_TRAIN_STEPS / LOG_CHECKPOINT_STEPS)\n",
        "\n",
        "\n",
        "def get_config_common_few_shot(\n",
        "    batch_size: Optional[int] = None,\n",
        "    target_resolution: int = 224,\n",
        "    resize_resolution: int = 256,\n",
        ") -\u003e ml_collections.ConfigDict:\n",
        "  \"\"\"Returns a standard-ish fewshot eval configuration.\n",
        "\n",
        "  Copied from\n",
        "  third_party/py/scenic/projects/baselines/configs/google/common/common_fewshot.py\n",
        "\n",
        "  Args:\n",
        "    batch_size: The batch size to use for fewshot evaluation.\n",
        "    target_resolution: The target resolution of the fewshot evaluation.\n",
        "    resize_resolution: The resize resolution of the fewshot evaluation.\n",
        "\n",
        "  Returns:\n",
        "    A ConfigDict with the fewshot evaluation configuration.\n",
        "  \"\"\"\n",
        "  config = ml_collections.ConfigDict()\n",
        "  config.batch_size = batch_size\n",
        "  config.representation_layer = 'pre_logits'\n",
        "  config.log_eval_steps = 25_000\n",
        "  config.datasets = {\n",
        "      'birds': ('caltech_birds2011', 'train', 'test'),\n",
        "      'caltech': ('caltech101', 'train', 'test'),\n",
        "      'cars': ('cars196:2.1.0', 'train', 'test'),\n",
        "      'cifar100': ('cifar100', 'train', 'test'),\n",
        "      'col_hist': ('colorectal_histology', 'train[:2000]', 'train[2000:]'),\n",
        "      'dtd': ('dtd', 'train', 'test'),\n",
        "      'imagenet': ('imagenet2012_subset/10pct', 'train', 'validation'),\n",
        "      'pets': ('oxford_iiit_pet', 'train', 'test'),\n",
        "      'uc_merced': ('uc_merced', 'train[:1000]', 'train[1000:]'),\n",
        "  }\n",
        "  config.pp_train = f'decode|resize({resize_resolution})|central_crop({target_resolution})|value_range(-1,1)'\n",
        "  config.pp_eval = f'decode|resize({resize_resolution})|central_crop({target_resolution})|value_range(-1,1)'\n",
        "  config.shots = [1, 5, 10, 25]\n",
        "  config.l2_regs = [2.0**i for i in range(-10, 20)]\n",
        "  config.walk_first = ('imagenet', 10)\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "def get_config(runlocal=''):\n",
        "  \"\"\"Returns the ViT experiment configuration.\"\"\"\n",
        "\n",
        "  runlocal = bool(runlocal)\n",
        "\n",
        "  # Experiment.\n",
        "  config = ml_collections.ConfigDict()\n",
        "  config.experiment_name = f'electrodes-mae-{DATASET_NAME}-{TRAIN_DATA_SIZE}'\n",
        "  config.dataset_name = f'lsm_prod/{DATASET_NAME}'\n",
        "\n",
        "  config.shuffle_seed = 42\n",
        "\n",
        "  # Dataset.\n",
        "  config.data_dtype_str = 'float32'\n",
        "  config.dataset_configs = ml_collections.ConfigDict()\n",
        "  config.dataset_configs.dataset = f'lsm_prod/{DATASET_NAME}'\n",
        "  # config.dataset_configs.num_classes = NUM_CLASSES\n",
        "  config.dataset_configs.train_split = 'train'  # train data split\n",
        "  config.dataset_configs.train_num_samples = TRAIN_DATA_SIZE  # train sample\n",
        "  # eval data split - note: this split is used for validation and test.\n",
        "  config.dataset_configs.eval_split = 'test[:64]' if runlocal else 'test'\n",
        "  config.dataset_configs.cache_dataset = CACHE_DATASET\n",
        "  config.dataset_configs.prefetch_to_device = 2\n",
        "  # Shuffle_buffer_size is per host, so small-ish is ok.\n",
        "  config.dataset_configs.shuffle_buffer_size = 250_000\n",
        "  config.dataset_configs.repeat_data = REPEAT_DATA\n",
        "  config.dataset_configs.ohe_labels = OHE_LABELS\n",
        "\n",
        "  # Model.\n",
        "  if len(VARIANT.split('/')) == 3:\n",
        "    version = VARIANT.split('/')[0]  # model variant\n",
        "    patch_h = VARIANT.split('/')[1]  # patch width\n",
        "    patch_w = VARIANT.split('/')[2]  # patch height\n",
        "  elif len(VARIANT.split('/')) == 2:\n",
        "    version = VARIANT.split('/')[0]  # model variant\n",
        "    patch_h = VARIANT.split('/')[1]  # patch width\n",
        "    patch_w = VARIANT.split('/')[1]  # patch height\n",
        "  else:\n",
        "    raise ValueError(f'Invalid model variant: {VARIANT}')\n",
        "\n",
        "  version = 'Deb' if runlocal else version\n",
        "  config.model_name = 'lsm_vit_mae'\n",
        "  config.model = ml_collections.ConfigDict()\n",
        "  # encoder\n",
        "  config.model.hidden_size = model_constants.HIDDEN_SIZES[version]\n",
        "  config.model.patches = ml_collections.ConfigDict()\n",
        "  config.model.patches.size = tuple([int(patch_h), int(patch_w)])\n",
        "  config.model.num_heads = model_constants.NUM_HEADS[version]\n",
        "  config.model.mlp_dim = model_constants.MLP_DIMS[version]\n",
        "  config.model.num_layers = model_constants.NUM_LAYERS[version]\n",
        "  config.model.dropout_rate = 0.0\n",
        "  config.model.classifier = 'none'  # Has to be \"none\" for the autoencoder\n",
        "  config.model.representation_size = None\n",
        "  config.model.positional_embedding = 'sinusoidal_2d'\n",
        "  config.model.positional_embedding_decoder = 'sinusoidal_2d'\n",
        "  # decoder\n",
        "  config.model.decoder_config = ml_collections.ConfigDict()\n",
        "  config.model.decoder_config.hidden_size = (\n",
        "      model_constants.DECODER_HIDDEN_SIZES[version]\n",
        "  )\n",
        "  config.model.decoder_config.mlp_dim = model_constants.DECODER_MLP_DIMS[\n",
        "      version\n",
        "  ]\n",
        "  config.model.decoder_config.num_layers = model_constants.DECODER_NUM_LAYERS[\n",
        "      version\n",
        "  ]\n",
        "  config.model.decoder_config.num_heads = model_constants.DECODER_NUM_HEADS[\n",
        "      version\n",
        "  ]\n",
        "  config.model.decoder_config.dropout_rate = 0.0\n",
        "  config.model.decoder_config.attention_dropout_rate = 0.0\n",
        "\n",
        "  config.masked_feature_loss = ml_collections.ConfigDict()\n",
        "  config.masked_feature_loss.targets_type = 'rgb'\n",
        "  config.masked_feature_loss.token_mask_probability = TOKEN_MASK_PROB\n",
        "  config.masked_feature_loss.loss_only_masked_tokens = LOSS_ONLY_MASKED_TOKENS\n",
        "  config.masked_feature_loss.loss_type = 'squared'  # 'squared' or 'absolute'\n",
        "\n",
        "  # Datetime features.\n",
        "  config.use_datetime_features = USE_DATETIME_FEATURES\n",
        "\n",
        "  # Training.\n",
        "  config.trainer_name = 'lsm_mae_trainer'\n",
        "  config.batch_size = 8 if runlocal else BATCH_SIZE\n",
        "  config.num_training_steps = NUM_TRAIN_STEPS\n",
        "  config.log_eval_steps = LOG_EVAL_SUMMARY_STEPS\n",
        "  config.log_summary_steps = LOG_EVAL_SUMMARY_STEPS\n",
        "  config.rng_seed = 42\n",
        "  config.use_train_augmentations = USE_TRAIN_AUGMENTATIONS\n",
        "  config.train_augmentations = TRAIN_AUGMENTATIONS\n",
        "  sched = ml_collections.ConfigDict()\n",
        "  sched.re = '(.*)'\n",
        "  sched.lr_configs = ml_collections.ConfigDict()\n",
        "  sched.lr_configs.learning_rate_schedule = 'compound'\n",
        "  sched.lr_configs.factors = 'constant * cosine_decay * linear_warmup'\n",
        "  sched.lr_configs.total_steps = NUM_TRAIN_STEPS\n",
        "  sched.lr_configs.steps_per_cycle = sched.lr_configs.total_steps\n",
        "  sched.lr_configs.warmup_steps = STEPS_PER_EPOCH * NUMBER_OF_EPOCH * 0.05\n",
        "  sched.lr_configs.base_learning_rate = LRS[0]\n",
        "  config.schedule = ml_collections.ConfigDict({'all': sched})\n",
        "\n",
        "  # *Single* optimizer.\n",
        "  optim = ml_collections.ConfigDict()\n",
        "  optim.optax_name = 'scale_by_adam'\n",
        "  # optim.optax = dict(mu_dtype='bfloat16')\n",
        "  optim.optax_configs = ml_collections.ConfigDict({  # Optimizer settings.\n",
        "      'b1': 0.9,\n",
        "      'b2': 0.95,\n",
        "  })\n",
        "  config.optax = dict(mu_dtype='bfloat16')\n",
        "  optim.max_grad_norm = 1.0\n",
        "\n",
        "  optim.weight_decay = 1e-4\n",
        "  optim.weight_decay_decouple = True\n",
        "  config.optimizer = optim\n",
        "\n",
        "  # Fewshot.\n",
        "  # TODO(girishvn): This needs to be adapted to electrode dataset\n",
        "  config.fewshot = get_config_common_few_shot(batch_size=config.batch_size)\n",
        "  config.fewshot.datasets = {}\n",
        "  config.fewshot.walk_first = ()\n",
        "  config.fewshot.representation_layer = 'pre_logits'\n",
        "  config.fewshot.log_eval_steps = LOG_EVAL_SUMMARY_STEPS\n",
        "\n",
        "  # Logging.\n",
        "  config.write_summary = True\n",
        "  config.xprof = True  # Profile using xprof.\n",
        "  config.checkpoint = True  # Do checkpointing.\n",
        "  config.checkpoint_steps = LOG_CHECKPOINT_STEPS\n",
        "  config.debug_train = False  # Debug mode during training.\n",
        "  config.debug_eval = False  # Debug mode during eval.\n",
        "  config.max_checkpoints_to_keep = MAX_NUM_CHECKPOINTS\n",
        "  # BEGIN GOOGLE-INTERNAL\n",
        "  if runlocal:\n",
        "    # Current implementation fails with UPTC.\n",
        "    config.count_flops = False\n",
        "  # END GOOGLE-INTERNAL\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "# BEGIN GOOGLE-INTERNAL\n",
        "def get_hyper(hyper):\n",
        "  \"\"\"Defines the hyper-parameters sweeps for doing grid search.\"\"\"\n",
        "  return hyper.product([\n",
        "      hyper.sweep('config.schedule.all.lr_configs.base_learning_rate', LRS),\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8Ho2Xzoyk5uP"
      },
      "outputs": [],
      "source": [
        "# @title Data Dir\n",
        "\n",
        "data_dir='/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/exp/dmcduff/ttl=6w/msa_1_5/lsm_tfds_datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GI_ZNAO4GJw0"
      },
      "outputs": [],
      "source": [
        "# @title Dataset\n",
        "\n",
        "\"\"\"Electrodes dataset data preprocesser and loader.\n",
        "\n",
        "Adapted from a combination of the following files:\n",
        "google3/third_party/py/scenic/dataset_lib/cifar10_dataset.py\n",
        "google3/third_party/py/scenic/dataset_lib/dataset_utils.py\n",
        "\"\"\"\n",
        "\n",
        "import functools\n",
        "from typing import Any, Optional\n",
        "\n",
        "from absl import logging\n",
        "import jax.numpy as jnp\n",
        "import jax.profiler\n",
        "import ml_collections  # pylint: disable=unused-import\n",
        "from scenic.dataset_lib import dataset_utils\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from google3.experimental.largesensormodels.scenic.datasets import dataset_constants\n",
        "\n",
        "\n",
        "def get_height_crop_width_pad(\n",
        "    feat_shape: tuple[int, int, int], patch_size: tuple[int, int]\n",
        "):\n",
        "  \"\"\"Gets H crop, and W pad values for an image to allow for even patching.\n",
        "\n",
        "  NOTE: This assumes that the image is of the shape [H, W, C],\n",
        "  where H is the time axis, and W is the feature axis.\n",
        "\n",
        "  Args:\n",
        "    feat_shape: tuple; Shape of the image (H, W, C).\n",
        "    patch_size: tuple; Size of the patches to extract from the image (H, W).\n",
        "\n",
        "  Returns:\n",
        "    crop_h: int; Number of rows to crop from the top of the image.\n",
        "    pad_w: tuple; Number of columns to pad on the left and right of the image.\n",
        "    feat_shape_new: tuple; Shape of the new feature image (H, W, C).\n",
        "  \"\"\"\n",
        "\n",
        "  height, width, channels = feat_shape\n",
        "  patch_h, patch_w = patch_size\n",
        "\n",
        "  # Crop H (time) for even patches\n",
        "  num_patches_h = height // patch_h\n",
        "  crop_h = height - int(num_patches_h * patch_h)\n",
        "\n",
        "  # Pad W to make even patches\n",
        "  remainder_w = width % patch_w\n",
        "  if remainder_w != 0:\n",
        "    pad_total = patch_w - remainder_w\n",
        "    pad1 = pad_total // 2\n",
        "    pad2 = pad_total - pad1\n",
        "  else:\n",
        "    pad1 = 0\n",
        "    pad2 = 0\n",
        "  pad_w = (pad1, pad2)\n",
        "\n",
        "  # Calculate new shape\n",
        "  height_new = height - crop_h\n",
        "  width_new = pad1 + width + pad2\n",
        "  feat_shape_new = (height_new, width_new, channels)\n",
        "\n",
        "  return (crop_h, 0), pad_w, feat_shape_new\n",
        "\n",
        "\n",
        "def patch_compatible_resize_example(\n",
        "    example: tf.Tensor,\n",
        "    patch_size: tuple[int, int],\n",
        "):\n",
        "  \"\"\"Crops and pads features to allow for a integer number of patches.\n",
        "\n",
        "  NOTE: This assumes that the image is in the shape [H, W, C], where H is the\n",
        "  Time axis which can be cropped, and W is the feature axis which can be padded.\n",
        "\n",
        "  NOTE: This should be applied AFTER augmentations as to ensure that noise is\n",
        "    not applied to zero-padding.\n",
        "\n",
        "  Args:\n",
        "    example: A dictionary of inputs containing at least the 'input_signal',\n",
        "      'labels', and possibly 'datetime_signal' fields.\n",
        "    patch_size: tuple; Size of the patches to extract from the image (H, W).\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of inputs containing at least the 'input_signal', 'labels',\n",
        "      and possibly 'datetime_signal' fields. Where 'input_signal', and possibly\n",
        "      'datetime_signal' fields are H cropped and W padded.\n",
        "  \"\"\"\n",
        "  # Parse inputs\n",
        "  features = example['input_signal']\n",
        "  time_features = example['datetime_signal']  # datetime features\n",
        "\n",
        "  # Crop time axis (h) and pad feature axis (w)\n",
        "  crop_h, pad_w, _ = get_height_crop_width_pad(features.shape, patch_size)\n",
        "  features = features[crop_h[0] :, :, :]\n",
        "  features = tf.pad(\n",
        "      features,\n",
        "      paddings=[[0, 0], pad_w, [0, 0]],\n",
        "      mode='CONSTANT',\n",
        "      constant_values=0,\n",
        "  )\n",
        "\n",
        "  # Crop time axis (h) and pad time feature axis (w) of datetime features.\n",
        "  if time_features is not None:\n",
        "    time_crop_h, time_pad_w, _ = get_height_crop_width_pad(\n",
        "        time_features.shape, patch_size\n",
        "    )\n",
        "    time_features = time_features[time_crop_h[0] :, :, :]\n",
        "    time_features = tf.pad(\n",
        "        time_features,\n",
        "        [[0, 0], time_pad_w, [0, 0]],\n",
        "        mode='CONSTANT',\n",
        "        constant_values=0,\n",
        "    )\n",
        "\n",
        "  example['input_signal'] = features\n",
        "  example['datetime_signal'] = time_features\n",
        "\n",
        "  return example\n",
        "\n",
        "\n",
        "def preprocess_example(example, dataset_name, dtype=tf.float32):\n",
        "  \"\"\"Preprocesses the given example.\n",
        "\n",
        "  Adapted from google3/third_party/py/scenic/dataset_lib/cifar10_dataset.py\n",
        "\n",
        "  Args:\n",
        "    example: dict; Example that has an 'image' and a 'label'.\n",
        "    dataset_name: str; Name of the dataset. This is used to extract the\n",
        "      datetime features.\n",
        "    dtype: Tensorflow data type; Data type of the image.\n",
        "\n",
        "  Returns:\n",
        "    A preprocessed example.\n",
        "\n",
        "  NOTE: This assumes that the image is in the shape [H, W, C],\n",
        "    where H is the Time axis, and W is the feature axis.\n",
        "  \"\"\"\n",
        "  dataset_name = dataset_name.split('/')[-1]\n",
        "  features = tf.cast(example['input_signal'], dtype=dtype)\n",
        "  time_features = dataset_constants.lsm_dataset_constants[dataset_name].get(\n",
        "      'datetime_features', None\n",
        "  )\n",
        "\n",
        "  if time_features is None:\n",
        "    raise ValueError(dataset_name)\n",
        "\n",
        "  # Split input into inputs and time-features\n",
        "  feature_indices = list(range(features.shape[1]))\n",
        "  if time_features is not None:\n",
        "\n",
        "    # Get the inidices of datetime_features,\n",
        "    # and split them from the indicies of other features.\n",
        "    time_feature_indices = list(time_features['indices'])\n",
        "    feature_indices = list(set(feature_indices) - set(time_features['indices']))\n",
        "    time_feature_indices = tf.convert_to_tensor(time_feature_indices)\n",
        "    feature_indices = tf.convert_to_tensor(feature_indices)\n",
        "\n",
        "    # Using the above indices, split the feature tensor.\n",
        "    time_features = tf.gather(features, time_feature_indices, axis=1)\n",
        "    features = tf.gather(features, feature_indices, axis=1)\n",
        "  else:\n",
        "    time_features = None\n",
        "\n",
        "  # Stress / Mood / Activity Labels:\n",
        "  # A) Binary label of stress (0/1).\n",
        "  stress_label = tf.cast(example['label'], dtype=tf.int32)\n",
        "  # B) Boolean logs (True/False) of an logged exercise or mood event.\n",
        "  # (exercise and mood events are mutally exclusive).\n",
        "  exercise_log = example['metadata']['exercise_log']\n",
        "  mood_log = example['metadata']['mood_log']\n",
        "  # C) The log value (int 64 log code) for an excercise or mood event.\n",
        "  # NOTE: that exercise and mood events DO NOT occur simultaneously\n",
        "  log_value = tf.cast(example['metadata']['log_value'], tf.int32)\n",
        "\n",
        "  # Return preprocessed feature and desired labels.\n",
        "  # A) If activities or mood dataset: the log value is indexed [0, n classes],\n",
        "  # one-hot encoded, and returned as the label.\n",
        "  if ('activities' in dataset_name or 'mood' in dataset_name):\n",
        "    # One hot encode the log value.\n",
        "    # a) offset value of log_value - an artifact of dataset creation.\n",
        "    log_value_offset = tf.cast(\n",
        "        dataset_constants.lsm_dataset_constants[dataset_name][\n",
        "            'log_value_offset'\n",
        "        ],\n",
        "        tf.int32\n",
        "    )\n",
        "    # b) list of possible labels (log_values) for a dataset.\n",
        "    log_value_label_list = tf.convert_to_tensor(\n",
        "        dataset_constants.lsm_dataset_constants[dataset_name]['log_values']\n",
        "    )\n",
        "    # c) offset log_value.\n",
        "    log_value_label_list = log_value_label_list - log_value_offset\n",
        "    n_classes = len(log_value_label_list)  # number of classes in label map\n",
        "    # d) generate label map.\n",
        "    lookup_initializer = tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=log_value_label_list, values=tf.range(n_classes)\n",
        "    )\n",
        "    label_map = tf.lookup.StaticHashTable(lookup_initializer, default_value=-1)\n",
        "    # e) get label index from label map.\n",
        "    label_idx = label_map.lookup(log_value)\n",
        "    return {\n",
        "        'input_signal': features,\n",
        "        'datetime_signal': time_features,\n",
        "        'label': tf.one_hot(label_idx, n_classes),\n",
        "        'exercise_log': exercise_log,\n",
        "        'mood_log': mood_log,\n",
        "        'log_value': log_value,\n",
        "    }\n",
        "\n",
        "  # B) If stress dataset: the stress_label is one-hot encoded,\n",
        "  # and returned as the label.\n",
        "  elif 'stress' in dataset_name:\n",
        "    stress_label = tf.cast(stress_label, tf.int32)\n",
        "    return {\n",
        "        'input_signal': features,\n",
        "        'datetime_signal': time_features,\n",
        "        'label': tf.one_hot(stress_label, 2)\n",
        "    }\n",
        "\n",
        "  # C) This is used for pretraining datasets.\n",
        "  else:\n",
        "    return {\n",
        "        'input_signal': features,\n",
        "        'datetime_signal': time_features,\n",
        "        'stress_label': stress_label,\n",
        "        'exercise_log': exercise_log,\n",
        "        'mood_log': mood_log,\n",
        "        'log_value': log_value,\n",
        "    }\n",
        "\n",
        "\n",
        "def augment_example(example, augmentations, seed=0):\n",
        "  \"\"\"Applies augmentations (stretch, flip, noise) to the features.\"\"\"\n",
        "\n",
        "  augmented_feat = example['input_signal']\n",
        "  height, width, _ = augmented_feat.shape\n",
        "\n",
        "  # TODO REMOVE THIS\n",
        "  apply_noise = -1.0\n",
        "  noise_std = -1.0\n",
        "  apply_flip = -1.0\n",
        "  apply_stretch = -1.0\n",
        "  stretch = -1.0\n",
        "  # TODO REMOVE THIS\n",
        "\n",
        "\n",
        "\n",
        "  # Stretch (along time/height axis).\n",
        "  if 'stretch' in augmentations:\n",
        "    apply_stretch = tf.random.uniform([], minval=0, maxval=1, seed=seed)\n",
        "    if apply_stretch \u003e= 0.5:\n",
        "      stretch = tf.random.uniform([], minval=1.0, maxval=1.5, seed=seed+1)\n",
        "      stretched_height = int(height * stretch)\n",
        "      augmented_feat = tf.image.resize(\n",
        "          augmented_feat, size=[int(stretched_height), int(width)]\n",
        "      )\n",
        "      offset_height = stretched_height - height\n",
        "      augmented_feat = tf.image.crop_to_bounding_box(\n",
        "          image=augmented_feat,\n",
        "          target_height=height,\n",
        "          target_width=width,\n",
        "          offset_height=offset_height,\n",
        "          offset_width=0,\n",
        "      )\n",
        "\n",
        "      # TODO(girishvn): apply translate?\n",
        "      augmented_feat = augmented_feat[\n",
        "          -1 * height :, :, :\n",
        "      ]  # crop to original size\n",
        "\n",
        "  # Flip (along time/height axis).\n",
        "  if 'flip' in augmentations:\n",
        "    apply_flip = tf.random.uniform([], minval=0, maxval=1, seed=seed+3)\n",
        "    if apply_flip \u003e= 0.5:\n",
        "      augmented_feat = tf.image.flip_up_down(augmented_feat)\n",
        "\n",
        "  # Noise (gaussian).\n",
        "  if 'noise' in augmentations:\n",
        "    apply_noise = tf.random.uniform([], minval=0, maxval=1, seed=seed+4)\n",
        "    if apply_noise \u003e= 0.5:\n",
        "      noise_std = tf.random.uniform([], minval=0.0, maxval=0.5, seed=seed+5)\n",
        "      noise = tf.random.normal(\n",
        "          shape=tf.shape(augmented_feat),\n",
        "          mean=0.0,\n",
        "          stddev=noise_std,\n",
        "          seed=seed+6\n",
        "      )\n",
        "      augmented_feat += noise\n",
        "\n",
        "  #TODO REMOVE\n",
        "  example['aug_apply_noise'] = apply_noise\n",
        "  example['aug_noise_std'] = noise_std\n",
        "  example['aug_apply_flip'] = apply_flip\n",
        "  example['aug_apply_stretch'] = apply_stretch\n",
        "  example['aug_stretch'] = stretch\n",
        "  #TODO REMOVE\n",
        "\n",
        "  example['input_signal'] = augmented_feat\n",
        "  return example\n",
        "\n",
        "\n",
        "def update_metadata(metadata, dataset_name, patch_size):\n",
        "  \"\"\"Update metadata to reflect resizing and addition of datetime features.\"\"\"\n",
        "  # Setup: Get dataset name, feature shape, and possible datetime features.\n",
        "  metadata_update = dict()\n",
        "  dataset_name = dataset_name.split('/')[-1]\n",
        "  time_features = dataset_constants.lsm_dataset_constants[dataset_name].get(\n",
        "      'datetime_features', None\n",
        "  )\n",
        "  feature_shape = list(metadata['input_shape'][1:])\n",
        "  feature_indices = list(range(feature_shape[1]))\n",
        "\n",
        "  # Split features from time series features\n",
        "  # NOTE: This assumes that the original 'input_signal' field has sensor\n",
        "  # features contactanated to datetime features along the feature (w) dimension.\n",
        "  if time_features is not None:\n",
        "    # Get datetime indicies\n",
        "    time_feature_indices = list(time_features['indices'])\n",
        "    # Remove datetime indices from feature indices\n",
        "    feature_indices = list(set(feature_indices) - set(time_features['indices']))\n",
        "    # Get updated feature and datetime feature shapes.\n",
        "    time_feature_shape = feature_shape.copy()  # update time feature shape\n",
        "    time_feature_shape[1] = len(time_feature_indices)\n",
        "    feature_shape[1] = len(feature_indices)  # update feature shape\n",
        "  else:\n",
        "    time_feature_shape = None\n",
        "\n",
        "  # Padding: Update shape to reflect padding (for perfect patching).\n",
        "  # valid_feats arrays denote which features are valid (1) vs padded (0).\n",
        "  # 1. Update for sensor features\n",
        "  _, pad_w, feat_shape_new = get_height_crop_width_pad(\n",
        "      tuple(feature_shape), patch_size\n",
        "  )\n",
        "  valid_feat_mask = [0] * pad_w[0] + [1] * feature_shape[1] + [0] * pad_w[1]\n",
        "  metadata_update['input_shape'] = tuple([-1] + list(feat_shape_new))\n",
        "  metadata_update['input_valid_feats'] = tuple(valid_feat_mask)\n",
        "\n",
        "  # 2. Update for datetime features\n",
        "  if time_features is not None:\n",
        "    _, time_pad_w, time_feature_shape_new = get_height_crop_width_pad(\n",
        "        tuple(time_feature_shape), patch_size\n",
        "    )\n",
        "    valid_time_feat_mask = (\n",
        "        [0] * time_pad_w[0] + [1] * time_feature_shape[1] + [0] * time_pad_w[1]\n",
        "    )\n",
        "    metadata_update['datetime_input_shape'] = tuple(\n",
        "        [-1] + list(time_feature_shape_new)\n",
        "    )\n",
        "    metadata_update['datime_valid_feats'] = tuple(valid_time_feat_mask)\n",
        "\n",
        "  else:\n",
        "    metadata_update['datetime_input_shape'] = None\n",
        "    metadata_update['datime_valid_feats'] = None\n",
        "\n",
        "  # Update if dataset it one-hot-encoded or not.\n",
        "  if 'activities' in dataset_name or 'mood' in dataset_name:\n",
        "    metadata_update['target_is_onehot'] = True\n",
        "    metadata_update['num_classes'] = len(\n",
        "        dataset_constants.lsm_dataset_constants[dataset_name]['log_values']\n",
        "    )\n",
        "  elif 'stress' in dataset_name:\n",
        "    metadata_update['target_is_onehot'] = True\n",
        "    metadata_update['num_classes'] = 2\n",
        "\n",
        "  return metadata_update\n",
        "\n",
        "\n",
        "def get_electrodes_dataset(\n",
        "    *,\n",
        "    config,\n",
        "    num_shards,\n",
        "    batch_size,\n",
        "    eval_batch_size=None,\n",
        "    dtype_str='float32',\n",
        "    shuffle_seed=0,\n",
        "    rng=None,\n",
        "    shuffle_buffer_size=None,\n",
        "    dataset_service_address: Optional[str] = None,\n",
        "    dataset_name=None,  # 'lsm_prod/lsm_300min_10M_impute'\n",
        "    data_dir='/namespace/fitbit-medical-sandboxes/partner/encrypted/chr-ards-electrodes/deid/exp/dmcduff/ttl=6w/msa_1_5/lsm_tfds_datasets',\n",
        "):\n",
        "  \"\"\"Gets and formats the Electrodes dataset.\n",
        "\n",
        "  Adapted from:\n",
        "  google3/third_party/py/scenic/dataset_lib/cifar10_dataset.py and\n",
        "  google3/third_party/py/scenic/dataset_lib/dataset_utils.py.\n",
        "\n",
        "  Args:\n",
        "    config: ml_collections.ConfigDict; Config for the experiment.\n",
        "    num_shards: int; Number of shards to split the dataset into.\n",
        "    batch_size: int; Batch size for training.\n",
        "    eval_batch_size: int; Batch size for evaluation.\n",
        "    dtype_str: str; Data type of the image.\n",
        "    shuffle_seed: int; Seed for shuffling the dataset.\n",
        "    rng: jax.random.PRNGKey; Random number generator key.\n",
        "    shuffle_buffer_size: int; Size of the shuffle buffer.\n",
        "    dataset_service_address: str; Address of the dataset service.\n",
        "    dataset_name: str; Name of the dataset.\n",
        "    data_dir: str; Directory of the dataset.\n",
        "\n",
        "  Returns:\n",
        "    A dataset_utils.Dataset object.\n",
        "  \"\"\"\n",
        "\n",
        "  # Setup: General\n",
        "  if rng is None:\n",
        "    rng = jax.random.PRNGKey(config.rng_seed)\n",
        "\n",
        "  # 1. Process information.\n",
        "  p_idx = jax.process_index()  # current process index\n",
        "  p_cnt = jax.process_count()  # process count (number of processes)\n",
        "\n",
        "  aug_rngs = jax.random.split(rng, p_cnt)  # per-device augmentation seeds\n",
        "  aug_rng = aug_rngs[p_idx]  # device augmentation seed\n",
        "  tf_aug_rng = aug_rng[0]  # jax random seeds are arrays, tf expects an int.\n",
        "  del rng\n",
        "\n",
        "  # 2. dataset and data type information.\n",
        "  dataset_configs = config.dataset_configs  # get dataset configurations.\n",
        "  dataset_name = dataset_configs.get('dataset', dataset_name)  # get ds name\n",
        "  dtype = getattr(tf, dtype_str)  # data dtype\n",
        "  if eval_batch_size is None:  # set eval batch size\n",
        "    eval_batch_size = batch_size\n",
        "\n",
        "  # Setup: Mapping functions.\n",
        "  # 1. Preprocessing, augmentation, and cropping/padding functions.\n",
        "  preprocess_fn = functools.partial(\n",
        "      preprocess_example, dataset_name=dataset_name, dtype=dtype\n",
        "  )\n",
        "  # 2. Augmentation function.\n",
        "  augment_fn = functools.partial(\n",
        "      augment_example,\n",
        "      augmentations=config.get('train_augmentations', []),\n",
        "      seed=tf_aug_rng,\n",
        "  )\n",
        "\n",
        "  print('BASE SEED IS', tf_aug_rng)\n",
        "\n",
        "  # 3. Crop and pad features and time features to be patch size compatible.\n",
        "  crop_and_pad_fn = functools.partial(\n",
        "      patch_compatible_resize_example, patch_size=config.model.patches.size\n",
        "  )\n",
        "\n",
        "  # Setup: Data splits.\n",
        "  # 1. Train split: Get the entire or a subset of the training set.\n",
        "  train_split_name = dataset_configs.get('train_split', 'train')\n",
        "  num_train_samples = dataset_configs.get('train_num_samples', None)\n",
        "  if num_train_samples:\n",
        "    train_split = f'{train_split_name}[:{num_train_samples}]'\n",
        "  else:\n",
        "    train_split = train_split_name\n",
        "\n",
        "  # 2. Validation / Test splits: Split the test split into validation and\n",
        "  # test sets. (50% - 50% split).\n",
        "  eval_split_name = dataset_configs.get('eval_split', 'test')\n",
        "  val_split, test_split = tfds.even_splits(split=eval_split_name, n=2)\n",
        "\n",
        "  # 3. Per-process split: Split splits evenly per worker).\n",
        "  train_split_range = tfds.even_splits(split=train_split, n=p_cnt)[p_idx]\n",
        "  val_split_range = tfds.even_splits(split=val_split, n=p_cnt)[p_idx]\n",
        "  test_split_range = tfds.even_splits(split=test_split, n=p_cnt)[p_idx]\n",
        "\n",
        "  # 4. Load dataset splits.\n",
        "  train_ds = tfds.load(\n",
        "      dataset_name,\n",
        "      data_dir=data_dir,\n",
        "      split=train_split_range,\n",
        "      shuffle_files=False,  # NOTE: train shuffle is done below.\n",
        "  )\n",
        "  val_ds = tfds.load(\n",
        "      dataset_name,\n",
        "      data_dir=data_dir,\n",
        "      split=val_split_range,\n",
        "      shuffle_files=False,\n",
        "  )\n",
        "  test_ds = tfds.load(\n",
        "      dataset_name,\n",
        "      data_dir=data_dir,\n",
        "      split=test_split_range,\n",
        "      shuffle_files=False,\n",
        "  )\n",
        "  logging.info(  # pylint:disable=logging-fstring-interpolation\n",
        "      f'Loaded train, val, and test split {p_idx}/{p_cnt} from {dataset_name}.'\n",
        "  )\n",
        "\n",
        "  # Data processing and preperation.\n",
        "  # 1. Enable multi threaded workers.\n",
        "  options = tf.data.Options()\n",
        "  options.threading.private_threadpool_size = 48\n",
        "  train_ds = train_ds.with_options(options)\n",
        "  val_ds = val_ds.with_options(options)\n",
        "  test_ds = test_ds.with_options(options)\n",
        "\n",
        "  # 2. Preprocessing: Applied before `ds.cache()` to re-use it.\n",
        "  train_ds = train_ds.map(\n",
        "      preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  val_ds = val_ds.map(\n",
        "      preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  test_ds = test_ds.map(\n",
        "      preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "\n",
        "  # 3. Cache datasets: This can signficantly speed up training.\n",
        "  if dataset_configs.cache_dataset:\n",
        "    train_ds = train_ds.cache()\n",
        "    val_ds = val_ds.cache()\n",
        "    test_ds = test_ds.cache()\n",
        "\n",
        "  # 4. Data preperation (repetition, shuffling, augmentations, batching, etc.).\n",
        "  repeat_ds = dataset_configs.get('repeat_data', True)\n",
        "\n",
        "  # 4a. Train: repeat, augment, crop/pad, shuffle, and batch.\n",
        "  if repeat_ds:\n",
        "    train_ds = train_ds.repeat()  # repeat\n",
        "  # NOTE: Train augmentations are done after repeat for true randomness.\n",
        "  if config.use_train_augmentations:\n",
        "    train_ds = train_ds.map(  # train data augmentations\n",
        "        augment_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "  train_ds = train_ds.map(  # crop/pad for perfect patching\n",
        "      crop_and_pad_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  shuffle_buffer_size = shuffle_buffer_size or (8 * batch_size)\n",
        "  train_ds = train_ds.shuffle(shuffle_buffer_size, seed=shuffle_seed)  # shuffle\n",
        "  train_ds = train_ds.batch(batch_size, drop_remainder=True)  # batch\n",
        "  train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)  # prefetch\n",
        "\n",
        "  # 4b. Validation: crop/pad, batch, and repeat.\n",
        "  val_ds = val_ds.map(  # crop/pad for perfect patching\n",
        "      crop_and_pad_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  val_ds = val_ds.batch(batch_size, drop_remainder=False)  # batch\n",
        "  if repeat_ds:\n",
        "    val_ds = val_ds.repeat()  # repeat\n",
        "  val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  # 4c. Test: crop/pad, batch, and repeat.\n",
        "  test_ds = test_ds.map(  # crop/pad for perfect patching\n",
        "      crop_and_pad_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  test_ds = test_ds.batch(batch_size, drop_remainder=False)  # batch\n",
        "  if repeat_ds:\n",
        "    test_ds = test_ds.repeat()  # repeat\n",
        "  test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  if dataset_service_address:\n",
        "    if shuffle_seed is not None:\n",
        "      raise ValueError(\n",
        "          'Using dataset service with a random seed causes each '\n",
        "          'worker to produce exactly the same data. Add '\n",
        "          'config.shuffle_seed = None to your config if you '\n",
        "          'want to run with dataset service.'\n",
        "      )\n",
        "    train_ds = dataset_utils.distribute(train_ds, dataset_service_address)\n",
        "    logging.info('Using the tf.data service at %s', dataset_service_address)\n",
        "\n",
        "  # Other mappings\n",
        "  # 1. Set up batch padding: If batch remainders are NOT dropped batches may be\n",
        "  # padded to allow for an enough patches to contain all samples.\n",
        "  maybe_pad_batches_train = functools.partial(\n",
        "      dataset_utils.maybe_pad_batch,\n",
        "      train=True,\n",
        "      batch_size=batch_size,\n",
        "      inputs_key='input_signal',\n",
        "  )\n",
        "  maybe_pad_batches_eval = functools.partial(\n",
        "      dataset_utils.maybe_pad_batch,\n",
        "      train=False,\n",
        "      batch_size=eval_batch_size,\n",
        "      inputs_key='input_signal',\n",
        "  )\n",
        "  maybe_pad_batches_test = functools.partial(\n",
        "      dataset_utils.maybe_pad_batch,\n",
        "      train=False,\n",
        "      batch_size=eval_batch_size,\n",
        "      inputs_key='input_signal',\n",
        "  )\n",
        "  # 2. Set up batch sharding: Shard batches to be processed by multiple devices.\n",
        "  shard_batches = functools.partial(dataset_utils.shard, n_devices=num_shards)\n",
        "\n",
        "  # 3. Apply other mappings and Iter dataset\n",
        "  train_iter = iter(train_ds)\n",
        "  train_iter = map(dataset_utils.tf_to_numpy, train_iter)\n",
        "  train_iter = map(maybe_pad_batches_train, train_iter)\n",
        "  train_iter = map(shard_batches, train_iter)\n",
        "\n",
        "  val_iter = iter(val_ds)\n",
        "  val_iter = map(dataset_utils.tf_to_numpy, val_iter)\n",
        "  val_iter = map(maybe_pad_batches_eval, val_iter)\n",
        "  val_iter = map(shard_batches, val_iter)\n",
        "\n",
        "  test_iter = iter(test_ds)\n",
        "  test_iter = map(dataset_utils.tf_to_numpy, test_iter)\n",
        "  test_iter = map(maybe_pad_batches_test, test_iter)\n",
        "  test_iter = map(shard_batches, test_iter)\n",
        "\n",
        "  # Save meta data\n",
        "  info = tfds.builder(dataset_name, data_dir=data_dir, try_gcs=True).info\n",
        "  input_shape = tuple([-1] + list(info.features['input_signal'].shape))\n",
        "  meta_data = {\n",
        "      'input_shape': input_shape,\n",
        "      'num_train_examples': dataset_utils.get_num_examples(\n",
        "          dataset=dataset_name, split=train_split, data_dir=data_dir\n",
        "      ),\n",
        "      'num_val_examples': dataset_utils.get_num_examples(\n",
        "          dataset=dataset_name, split=val_split, data_dir=data_dir\n",
        "      ),\n",
        "      'num_test_examples': dataset_utils.get_num_examples(\n",
        "          dataset=dataset_name, split=test_split, data_dir=data_dir\n",
        "      ),\n",
        "      'input_dtype': getattr(jnp, dtype_str),\n",
        "      # The following two fields are set as defaults and may be updated in the\n",
        "      # update_metadata function below.\n",
        "      'target_is_onehot': False,\n",
        "      'num_classes': None,\n",
        "  }\n",
        "  # Update metadata to reflect preprocessing, and paddings\n",
        "  # (Changes in shape, and features).\n",
        "  meta_data.update(\n",
        "      update_metadata(\n",
        "          meta_data,\n",
        "          dataset_name=dataset_name,\n",
        "          patch_size=config.model.patches.size,\n",
        "      )\n",
        "  )\n",
        "\n",
        "  # Return dataset structure.\n",
        "  return dataset_utils.Dataset(train_iter, val_iter, test_iter, meta_data)\n",
        "\n",
        "\n",
        "def get_dataset(\n",
        "    config: Any,\n",
        "    data_rng: jnp.ndarray,\n",
        "    *,\n",
        "    num_local_shards: Optional[int] = None,\n",
        "    dataset_service_address: Optional[str] = None,\n",
        "    **kwargs: Any,\n",
        ") -\u003e dataset_utils.Dataset:\n",
        "  \"\"\"Adapted from: google3/third_party/py/scenic/train_lib/train_utils.py.\"\"\"\n",
        "\n",
        "  # Get device count\n",
        "  device_count = jax.device_count()\n",
        "  logging.info('device_count: %d', device_count)\n",
        "  logging.info('num_hosts : %d', jax.process_count())\n",
        "  logging.info('host_id : %d', jax.process_index())\n",
        "\n",
        "  # Set the dataset builder functions\n",
        "  dataset_suported_list = [\n",
        "      x['dataset_name']\n",
        "      for x in dataset_constants.lsm_dataset_constants.values()\n",
        "  ]\n",
        "  dataset_name = config.dataset_configs.dataset\n",
        "  if dataset_name.split('/')[1] in dataset_suported_list:\n",
        "    dataset_builder = get_electrodes_dataset\n",
        "  else:\n",
        "    raise ValueError(f'Dataset {dataset_name} is not supported.')\n",
        "\n",
        "  # Get batch size\n",
        "  batch_size = config.batch_size\n",
        "  if batch_size % device_count \u003e 0:\n",
        "    raise ValueError(\n",
        "        f'Batch size ({batch_size}) must be divisible by the '\n",
        "        f'number of devices ({device_count})'\n",
        "    )\n",
        "\n",
        "  local_batch_size = batch_size // jax.process_count()\n",
        "  device_batch_size = batch_size // device_count\n",
        "  logging.info('local_batch_size : %d', local_batch_size)\n",
        "  logging.info('device_batch_size : %d', device_batch_size)\n",
        "\n",
        "  # Get shuffle seed - ensure it exists\n",
        "  shuffle_seed = config.get('shuffle_seed', None)\n",
        "  if dataset_service_address and shuffle_seed is not None:\n",
        "    raise ValueError(\n",
        "        'Using dataset service with a random seed causes each '\n",
        "        'worker to produce exactly the same data. Add '\n",
        "        'config.shuffle_seed = None to your config if you want '\n",
        "        'to run with dataset service.'\n",
        "    )\n",
        "\n",
        "  # Get shuffle buffer size.\n",
        "  shuffle_buffer_size = config.get('shuffle_buffer_size', None)\n",
        "  # Local shard count.\n",
        "  num_local_shards = num_local_shards or jax.local_device_count()\n",
        "\n",
        "  # Build the dataset\n",
        "  ds = dataset_builder(\n",
        "      config=config,\n",
        "      num_shards=num_local_shards,\n",
        "      batch_size=local_batch_size,\n",
        "      dtype_str=config.data_dtype_str,\n",
        "      shuffle_seed=shuffle_seed,\n",
        "      rng=data_rng,\n",
        "      shuffle_buffer_size=shuffle_buffer_size,\n",
        "      dataset_service_address=dataset_service_address,\n",
        "      **kwargs,\n",
        "  )\n",
        "\n",
        "  return ds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VROqZiZtk1E"
      },
      "source": [
        "# Check Dataset Reproducibility\n",
        "### Takeaways:\n",
        "- Training augmentations ARE reproducible if `tf.keras.utils.set_random_seed` is set AND if `tf.config.experimental.enable_op_determinism` enabled.\n",
        "- Reproducible training also requires a set dataset shuffle seed. This can be done by setting `config.shuffle_seed`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTaRO7PZGPHv"
      },
      "outputs": [],
      "source": [
        "DATASET_NAME = 'lsm_300min_600_activities_balanced'\n",
        "TRAIN_DATA_SIZE = None\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# TEST 1\n",
        "print('Trail 1:')\n",
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "config = get_config(runlocal=False)  # must be false to get full dataset\n",
        "rng = jax.random.PRNGKey(config.rng_seed)\n",
        "data_rng, rng = jax.random.split(rng)\n",
        "dataset = get_dataset(config, data_rng)\n",
        "\n",
        "apply_noise_arr1 = []\n",
        "noise_std_arr1 = []\n",
        "apply_flip_arr1 = []\n",
        "apply_stretch_arr1 = []\n",
        "stretch_arr1 = []\n",
        "for i in range(100):\n",
        "  x = next(dataset.train_iter)\n",
        "  apply_noise_arr1.append(x['aug_apply_noise'])\n",
        "  noise_std_arr1.append(x['aug_noise_std'])\n",
        "  apply_flip_arr1.append(x['aug_apply_flip'])\n",
        "  apply_stretch_arr1.append(x['aug_apply_stretch'])\n",
        "  stretch_arr1.append(x['aug_stretch'])\n",
        "apply_noise_arr1 = tf.concat(apply_noise_arr1, axis=-1)[0]\n",
        "noise_std_arr1 = tf.concat(noise_std_arr1, axis=-1)[0]\n",
        "apply_flip_arr1 = tf.concat(apply_flip_arr1, axis=-1)[0]\n",
        "apply_stretch_arr1 = tf.concat(apply_stretch_arr1, axis=-1)[0]\n",
        "stretch_arr1 = tf.concat(stretch_arr1, axis=-1)[0]\n",
        "print(apply_noise_arr1[0:5])\n",
        "\n",
        "\n",
        "# TEST 2\n",
        "print('\\nTrail 2:')\n",
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "config = get_config(runlocal=False)  # must be false to get full dataset\n",
        "rng = jax.random.PRNGKey(config.rng_seed)\n",
        "data_rng, rng = jax.random.split(rng)\n",
        "dataset = get_dataset(config, data_rng)\n",
        "\n",
        "apply_noise_arr2 = []\n",
        "noise_std_arr2 = []\n",
        "apply_flip_arr2 = []\n",
        "apply_stretch_arr2 = []\n",
        "stretch_arr2 = []\n",
        "for i in range(100):\n",
        "  x = next(dataset.train_iter)\n",
        "  apply_noise_arr2.append(x['aug_apply_noise'])\n",
        "  noise_std_arr2.append(x['aug_noise_std'])\n",
        "  apply_flip_arr2.append(x['aug_apply_flip'])\n",
        "  apply_stretch_arr2.append(x['aug_apply_stretch'])\n",
        "  stretch_arr2.append(x['aug_stretch'])\n",
        "apply_noise_arr2 = tf.concat(apply_noise_arr2, axis=-1)[0]\n",
        "noise_std_arr2 = tf.concat(noise_std_arr2, axis=-1)[0]\n",
        "apply_flip_arr2 = tf.concat(apply_flip_arr2, axis=-1)[0]\n",
        "apply_stretch_arr2 = tf.concat(apply_stretch_arr2, axis=-1)[0]\n",
        "stretch_arr2 = tf.concat(stretch_arr2, axis=-1)[0]\n",
        "print(apply_noise_arr2[0:5])\n",
        "\n",
        "print('\\nTrail 1 equals Trail 2?:')\n",
        "print('apply_noise:', bool(tf.reduce_all(tf.math.equal(apply_noise_arr1, apply_noise_arr2))))\n",
        "print('noise_std:', bool(tf.reduce_all(tf.math.equal(noise_std_arr1, noise_std_arr2))))\n",
        "print('apply_flip:', bool(tf.reduce_all(tf.math.equal(apply_flip_arr1, apply_flip_arr2))))\n",
        "print('apply_stretch:', bool(tf.reduce_all(tf.math.equal(apply_stretch_arr1, apply_stretch_arr2))))\n",
        "print('stretch:', bool(tf.reduce_all(tf.math.equal(stretch_arr1, stretch_arr2))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOO6x6EDvrKI"
      },
      "source": [
        "# Check seeded random functions vs unseeded random functions\n",
        "### Experiment information:\n",
        "- Assuming the global seed is set, will functions with the same seed produce the same sequence of numbers.\n",
        "### Takeaways:\n",
        "- Random functions must be seeded differently if different sequences of random numbers are required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JAbDFRfr3Gmo"
      },
      "outputs": [],
      "source": [
        "# @title Baseline: Global Seed Set - Function Seeds Set (All Same)\n",
        "\n",
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B68M2mlM4FtF"
      },
      "outputs": [],
      "source": [
        "# @title Experiment 1: Global Seed Set / Function Seeds Set (All Same)\n",
        "\n",
        "# Explanation:\n",
        "# If function seeds are set, and there are random functions, with different\n",
        "# seeds are run between calls, will the output sequence be the same?\n",
        "\n",
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=1)\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=1)\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N6m1KkV94bjt"
      },
      "outputs": [],
      "source": [
        "# @title Experiment 2: Global Seed Set - Function Seeds Set (All Different)\n",
        "\n",
        "# Explanation:\n",
        "# Showing that random function with different seed will produce a different\n",
        "# sequence of numbers.\n",
        "\n",
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=0)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=1)\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=100)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=1)\n",
        "x = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32, seed=1000)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw1wnuGa4OEf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-GZBYUXeEUbg",
        "4VROqZiZtk1E",
        "NOO6x6EDvrKI"
      ],
      "last_runtime": {
        "build_target": "//fitbit/research/sensing/electrodes/colab:rl_colab",
        "kind": "shared"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
